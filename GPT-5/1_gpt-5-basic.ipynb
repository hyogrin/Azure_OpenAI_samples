{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-5 Basic Test Notebook (Azure OpenAI)\n",
    "\n",
    "This notebook provides examples of the Chat Completions API and the Responses API to quickly validate the basic functionality of GPT-5 in Azure OpenAI. It uses the Azure OpenAI endpoint, key, and deployment name configured in the environment variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "## Requruirements\n",
    "\n",
    "- Python 3.10+\n",
    "- `pip install -r GPT-5/requirements.txt`\n",
    "- `GPT-5/.env` \n",
    "  - AZURE_OPENAI_ENDPOINT\n",
    "  - AZURE_OPENAI_API_KEY\n",
    "  - AZURE_OPENAI_API_VERSION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Completions API Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Azure OpenAI 환경 설정 ===\n",
      "Endpoint: https://hyo-ai-foundry-pjt1-resource.openai.azure.com/\n",
      "API Version: 2025-03-01-preview\n",
      "Deployment Name: gpt-5\n",
      "Embedding Deployment: text-embedding-ada-002\n",
      "API Key set: True\n",
      "Client initialized: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "import base64\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential, EnvironmentCredential\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "from io import BytesIO\n",
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "import json\n",
    "load_dotenv(override=True)\n",
    "\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\", \"\") if len(os.getenv(\"AZURE_OPENAI_API_KEY\", \"\")) > 0 else None\n",
    "azure_openai_gpt5_deployment_name = \"gpt-5\"\n",
    "azure_openai_gpt41_deployment_name = \"gpt-4.1\"\n",
    "azure_openai_embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-ada-002\")\n",
    "aoai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"\") if len(os.getenv(\"AZURE_OPENAI_API_VERSION\", \"\")) > 0 else None\n",
    "\n",
    "\n",
    "try:\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=azure_openai_endpoint,\n",
    "        api_key=azure_openai_key,\n",
    "        api_version=aoai_api_version\n",
    "    )\n",
    "except (ValueError, TypeError) as e:\n",
    "    print(e)\n",
    "\n",
    "\n",
    "# Print environment variables (excluding sensitive info)\n",
    "print(\"=== Azure OpenAI 환경 설정 ===\")\n",
    "print(f\"Endpoint: {azure_openai_endpoint}\")\n",
    "print(f\"API Version: {aoai_api_version}\")\n",
    "print(f\"Deployment Name: {azure_openai_gpt5_deployment_name}\")\n",
    "print(f\"Embedding Deployment: {azure_openai_embedding_deployment}\")\n",
    "print(f\"API Key set: {azure_openai_key is not None}\")\n",
    "print(f\"Client initialized: {client is not None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Calling Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 기본 채팅 예제 ===\n",
      "다음 내용은 제가 확인할 수 있는 최신 공개 정보(지식 기준: 2024년 10월)까지를 바탕으로 한 마이크로소프트(Microsoft) 동향 요약입니다. 2025년에 새로 발표된 사항은 포함되지 않았을 수 있으니, 정말 “최신” 소식을 원하시면 공식 뉴스룸이나 최근 실적 발표 자료를 함께 확인하시길 권합니다.\n",
      "\n",
      "핵심 요약\n",
      "- 전사 전략: “클라우드 + AI”에 집중. Copilot을 중심으로 제품 전반에 생성형 AI를 통합하고, 이를 뒷받침하기 위해 Azure 인프라(데이터센터·전력·네트워킹·반도체 파트너십)에 대규모 투자를 지속.\n",
      "- 실적/투자: 클라우드와 AI 수요 확대에 힘입어 사상 최대 실적을 경신(연속 분기 최고치 갱신). AI 워크로드 대응을 위한 설비투자(CapEx)가 크게 증가하는 기조가 이어짐.\n",
      "- 규제/정책: Teams 번들 이슈에 대한 비판에 대응해 2024년에 전세계적으로 Teams 분리판매를 확대. 유럽 등에서 클라우드 라이선싱 관행 관련 조사와 논의가 진행 중.\n",
      "- 파트너십/거버넌스: OpenAI와의 전략적 파트너십 유지. 2024년 중반에는 각국 규제 당국의 우려를 고려해 OpenAI 이사회 옵저버 자리에서 물러났으나, 기술·사업 협력은 지속.\n",
      "- 보안: 국가 연계 위협 사건 공개 이후 “Secure Future Initiative”를 통해 기본 보안 강화, 엔지니어링 프로세스 개선, 제품 기본 설정의 보안성 제고 등 전사적 보안 체질 개선을 진행.\n",
      "\n",
      "AI와 Copilot\n",
      "- Copilot 확장: Bing Chat/Office 365의 AI 기능을 “Copilot” 브랜드로 통합. Copilot Pro(개인 유료), Copilot for Microsoft 365(기업용) 보급이 확대되었고, 2024년에는 좌석 수 제한 완화 등 도입 장벽이 낮아짐.\n",
      "- 팀 협업: 회의·프로젝트 관리·문서 협업에서 AI가 팀 단위로 보조하는 ‘Team Copilot’이 2024년에 공개/예고되며 기능 영역 확대.\n",
      "- 개발자 생태계: GitHub Copilot의 엔터프라이즈 기능 강화, Copilot Studio로 맞춤형 Copilot/플러그인 제작, Microsoft Graph 기반의 데이터 그라운딩 강화.\n",
      "- 모델과 플랫폼: 경량 SLM 계열인 Phi-3 등 자체 모델군을 공개하고, Azure OpenAI Service로 GPT 계열을 비롯한 모델 접근을 제공. RAG, 벡터 검색, 프라이버시/거버넌스 기능을 보강.\n",
      "\n",
      "Windows와 디바이스(Copilot+ PC)\n",
      "- Copilot+ PC: 2024년에 NPU(초당 40+ TOPS) 탑재를 요건으로 한 ‘Copilot+ PC’를 발표. ARM 기반(예: Snapdragon X Elite/Plus) 기종이 선도하며, 배터리·성능·온디바이스 AI 가속을 내세움.\n",
      "- Recall 기능: 개인 정보 보호와 보안 우려로 기본 활성화 방식이 조정되고 출시 시점이 늦춰지는 등 신중한 접근으로 전환.\n",
      "- Windows 11: 24H2 세대의 성능·보안·로컬 AI 기능 강화, ARM 전환 가속을 위한 에뮬레이션과 앱 호환성 개선.\n",
      "\n",
      "Azure와 인프라\n",
      "- AI 인프라 증설: GPU/가속기 클러스터 확충, 고속 네트워킹, 냉각·전력 효율화 등 대규모 데이터센터 투자. 전력 수급을 위해 장기 재생에너지 계약을 적극 체결.\n",
      "- 데이터/분석: Microsoft Fabric로 데이터 분석·BI·실시간 분석을 통합하는 전략을 전개. Oracle Database@Azure 등 이기종 엔터프라이즈 워크로드 지원도 확대.\n",
      "- 보안/관리: Defender XDR, Sentinel 등 보안 제품군을 통한 엔드투엔드 탐지·대응 역량 강화, 기본 MFA 확대 등 보안 기본값 상향.\n",
      "\n",
      "보안과 신뢰\n",
      "- 사고 대응과 체질 개선: 2024년에 국가 연계 위협의 침해 사실을 공개하고, 토큰·키 관리, 권한 최소화, 내부 접근 통제, 보안 기본값 상향 등 엔지니어링·운영 차원의 개선책을 단계적으로 적용.\n",
      "- 고객 제품: 보안 제품 라인업을 통합·간소화하고, AI 기반 위협 탐지·자동화 조치 기능을 보강.\n",
      "\n",
      "규제·반독점·정책\n",
      "- 협업툴 번들링: Microsoft 365에서 Teams 분리판매를 유럽뿐 아니라 전세계로 확대(2024). 경쟁·공정성 관련 우려에 대한 대응 조치.\n",
      "- 클라우드 라이선싱: 유럽/영국 중심으로 라이선싱 관행에 대한 문제 제기가 이어지며, 조건 조정과 대화가 진행 중.\n",
      "\n",
      "게임(게이밍)\n",
      "- 액티비전 블리자드 인수(2023년 성사) 이후 통합 진행, 프랜차이즈 파이프라인과 Game Pass 생태계 강화. 규제 당국과의 합의에 따른 클라우드 게이밍 관련 약속 이행 지속.\n",
      "\n",
      "지속가능성\n",
      "- 데이터센터 확장에 따른 배출 증가 압력 속에서도 2030년 탄소 네거티브·물 긍정·제로 폐기물 목표를 유지. 대규모 재생에너지 PPA 체결, 탄소 제거 크레딧 조달, 물 사용 효율화 투자 확대.\n",
      "\n",
      "조직/리더십\n",
      "- 2024년 소비자 AI 조직(Microsoft AI) 출범과 함께 AI 리더십 보강. Windows/Surface 조직도 ARM 전환과 Copilot+ PC 전략에 맞춰 재편.\n",
      "\n",
      "최신 정보 확인 팁\n",
      "- Microsoft 공식 뉴스룸: news.microsoft.com\n",
      "- 투자자 관계(IR) 페이지(분기 실적/가이던스): investor.microsoft.com\n",
      "- 연례 개발자 행사(Build), IT 프로 행사(Ignite) 키노트와 세션\n",
      "- 제품별 블로그(Windows, Azure, Security, GitHub, Microsoft 365 등)\n",
      "\n",
      "원하시면 특정 영역(예: 재무 실적, Copilot 기능 로드맵, Copilot+ PC, 보안, 규제 이슈, 파트너십 등)으로 좁혀서 더 자세히 정리해 드릴게요.\n",
      "\n",
      "=== 함수 호출 예제 ===\n",
      "함수 호출: get_weather({'city': 'Seoul'})\n",
      "함수 결과: 맑음, 22°C\n",
      "최종 응답: 현재 서울은 맑고 기온은 약 22°C입니다.\n",
      "시간대별 예보나 강수확률, 바람·습도, 미세먼지 정보도 확인해드릴까요?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) 기본 채팅\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Microsoft에 대한 가장 최신 정보를 알려줘.\"}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=azure_openai_gpt5_deployment_name,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(\"=== 기본 채팅 예제 ===\")\n",
    "print(response.choices[0].message.content)\n",
    "print()\n",
    "\n",
    "# 2) 함수 호출 (간단한 버전)\n",
    "def get_weather(city: str):\n",
    "    \"\"\"Mock weather function\"\"\"\n",
    "    weather_data = {\n",
    "        \"Seoul\": \"맑음, 22°C\",\n",
    "        \"Busan\": \"흐림, 19°C\"\n",
    "    }\n",
    "    return weather_data.get(city, f\"{city}: 날씨 정보 없음\")\n",
    "\n",
    "# 함수 스키마 정의\n",
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get weather for a city\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"city\": {\"type\": \"string\", \"description\": \"City name\"}\n",
    "            },\n",
    "            \"required\": [\"city\"]\n",
    "        }\n",
    "    }\n",
    "}]\n",
    "\n",
    "# 함수 호출이 포함된 대화\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"서울 날씨 알려줘\"}\n",
    "]\n",
    "\n",
    "print(\"=== 함수 호출 예제 ===\")\n",
    "response = client.chat.completions.create(\n",
    "    model=azure_openai_gpt5_deployment_name,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "\n",
    "# 함수 호출 확인 및 실행 (실제 코드는 while 루프 등으로 실행하는게 일반적)\n",
    "if response.choices[0].message.tool_calls:\n",
    "    tool_call = response.choices[0].message.tool_calls[0]\n",
    "    function_name = tool_call.function.name\n",
    "    arguments = json.loads(tool_call.function.arguments)\n",
    "    \n",
    "    print(f\"함수 호출: {function_name}({arguments})\")\n",
    "    \n",
    "    # 실제 함수 실행\n",
    "    if function_name == \"get_weather\":\n",
    "        result = get_weather(arguments[\"city\"])\n",
    "        print(f\"함수 결과: {result}\")\n",
    "        \n",
    "        # 함수 결과와 함께 최종 응답 생성\n",
    "        messages.append(response.choices[0].message)\n",
    "        messages.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"content\": result\n",
    "        })\n",
    "        \n",
    "        final_response = client.chat.completions.create(\n",
    "            model=azure_openai_gpt5_deployment_name,\n",
    "            messages=messages\n",
    "        )\n",
    "        \n",
    "        print(f\"최종 응답: {final_response.choices[0].message.content}\")\n",
    "else:\n",
    "    print(f\"직접 응답: {response.choices[0].message.content}\")\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Output Test with Json Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Structured Output (JSON Schema) ===\n",
      "{\"title\":\"ASUS ROG Zephyrus G14 (2024, RTX 4070)\",\"category\":\"게이밍 노트북\",\"price_krw\":2900000,\"pros\":[\"3K 120Hz OLED 디스플레이로 선명한 화질과 빠른 응답\",\"RTX 4070 + 최신 Ryzen 9 조합으로 강력한 게임/크리에이티브 성능\",\"1.6kg대의 경량·슬림 설계로 휴대성 우수\",\"우수한 스피커와 키보드/트랙패드 품질\",\"성능·소음 프로필 전환 등 유연한 팬/전력 관리\"],\"cons\":[\"가격대가 높음\",\"고부하 시 발열과 팬 소음 증가\",\"메모리 업그레이드 제약(일부 용량 온보드)\",\"포트 구성 제한적(유선 LAN 미탑재 등)\",\"OLED 특성상 번인 우려 및 SDR 밝기 제한\"]}\n"
     ]
    }
   ],
   "source": [
    "# 5) 구조화된 출력 (Chat Completions API - JSON Schema)\n",
    "json_schema = {\n",
    "    \"name\": \"product_summary\",\n",
    "    \"schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"title\": {\"type\": \"string\"},\n",
    "            \"category\": {\"type\": \"string\"},\n",
    "            \"price_krw\": {\"type\": \"number\"},\n",
    "            \"pros\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "            \"cons\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "        },\n",
    "        \"required\": [\"title\", \"category\", \"price_krw\", \"pros\", \"cons\"], \n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "    \"strict\": True,\n",
    "}\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"게이밍 노트북 추천 모델 하나를 임의로 정하고 요약 JSON을 생성해줘. 가격은 원화로 대략적 수치를 넣어.\"}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=azure_openai_gpt5_deployment_name,\n",
    "    messages=messages,\n",
    "    response_format={\"type\": \"json_schema\", \"json_schema\": json_schema},\n",
    ")\n",
    "\n",
    "print(\"=== Structured Output (JSON Schema) ===\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API (stateful chat for 30days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"resp_68baa470744c819cbdf882d929a1b21f0db26a9495fbecdb\",\n",
      "  \"created_at\": 1757062256.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"rs_68baa470fee0819c9b6f84a4393abbe30db26a9495fbecdb\",\n",
      "      \"summary\": [],\n",
      "      \"type\": \"reasoning\",\n",
      "      \"content\": null,\n",
      "      \"encrypted_content\": null,\n",
      "      \"status\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"msg_68baa471b3c0819cbe84fd773233e64e0db26a9495fbecdb\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"Thanks for the test. How can I help you today?\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 11,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 82,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 64\n",
      "    },\n",
      "    \"total_tokens\": 93\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(   \n",
    "  model=azure_openai_gpt5_deployment_name, \n",
    "  input=\"This is a test.\",\n",
    ")\n",
    "\n",
    "print(response.model_dump_json(indent=2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - Function Calling Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"resp_68baa47759e481a299f683a7eefa9e9303b6b99fee8d17a1\",\n",
      "  \"created_at\": 1757062263.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"rs_68baa47842c481a280bbd8b2ae5aa1be03b6b99fee8d17a1\",\n",
      "      \"summary\": [],\n",
      "      \"type\": \"reasoning\",\n",
      "      \"content\": null,\n",
      "      \"encrypted_content\": null,\n",
      "      \"status\": null\n",
      "    },\n",
      "    {\n",
      "      \"arguments\": \"{\\\"location\\\":\\\"San Francisco\\\"}\",\n",
      "      \"call_id\": \"call_35iBDrjMUCPw0suPvmGf9HrC\",\n",
      "      \"name\": \"get_weather\",\n",
      "      \"type\": \"function_call\",\n",
      "      \"id\": \"fc_68baa479342c81a2ba49b544cab6995f03b6b99fee8d17a1\",\n",
      "      \"status\": \"completed\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"name\": \"get_weather\",\n",
      "      \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "          \"location\": {\n",
      "            \"type\": \"string\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"location\"\n",
      "        ]\n",
      "      },\n",
      "      \"strict\": true,\n",
      "      \"type\": \"function\",\n",
      "      \"description\": \"Get the weather for a location\"\n",
      "    }\n",
      "  ],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 50,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 85,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 64\n",
      "    },\n",
      "    \"total_tokens\": 135\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "{\n",
      "  \"id\": \"resp_68baa47a503881a2b5112eb0ebb4ce4803b6b99fee8d17a1\",\n",
      "  \"created_at\": 1757062266.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4.1\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"msg_68baa47b3ff081a29cbdcaf40c48e02903b6b99fee8d17a1\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"The current temperature in San Francisco is about 70 degrees Fahrenheit. If you need a more detailed forecast (including wind, precipitation, etc.), please let me know!\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": \"resp_68baa47759e481a299f683a7eefa9e9303b6b99fee8d17a1\",\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 45,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 34,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 79\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(  \n",
    "    model=azure_openai_gpt5_deployment_name, \n",
    "    tools=[  \n",
    "        {  \n",
    "            \"type\": \"function\",  \n",
    "            \"name\": \"get_weather\",  \n",
    "            \"description\": \"Get the weather for a location\",  \n",
    "            \"parameters\": {  \n",
    "                \"type\": \"object\",  \n",
    "                \"properties\": {  \n",
    "                    \"location\": {\"type\": \"string\"},  \n",
    "                },  \n",
    "                \"required\": [\"location\"],  \n",
    "            },  \n",
    "        }  \n",
    "    ],  \n",
    "    input=[{\"role\": \"user\", \"content\": \"What's the weather in San Francisco?\"}],  \n",
    ")  \n",
    "\n",
    "print(response.model_dump_json(indent=2))  \n",
    "  \n",
    "# To provide output to tools, add a response for each tool call to an array passed  \n",
    "# to the next response as `input`  \n",
    "input = []  \n",
    "for output in response.output:  \n",
    "    if output.type == \"function_call\":  \n",
    "        match output.name:  \n",
    "            case \"get_weather\":  \n",
    "                input.append(  \n",
    "                    {  \n",
    "                        \"type\": \"function_call_output\",  \n",
    "                        \"call_id\": output.call_id,  \n",
    "                        \"output\": '{\"temperature\": \"70 degrees\"}',  \n",
    "                    }  \n",
    "                )  \n",
    "            case _:  \n",
    "                raise ValueError(f\"Unknown function call: {output.name}\")  \n",
    "  \n",
    "second_response = client.responses.create(  \n",
    "    model=azure_openai_gpt41_deployment_name,  \n",
    "    previous_response_id=response.id,  \n",
    "    input=input  \n",
    ")  \n",
    "\n",
    "print(second_response.model_dump_json(indent=2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - Structured Output Test with Json Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Responses API doen't support response_format.\n"
     ]
    }
   ],
   "source": [
    "# 5) 구조화된 출력 (Responses API - JSON Schema)\n",
    "# json_schema = {\n",
    "#     \"name\": \"product_summary\",\n",
    "#     \"schema\": {\n",
    "#         \"type\": \"object\",\n",
    "#         \"properties\": {\n",
    "#             \"title\": {\"type\": \"string\"},\n",
    "#             \"category\": {\"type\": \"string\"},\n",
    "#             \"price_krw\": {\"type\": \"number\"},\n",
    "#             \"pros\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "#             \"cons\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "#         },\n",
    "#         \"required\": [\"title\", \"category\", \"price_krw\"],\n",
    "#         \"additionalProperties\": False,\n",
    "#     },\n",
    "#     \"strict\": True,\n",
    "# }\n",
    "\n",
    "# inputs = [\n",
    "#     {\"role\": \"user\", \"content\": \"게이밍 노트북 추천 모델 하나를 임의로 정하고 요약 JSON을 생성해줘. 가격은 원화로 대략적 수치를 넣어.\"}\n",
    "# ]\n",
    "\n",
    "# response = client.responses.create(\n",
    "#     model=azure_openai_gpt5_deployment_name,\n",
    "#     input=inputs,\n",
    "#     response_format={\"type\": \"json_schema\", \"json_schema\": json_schema},\n",
    "# )\n",
    "\n",
    "# print(response.model_dump_json(indent=2)) \n",
    "\n",
    "print(\"Responses API doen't support response_format.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - Streaming output Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "냉장고를 열었더니 물만 하나 있었다.\n",
      "그래서 물어봤다.\n",
      "\"나 말고 뭐 먹을 거 없어?\"\n",
      "물이 대답했다.\n",
      "\"물론.\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    stream = client.chat.completions.create(\n",
    "        model=azure_openai_gpt5_deployment_name,\n",
    "        messages=[{\"role\": \"user\", \"content\": \"다섯줄 줄 농담 하나.\"}],\n",
    "        stream=True,\n",
    "    )\n",
    "    \n",
    "    for chunk in stream:\n",
    "        if chunk.choices:\n",
    "            delta = chunk.choices[0].delta.content\n",
    "            if delta:\n",
    "                print(delta, end=\"\", flush=True)\n",
    "                time.sleep(0.05)\n",
    "    print()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"스트리밍 오류: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - Vision Support Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"resp_68baa7048ac0819fbc24fd3dd1a2fce802610945b92f961a\",\n",
      "  \"created_at\": 1757062916.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"rs_68baa7070ddc819f9f16b5d03b9d8c4702610945b92f961a\",\n",
      "      \"summary\": [],\n",
      "      \"type\": \"reasoning\",\n",
      "      \"content\": null,\n",
      "      \"encrypted_content\": null,\n",
      "      \"status\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"msg_68baa70c7f64819fb75427bbd636d9b002610945b92f961a\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"- 초록 숲과 초원이 뒤덮인 산악 지형으로, 중앙의 절벽형 능선이 두드러집니다.\\n- 산기슭에는 목초지와 작은 마을이 점점이 놓여 있으며 완만한 계곡이 펼쳐집니다.\\n- 맑은 파란 하늘에 구름이 흩어져 있고, 멀리 더 높은 봉우리와 일부 설산이 보입니다.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 373,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 422,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 320\n",
      "    },\n",
      "    \"total_tokens\": 795\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 4) 멀티모달: 이미지 분석 (Responses API)\n",
    "# Note: Requires the deployed model to support vision and your API version to allow image input.\n",
    "image_url = os.getenv(\"TEST_IMAGE_URL\", \"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Fronalpstock_big.jpg/640px-Fronalpstock_big.jpg\")\n",
    "\n",
    "inputs = [\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"input_text\", \"text\": \"이미지의 주요 특징을 한국어로 3줄 요약해줘.\"},\n",
    "        {\"type\": \"input_image\", \"image_url\": image_url},\n",
    "    ]}\n",
    "]\n",
    "\n",
    "response = client.responses.create(model=azure_openai_gpt5_deployment_name, input=inputs)\n",
    "\n",
    "print(response.model_dump_json(indent=2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - Code Interpreter Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"resp_68baa72e3ae0819fa9555ff33ea9095807fb44d44c7f7b1f\",\n",
      "  \"created_at\": 1757062958.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": \"You are a personal math tutor. When asked a math question, write and run code using the python tool to answer the question.\",\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"rs_68baa7307010819fad4220632f49d48307fb44d44c7f7b1f\",\n",
      "      \"summary\": [],\n",
      "      \"type\": \"reasoning\",\n",
      "      \"content\": null,\n",
      "      \"encrypted_content\": null,\n",
      "      \"status\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ci_68baa734b0f4819face6bf108689f32807fb44d44c7f7b1f\",\n",
      "      \"code\": \"# Solve 3x + 11 = 14 for x\\r\\nx = (14 - 11) / 3\\r\\nx\",\n",
      "      \"container_id\": \"cntr_68baa72f018c81908c456f9bb8c7a5620c3b65bc73b36f02\",\n",
      "      \"outputs\": null,\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"code_interpreter_call\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"msg_68baa736261c819fbae26878fdef040107fb44d44c7f7b1f\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"Solve 3x + 11 = 14:\\n- Subtract 11 from both sides: 3x = 3\\n- Divide both sides by 3: x = 1\\n\\nAnswer: x = 1\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"container\": {\n",
      "        \"type\": \"auto\",\n",
      "        \"file_ids\": null\n",
      "      },\n",
      "      \"type\": \"code_interpreter\"\n",
      "    }\n",
      "  ],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 1712,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 306,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 256\n",
      "    },\n",
      "    \"total_tokens\": 2018\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "instructions = \"You are a personal math tutor. When asked a math question, write and run code using the python tool to answer the question.\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=azure_openai_gpt5_deployment_name,\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"code_interpreter\",\n",
    "            \"container\": {\"type\": \"auto\"}\n",
    "        }\n",
    "    ],\n",
    "    instructions=instructions,\n",
    "    input=\"I need to solve the equation 3x + 11 = 14. Can you help me?\",\n",
    ")\n",
    "\n",
    "print(response.model_dump_json(indent=2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - List previous chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"id\": \"msg_68baa72ea2a4819fabfe4bc7e6979c7907fb44d44c7f7b1f\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"text\": \"I need to solve the equation 3x + 11 = 14. Can you help me?\",\n",
      "          \"type\": \"input_text\"\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"user\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"has_more\": false,\n",
      "  \"object\": \"list\",\n",
      "  \"first_id\": \"msg_68baa72ea2a4819fabfe4bc7e6979c7907fb44d44c7f7b1f\",\n",
      "  \"last_id\": \"msg_68baa72ea2a4819fabfe4bc7e6979c7907fb44d44c7f7b1f\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.input_items.list(\"resp_68baa72e3ae0819fa9555ff33ea9095807fb44d44c7f7b1f\")\n",
    "\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - Upload PDF and analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"assistant-8StXmwbgba1Ke52mPt7AHs\",\n",
      "  \"bytes\": 1165436,\n",
      "  \"created_at\": 1757063685,\n",
      "  \"filename\": \"AI_Brief_Aug2025.pdf\",\n",
      "  \"object\": \"file\",\n",
      "  \"purpose\": \"assistants\",\n",
      "  \"status\": \"processed\",\n",
      "  \"expires_at\": null,\n",
      "  \"status_details\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Upload a file with a purpose of \"assistants\"\n",
    "file = client.files.create(\n",
    "  file=open(\"AI_Brief_Aug2025.pdf\", \"rb\"), # This assumes a .pdf file in the same directory as the executing script\n",
    "  purpose=\"assistants\"\n",
    ")\n",
    "\n",
    "print(file.model_dump_json(indent=2))\n",
    "file_id = file.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"resp_68baab59766881a2ac3a1c5dbdcd060c0a4857b25b5d767c\",\n",
      "  \"created_at\": 1757064029.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"rs_68baab6476ec81a2b4bc2e7a8cef48d30a4857b25b5d767c\",\n",
      "      \"summary\": [],\n",
      "      \"type\": \"reasoning\",\n",
      "      \"content\": null,\n",
      "      \"encrypted_content\": null,\n",
      "      \"status\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"msg_68baabb5917481a2abc7d0639f8226b50a4857b25b5d767c\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"- 정책·법제에선 대만 디지털발전부의 5대 정책도구(컴퓨팅 파워·데이터·인재·마케팅·자금) 발표, OECD의 생성 AI를 범용기술로 본 생산성·정책 권고, 미 상원의 주정부 AI 규제 10년 유예 조항 삭제, 트럼프 행정부의 AI 행동계획·3개 행정명령 공표, EU의 AI법 범용 AI 실천 강령·지침 공개가 핵심입니다. \\n- 산업에선 미드저니 비디오 생성 ‘V1’ 출시, 바이두의 어니·딥시크 기반 AI 검색 대개편과 MCP 생태계 확장, 문샷AI의 에이전트형 오픈소스 ‘키미 K2’, xAI ‘그록 4’와 정부 시장 진출(국방부 계약), 퍼플렉시티의 에이전트 브라우저 ‘코멧’(한계 지적), 오픈AI의 복잡 업무를 수행하는 ‘챗GPT 에이전트’ 공개가 두드러졌습니다. \\n- 기술·연구·인력 측면에선 딥마인드 ‘알파게놈’, 구글 ‘메드젬마’, MS ‘MAI-DxO’ 등 의료·게놈 AI 진전과 사카나AI의 추론 시간 스케일링, 프린스턴·니케이의 AI 공개/프롬프트 은닉 이슈, METR의 숙련 개발자 생산성 둔화 등 혼재된 결과가 나타났고, 현장에선 일상적 AI 사용 급증(세일즈포스), 앤스로픽 ‘경제 미래 프로그램’ 출범, 딥마인드의 윈드서프 핵심 인력 영입과 코그니션의 인수 등으로 생태계 정비가 진행되고 있습니다.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 21525,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 1455,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 1024\n",
      "    },\n",
      "    \"total_tokens\": 22980\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=azure_openai_gpt5_deployment_name,\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"input_file\",\n",
    "                    \"file_id\":\"assistant-8StXmwbgba1Ke52mPt7AHs\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"input_text\",\n",
    "                    \"text\": \"Summarize this PDF in Korean in three sentences.\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - Background Task (async)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"resp_68baaca73eac8191be4d9c743a09c8c50bfaaa0cc82df074\",\n",
      "  \"created_at\": 1757064360.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": true,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"auto\",\n",
      "  \"status\": \"queued\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": null,\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model = azure_openai_gpt5_deployment_name,\n",
    "    input = \"Write me a bed time story (1min)\",\n",
    "    background = True\n",
    ")\n",
    "\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current status: queued\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current status: queued\n",
      "Current status: queued\n",
      "Current status: queued\n",
      "Final status: completed\n",
      "Output:\n",
      "Tonight, the moon props a silver ladder by your window. You climb it with a little yawn, and at the top waits Luma, a pocket-sized keeper of light with a lantern no bigger than a teardrop. Together you drift in a thistledown boat across the quiet sky, where stars hum like sleepy bees and clouds breathe slow and soft.\n",
      "\n",
      "Luma shows you jars of dreams, each glowing a different kind of gentle—vanilla, rain, warm bread, sunlight on closed eyes. You tip the dreams over rooftops, and the town below sighs as they fall like soft snow. An owl folds the night into its wings. A distant whale-shaped constellation hums a lullaby that twinkles through the air.\n",
      "\n",
      "When the lantern grows warm, Luma smiles. Time to float home before dawn slips a pale feather into the east. You climb down the silver ladder. Your bed is a small boat now, your pillow a cloud, your blanket a tide.\n",
      "\n",
      "Luma tucks one glimmer in your hand. If you wake, hold it close and know the dark is kind. The house listens. The stars close their eyes. Your breath is the sea.\n",
      "\n",
      "Good night.\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "while response.status in {\"queued\", \"in_progress\"}:\n",
    "    print(f\"Current status: {response.status}\")\n",
    "    sleep(2)\n",
    "    response = client.responses.retrieve(response.id)\n",
    "\n",
    "print(f\"Final status: {response.status}\\nOutput:\\n{response.output_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
