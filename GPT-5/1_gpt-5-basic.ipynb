{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-5 Basic Test Notebook (Azure OpenAI)\n",
    "\n",
    "This notebook provides examples of the Chat Completions API and the Responses API to quickly validate the basic functionality of GPT-5 in Azure OpenAI. It uses the Azure OpenAI endpoint, key, and deployment name configured in the environment variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "## Requirements\n",
    "\n",
    "- Python 3.10+\n",
    "- `pip install -r GPT-5/requirements.txt`\n",
    "- `GPT-5/.env` \n",
    "  - AZURE_OPENAI_ENDPOINT\n",
    "  - AZURE_OPENAI_API_KEY\n",
    "  - AZURE_OPENAI_API_VERSION\n",
    "  - AZURE_OPENAI_DEPLOYMENT_NAME\n",
    "\n",
    "## GPT-5 series model comparision \n",
    "Reference: https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/models?tabs=global-standard%2Cstandard-chat-completions \n",
    "\n",
    "| Model          | Chat Completions API | Responses API        | Structured Outputs API | Function / Tool Calling | Context Window |\n",
    "|---------------|-----------------------|----------------------|--------------------------|--------------------------------------|----------------|\n",
    "| **gpt-5**      | ✅                   | ✅                   | ✅                     | ✅                                   | 400,000        |\n",
    "| **gpt-5-mini** | ✅                   | ✅                   | ✅                     | ✅                                   | 400,000        |\n",
    "| **gpt-5-chat** | ✅                   | ✅                    | X                      | X                                     | 128,000        |\n",
    "\n",
    "> - gpt-5 and gpt-5-mini support Chat Completions API, Responses API, Structured Outputs API, and Function/Tool Calling (including parallel calls).\n",
    "> - As of September 8, 2025, gpt-5-chat (Preview) supports Chat Completions API and Responses API, but does not support Structured Outputs or Function/Tool Calling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Completions API Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Azure OpenAI Configuration ===\n",
      "Endpoint: https://hyo-ai-foundry-pjt1-resource.openai.azure.com/\n",
      "API Version: 2025-03-01-preview\n",
      "GPT-5 Deployment: gpt-5\n",
      "GPT-4.1 Deployment: gpt-4.1\n",
      "Embedding Deployment: text-embedding-ada-002\n",
      "API Key set: True\n",
      "Client initialized: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "import base64\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential, EnvironmentCredential\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "from io import BytesIO\n",
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "import json\n",
    "load_dotenv(override=True)\n",
    "\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\", \"\") if len(os.getenv(\"AZURE_OPENAI_API_KEY\", \"\")) > 0 else None\n",
    "azure_openai_gpt5_deployment_name = \"gpt-5-mini\" # can be \"gpt-5\" or \"gpt-5-chat\" or \"gpt-5-mini\"\n",
    "azure_openai_gpt41_deployment_name = \"gpt-4.1\"\n",
    "azure_openai_embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-ada-002\")\n",
    "aoai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"\") if len(os.getenv(\"AZURE_OPENAI_API_VERSION\", \"\")) > 0 else None\n",
    "\n",
    "try:\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=azure_openai_endpoint,\n",
    "        api_key=azure_openai_key,\n",
    "        api_version=aoai_api_version\n",
    "    )\n",
    "except (ValueError, TypeError) as e:\n",
    "    print(e)\n",
    "\n",
    "# Performance measurement utilities\n",
    "class PerformanceTimer:\n",
    "    def __init__(self, test_name):\n",
    "        self.test_name = test_name\n",
    "        self.start_time = None\n",
    "        \n",
    "    def __enter__(self):\n",
    "        self.start_time = time.time()\n",
    "        return self\n",
    "        \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        end_time = time.time()\n",
    "        self.execution_time = end_time - self.start_time\n",
    "        \n",
    "    def get_time(self):\n",
    "        return getattr(self, 'execution_time', None)\n",
    "\n",
    "def measure_and_compare(test_name, gpt5_func, gpt41_func):\n",
    "    \"\"\"Generic performance comparison for any test function\"\"\"\n",
    "    print(f\"\\n=== {test_name} Performance Comparison ===\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Test GPT-5\n",
    "    print(f\"\\n--- {azure_openai_gpt5_deployment_name} Results ---\")\n",
    "    try:\n",
    "        with PerformanceTimer(\"GPT-5\") as timer:\n",
    "            gpt5_result = gpt5_func()\n",
    "        results[\"GPT-5\"] = {\n",
    "            'time': timer.get_time(),\n",
    "            'result': gpt5_result,\n",
    "            'success': True\n",
    "        }\n",
    "        print(f\"Execution Time: {timer.get_time():.2f}s\")\n",
    "    except Exception as e:\n",
    "        results[\"GPT-5\"] = {'time': None, 'result': None, 'success': False, 'error': str(e)}\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    # Test GPT-4.1\n",
    "    print(f\"\\n--- {azure_openai_gpt41_deployment_name} Results ---\")\n",
    "    try:\n",
    "        with PerformanceTimer(\"GPT-4.1\") as timer:\n",
    "            gpt41_result = gpt41_func()\n",
    "        results[\"GPT-4.1\"] = {\n",
    "            'time': timer.get_time(),\n",
    "            'result': gpt41_result,\n",
    "            'success': True\n",
    "        }\n",
    "        print(f\"Execution Time: {timer.get_time():.2f}s\")\n",
    "    except Exception as e:\n",
    "        results[\"GPT-4.1\"] = {'time': None, 'result': None, 'success': False, 'error': str(e)}\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    # Comparison summary\n",
    "    if results[\"GPT-5\"]['success'] and results[\"GPT-4.1\"]['success']:\n",
    "        time_diff = results[\"GPT-5\"]['time'] - results[\"GPT-4.1\"]['time']\n",
    "        faster_model = \"GPT-5\" if time_diff < 0 else \"GPT-4.1\"\n",
    "        print(\"\\n--- Performance Summary ---\")\n",
    "        print(f\"{azure_openai_gpt5_deployment_name}: {results['GPT-5']['time']:.2f}s\")\n",
    "        print(f\"{azure_openai_gpt41_deployment_name}: {results['GPT-4.1']['time']:.2f}s\")\n",
    "        print(f\"Time Difference: {abs(time_diff):.2f}s ({faster_model} faster)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Print environment variables (excluding sensitive info)\n",
    "print(\"=== Azure OpenAI Configuration ===\")\n",
    "print(f\"Endpoint: {azure_openai_endpoint}\")\n",
    "print(f\"API Version: {aoai_api_version}\")\n",
    "print(f\"GPT-5 Deployment: {azure_openai_gpt5_deployment_name}\")\n",
    "print(f\"GPT-4.1 Deployment: {azure_openai_gpt41_deployment_name}\")\n",
    "print(f\"Embedding Deployment: {azure_openai_embedding_deployment}\")\n",
    "print(f\"API Key set: {azure_openai_key is not None}\")\n",
    "print(f\"Client initialized: {client is not None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Chat Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Basic Chat Performance Comparison ===\n",
      "\n",
      "--- gpt-5 Results ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here’s a concise overview of Microsoft (MSFT):\n",
      "\n",
      "- What it is: One of the world’s largest technology companies, founded in 1975 by Bill Gates and Paul Allen. Headquartered in Redmond, Washington. CEO: Satya Nadella (since 2014).\n",
      "\n",
      "- Scale: More than 220,000 employees worldwide and annual revenue well over $200 billion. Market capitalization surpassed $3 trillion in 2024. Microsoft pays a quarterly dividend and is a component of major stock indices.\n",
      "\n",
      "- Core businesses (reporting segments):\n",
      "  - Productivity and Business Processes: Microsoft 365 (Office apps and cloud services), Teams, Outlook/Exchange, SharePoint, OneDrive; LinkedIn; Dynamics 365 (ERP/CRM).\n",
      "  - Intelligent Cloud: Azure (IaaS, PaaS, AI/ML services), Windows Server, SQL Server, Enterprise services, GitHub and developer offerings.\n",
      "  - More Personal Computing: Windows client, Surface devices, Xbox hardware/services (including Game Pass), Bing/Ads, Microsoft Edge.\n",
      "\n",
      "- Cloud and AI:\n",
      "  - Azure is a leading global cloud platform competing with AWS and Google Cloud, offering compute, storage, databases, analytics, DevOps, security, and specialized services for regulated industries.\n",
      "  - AI has become central to Microsoft’s strategy: partnership with OpenAI; Azure OpenAI Service; Copilot experiences across Windows, GitHub, Microsoft 365, Dynamics, and security tools; Copilot Studio for building custom copilots.\n",
      "  - Custom silicon initiatives announced in 2023 include Maia (AI accelerator) and Cobalt (Arm-based CPU) to optimize AI and cloud workloads.\n",
      "  - In 2024, Microsoft introduced “Copilot+ PCs” with on-device NPUs and new Windows AI features; the proposed Recall feature drew privacy scrutiny and was paused for additional safeguards.\n",
      "\n",
      "- Software and developer ecosystem:\n",
      "  - Windows remains a dominant desktop OS; Windows 11 focuses on security, manageability, and AI features.\n",
      "  - Developer stack includes Visual Studio, .NET, GitHub, GitHub Copilot, Power Platform (Power BI, Power Apps, Power Automate), and Azure DevOps.\n",
      "  - Broad support for open source (e.g., GitHub, VS Code, contributions to Linux kernel and CNCF projects).\n",
      "\n",
      "- Gaming:\n",
      "  - Xbox consoles and services; Xbox Game Pass subscription; cloud gaming via Xbox Cloud Gaming (xCloud).\n",
      "  - Acquired Activision Blizzard in October 2023, adding franchises like Call of Duty, World of Warcraft, and Candy Crush (King).\n",
      "\n",
      "- Security:\n",
      "  - Portfolio includes Microsoft Defender, Sentinel SIEM, Entra (identity), Purview (compliance), and Intune (endpoint management).\n",
      "  - Following notable incidents (e.g., 2023 cloud email intrusion), Microsoft launched the Secure Future Initiative to strengthen engineering practices, identity controls, and cloud security; a 2024 U.S. review urged cultural and process improvements, which Microsoft committed to address.\n",
      "\n",
      "- Hardware:\n",
      "  - Surface PCs/tablets and accessories aimed at premium Windows experiences.\n",
      "  - Mixed reality efforts (HoloLens) have shifted toward enterprise/defense scenarios.\n",
      "\n",
      "- Ads and web:\n",
      "  - Bing search and Microsoft Advertising (including retail media and Xandr assets).\n",
      "  - Edge browser built on Chromium; privacy and enterprise management are positioning points.\n",
      "\n",
      "- Industry positioning and competition:\n",
      "  - Competes with Amazon (cloud/retail media), Google (cloud, productivity, search, ads), Apple (devices/OS), Salesforce (CRM), Oracle (databases/ERP), Sony/Nintendo (gaming), and cybersecurity vendors.\n",
      "  - Differentiators often cited: integrated cloud + productivity stack, enterprise relationships, and rapid AI productization.\n",
      "\n",
      "- Responsible AI and sustainability:\n",
      "  - Publishes responsible AI standards and impact assessments; offers tools like Azure AI Content Safety.\n",
      "  - Sustainability goals include being carbon negative, water positive, and zero waste by 2030, plus removing all historical emissions by 2050; invests heavily in renewable energy and carbon removal contracts.\n",
      "\n",
      "- Notable acquisitions (selected):\n",
      "  - LinkedIn (2016), GitHub (2018), Nuance (2021), Activision Blizzard (2023). Many smaller deals in security, AI, and cloud tooling.\n",
      "\n",
      "- Regulatory and legal context:\n",
      "  - Ongoing scrutiny globally around competition, app store practices, and AI/ cloud market power. Historical U.S. antitrust case in the late 1990s; more recently, EU and UK reviews of acquisitions and cloud practices.\n",
      "\n",
      "- How to learn more:\n",
      "  - microsoft.com and news.microsoft.com for product and corporate announcements\n",
      "  - investor.microsoft.com for annual reports, earnings, and segment detail\n",
      "  - learn.microsoft.com for technical documentation\n",
      "  - github.com/microsoft for open-source projects\n",
      "\n",
      "If you tell me your angle (investor, developer, job seeker, IT buyer, or general interest), I can tailor a deeper rundown and point you to the most relevant resources.\n",
      "Execution Time: 56.82s\n",
      "\n",
      "--- gpt-4.1 Results ---\n",
      "Certainly! Here's an overview of **Microsoft**:\n",
      "\n",
      "### What is Microsoft?\n",
      "**Microsoft Corporation** is a multinational technology company based in Redmond, Washington, USA. It is one of the world’s leading producers of computer software, consumer electronics, personal computers, and related services.\n",
      "\n",
      "### Key Facts\n",
      "\n",
      "- **Founded:** April 4, 1975\n",
      "- **Founders:** Bill Gates and Paul Allen\n",
      "- **CEO (as of 2024):** Satya Nadella\n",
      "- **Headquarters:** Redmond, Washington, USA\n",
      "\n",
      "### Major Products & Services\n",
      "\n",
      "- **Windows:** The world’s most widely used PC operating system.\n",
      "- **Microsoft Office:** Productivity suite (Word, Excel, PowerPoint, Outlook, etc.).\n",
      "- **Azure:** Cloud computing platform and services.\n",
      "- **Microsoft 365:** Subscription-based productivity services.\n",
      "- **Surface:** Line of personal computers, tablets, and accessories.\n",
      "- **Xbox:** Gaming consoles and related services.\n",
      "- **LinkedIn:** Professional networking platform, acquired by Microsoft in 2016.\n",
      "- **GitHub:** Platform for software development and version control.\n",
      "\n",
      "### Business Areas\n",
      "\n",
      "- Software development\n",
      "- Cloud computing\n",
      "- Hardware manufacturing\n",
      "- Gaming and entertainment\n",
      "- Internet services (search engines, advertising, etc.)\n",
      "\n",
      "### Influence & Innovations\n",
      "\n",
      "Microsoft pioneered the personal computing revolution in the 1980s and 1990s with MS-DOS and later Windows. It has continually evolved to focus on cloud computing, artificial intelligence, and modern workplace tools. Its acquisition strategy (e.g., buying LinkedIn, GitHub, and Activision Blizzard in 2023) has helped the company maintain dominance and diversify its offerings.\n",
      "\n",
      "### Financials & Market Position\n",
      "\n",
      "- One of only a few companies to exceed a $2 trillion market valuation (as of 2024).\n",
      "- Consistently ranked among the world’s most valuable and influential brands.\n",
      "\n",
      "### Social & Community Impact\n",
      "\n",
      "Microsoft emphasizes corporate social responsibility, with investments in philanthropy, digital inclusion, sustainability, and upskilling individuals through programs like Microsoft Philanthropies.\n",
      "\n",
      "---\n",
      "\n",
      "If you’d like more detailed information about any aspect of Microsoft—like its history, specific products, or recent developments—let me know!\n",
      "Execution Time: 5.90s\n",
      "\n",
      "--- Performance Summary ---\n",
      "gpt-5: 56.82s\n",
      "gpt-4.1: 5.90s\n",
      "Time Difference: 50.92s (GPT-4.1 faster)\n"
     ]
    }
   ],
   "source": [
    "# 1) Basic Chat Test with Performance Comparison\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Microsoft\"}\n",
    "]\n",
    "\n",
    "def test_basic_chat_gpt5():\n",
    "    response = client.chat.completions.create(\n",
    "        model=azure_openai_gpt5_deployment_name,\n",
    "        messages=messages,\n",
    "        reasoning_effort = \"low\"  # low, medium, or high\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def test_basic_chat_gpt41():\n",
    "    response = client.chat.completions.create(\n",
    "        model=azure_openai_gpt41_deployment_name,\n",
    "        messages=messages\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Performance comparison\n",
    "results = measure_and_compare(\"Basic Chat\", test_basic_chat_gpt5, test_basic_chat_gpt41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Calling Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Function Calling Performance Comparison ===\n",
      "\n",
      "--- gpt-5 Results ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function calling: get_weather({'city': 'Seoul'})\n",
      "function result: Clear, 22°C\n",
      "final response: It’s currently clear in Seoul, around 22°C. Would you like a forecast for the next few days?\n",
      "Execution Time: 5.94s\n",
      "\n",
      "--- gpt-4.1 Results ---\n",
      "function calling: get_weather({'city': 'Seoul'})\n",
      "function result: Clear, 22°C\n",
      "final response: The weather in Seoul is currently clear with a temperature of 22°C.\n",
      "Execution Time: 0.95s\n",
      "\n",
      "--- Performance Summary ---\n",
      "gpt-5: 5.94s\n",
      "gpt-4.1: 0.95s\n",
      "Time Difference: 4.98s (GPT-4.1 faster)\n"
     ]
    }
   ],
   "source": [
    "# 2) Function Calling Performance Comparison\n",
    "def get_weather(city: str):\n",
    "    \"\"\"Mock weather function\"\"\"\n",
    "    weather_data = {\n",
    "        \"Seoul\": \"Clear, 22°C\",\n",
    "        \"Busan\": \"Cloudy, 19°C\"\n",
    "    }\n",
    "    return weather_data.get(city, f\"{city}: Weather information not available\")\n",
    "\n",
    "# function schema\n",
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get weather for a city\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"city\": {\"type\": \"string\", \"description\": \"City name\"}\n",
    "            },\n",
    "            \"required\": [\"city\"]\n",
    "        }\n",
    "    }\n",
    "}]\n",
    "\n",
    "# query include function calling\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Tell me the weather in Seoul\"}\n",
    "]\n",
    "\n",
    "def test_function_calling_gpt5():\n",
    "    response = client.chat.completions.create(\n",
    "        model=azure_openai_gpt5_deployment_name,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\"\n",
    "    )\n",
    "    \n",
    "    # function call check and execution\n",
    "    if response.choices[0].message.tool_calls:\n",
    "        tool_call = response.choices[0].message.tool_calls[0]\n",
    "        function_name = tool_call.function.name\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        \n",
    "        print(f\"function calling: {function_name}({arguments})\")\n",
    "        \n",
    "        if function_name == \"get_weather\":\n",
    "            result = get_weather(arguments[\"city\"])\n",
    "            print(f\"function result: {result}\")\n",
    "\n",
    "            # generate final response with function result\n",
    "            final_messages = messages.copy()\n",
    "            final_messages.append(response.choices[0].message)\n",
    "            final_messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": result\n",
    "            })\n",
    "            \n",
    "            final_response = client.chat.completions.create(\n",
    "                model=azure_openai_gpt5_deployment_name,\n",
    "                messages=final_messages,\n",
    "                reasoning_effort = \"low\"  # low, medium, or high\n",
    "            )\n",
    "\n",
    "            print(f\"final response: {final_response.choices[0].message.content}\")\n",
    "            return final_response.choices[0].message.content\n",
    "    else:\n",
    "        print(f\"direct response: {response.choices[0].message.content}\")\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "def test_function_calling_gpt41():\n",
    "    response = client.chat.completions.create(\n",
    "        model=azure_openai_gpt41_deployment_name,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\"\n",
    "    )\n",
    "    \n",
    "    # function call check and execution\n",
    "    if response.choices[0].message.tool_calls:\n",
    "        tool_call = response.choices[0].message.tool_calls[0]\n",
    "        function_name = tool_call.function.name\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        \n",
    "        print(f\"function calling: {function_name}({arguments})\")\n",
    "        \n",
    "        if function_name == \"get_weather\":\n",
    "            result = get_weather(arguments[\"city\"])\n",
    "            print(f\"function result: {result}\")\n",
    "\n",
    "            # generate final response with function result\n",
    "            final_messages = messages.copy()\n",
    "            final_messages.append(response.choices[0].message)\n",
    "            final_messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": result\n",
    "            })\n",
    "            \n",
    "            final_response = client.chat.completions.create(\n",
    "                model=azure_openai_gpt41_deployment_name,\n",
    "                messages=final_messages\n",
    "            )\n",
    "\n",
    "            print(f\"final response: {final_response.choices[0].message.content}\")\n",
    "            return final_response.choices[0].message.content\n",
    "    else:\n",
    "        print(f\"direct response: {response.choices[0].message.content}\")\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "# Performance comparison\n",
    "results = measure_and_compare(\"Function Calling\", test_function_calling_gpt5, test_function_calling_gpt41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Output Test with Json Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Structured Output (JSON Schema) Performance Comparison ===\n",
      "\n",
      "--- gpt-5 Results ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"title\":\"Lenovo Legion Pro 5 (16-inch, 2024, RTX 4070)\",\"category\":\"Gaming Laptop\",\"price_krw\":2450000,\"pros\":[\"Strong 1440p gaming performance with RTX 4070 and latest Intel CPU\",\"Bright 16-inch QHD+ 240Hz display with good color coverage\",\"Sturdy build and comfortable keyboard with customizable RGB\",\"Efficient cooling maintains sustained performance under load\",\"Comprehensive port selection including USB-C and HDMI 2.1\"],\"cons\":[\"Heavier and bulkier than some competitors\",\"Mediocre battery life for everyday use\",\"Fans can get loud under heavy gaming loads\",\"No SD card slot; webcam quality is average\"]}\n",
      "Execution Time: 22.87s\n",
      "\n",
      "--- gpt-4.1 Results ---\n",
      "{\"title\":\"ASUS ROG Strix G16\",\"category\":\"Gaming Laptop\",\"price_krw\":2100000,\"pros\":[\"High-performance Intel Core i7-13650HX processor\",\"NVIDIA GeForce RTX 4060 graphics card\",\"Fast 165Hz FHD display\",\"Effective cooling system\",\"Stylish RGB keyboard\"],\"cons\":[\"Relatively bulky and heavy chassis\",\"Below-average battery life\",\"No Thunderbolt support\",\"Screen could be brighter\"]}\n",
      "Execution Time: 1.37s\n",
      "\n",
      "--- Performance Summary ---\n",
      "gpt-5: 22.87s\n",
      "gpt-4.1: 1.37s\n",
      "Time Difference: 21.49s (GPT-4.1 faster)\n"
     ]
    }
   ],
   "source": [
    "# 3) Structured Output Performance Comparison (Chat Completions API - JSON Schema)\n",
    "json_schema = {\n",
    "    \"name\": \"product_summary\",\n",
    "    \"schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"title\": {\"type\": \"string\"},\n",
    "            \"category\": {\"type\": \"string\"},\n",
    "            \"price_krw\": {\"type\": \"number\"},\n",
    "            \"pros\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "            \"cons\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "        },\n",
    "        \"required\": [\"title\", \"category\", \"price_krw\", \"pros\", \"cons\"], \n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "    \"strict\": True,\n",
    "}\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Pick a gaming laptop model randomly and generate a summary JSON. Include price in Korean Won with approximate values.\"}\n",
    "]\n",
    "\n",
    "def test_structured_output_gpt5():\n",
    "    response = client.chat.completions.create(\n",
    "        model=azure_openai_gpt5_deployment_name,\n",
    "        messages=messages,\n",
    "        response_format={\"type\": \"json_schema\", \"json_schema\": json_schema},\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def test_structured_output_gpt41():\n",
    "    response = client.chat.completions.create(\n",
    "        model=azure_openai_gpt41_deployment_name,\n",
    "        messages=messages,\n",
    "        response_format={\"type\": \"json_schema\", \"json_schema\": json_schema},\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Performance comparison\n",
    "results = measure_and_compare(\"Structured Output (JSON Schema)\", test_structured_output_gpt5, test_structured_output_gpt41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API (stateful chat for 30days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"resp_68be7e5ed01c819496fda3b2d3413829098ca9ac50ce8472\",\n",
      "  \"created_at\": 1757314654.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"rs_68be7e5f654c819480e49f6ba5b4b5f0098ca9ac50ce8472\",\n",
      "      \"summary\": [],\n",
      "      \"type\": \"reasoning\",\n",
      "      \"content\": null,\n",
      "      \"encrypted_content\": null,\n",
      "      \"status\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"msg_68be7e63703c8194be231385fb834c05098ca9ac50ce8472\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"I’m here and ready. What would you like to test or work on?\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 11,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 214,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 192\n",
      "    },\n",
      "    \"total_tokens\": 225\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(   \n",
    "  model=azure_openai_gpt5_deployment_name, \n",
    "  input=\"This is a test.\",\n",
    ")\n",
    "\n",
    "print(response.model_dump_json(indent=2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - List previous chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"id\": \"msg_68be60657c2c8194a339915244faadfe0d97914cd52a20b6\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"text\": \"This is a test.\",\n",
      "          \"type\": \"input_text\"\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"user\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"has_more\": false,\n",
      "  \"object\": \"list\",\n",
      "  \"first_id\": \"msg_68be60657c2c8194a339915244faadfe0d97914cd52a20b6\",\n",
      "  \"last_id\": \"msg_68be60657c2c8194a339915244faadfe0d97914cd52a20b6\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.input_items.list(\"resp_68be60657b208194a9c1549d18e9223a0d97914cd52a20b6\")\n",
    "\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - Upload PDF and analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded successfully:\n",
      "{\n",
      "  \"id\": \"assistant-RxiLmzhQLga3Q9wyF444f2\",\n",
      "  \"bytes\": 1165436,\n",
      "  \"created_at\": 1757314661,\n",
      "  \"filename\": \"AI_Brief_Aug2025.pdf\",\n",
      "  \"object\": \"file\",\n",
      "  \"purpose\": \"assistants\",\n",
      "  \"status\": \"processed\",\n",
      "  \"expires_at\": null,\n",
      "  \"status_details\": null\n",
      "}\n",
      "\n",
      "=== Responses API PDF Analysis Performance Comparison ===\n",
      "\n",
      "--- gpt-5 Results ---\n",
      "--- GPT-5 Responses API PDF Analysis ---\n",
      "{\n",
      "  \"id\": \"resp_68be7e669b148194b126ff03024d0dc608d12bbf65b0e1b4\",\n",
      "  \"created_at\": 1757314664.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"rs_68be7e69ee708194981bae4863b7d7da08d12bbf65b0e1b4\",\n",
      "      \"summary\": [],\n",
      "      \"type\": \"reasoning\",\n",
      "      \"content\": null,\n",
      "      \"encrypted_content\": null,\n",
      "      \"status\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"msg_68be7e9410d08194882845785c05f2f408d12bbf65b0e1b4\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"The August 2025 SPRi AI Brief reports major policy moves: Taiwan’s five‑pillar plan to grow its AI sector (compute, open data, talent, marketing, funding), the OECD’s view of generative AI as a general‑purpose technology requiring supportive and risk‑aware policy, the U.S. Senate’s removal of a 10‑year state AI‑regulation moratorium alongside the Trump administration’s AI Action Plan and executive orders, and the EU’s final GPAI Code of Practice and provider guidelines under the AI Act. Industry highlights include Midjourney’s low‑cost V1 image‑to‑video model, Baidu’s ERNIE/DeepSeek‑powered search revamp and MuseSteamer, Moonshot’s open‑source agentic Kimi K2, xAI’s Grok 4 (plus a government offering and DoD deal), Perplexity’s Comet agentic browser, and OpenAI’s ChatGPT Agent that completes complex web tasks with tools. Research and workforce notes cover DeepMind’s AlphaGenome, hidden “positive review” prompts in preprints, Sakana AI’s multi‑LLM inference‑time scaling, evidence that disclosing AI authorship lowers human and LLM ratings, Microsoft’s MAI‑DxO medical diagnosis agents and Google’s open‑source MedGemma, METR’s finding that AI can slow experienced developers, and rising workplace AI adoption, Anthropic’s Economic Futures Program, and DeepMind’s hiring of Windsurf talent.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 21525,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 1398,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 1088\n",
      "    },\n",
      "    \"total_tokens\": 22923\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "Execution Time: 57.67s\n",
      "\n",
      "--- gpt-4.1 Results ---\n",
      "--- GPT-4.1 Responses API PDF Analysis ---\n",
      "{\n",
      "  \"id\": \"resp_68be7ea061988194918297c6383b1c560b3840304ccc36e2\",\n",
      "  \"created_at\": 1757314722.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4.1\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"msg_68be7ea3c1688194a72666389284c31f0b3840304ccc36e2\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"This August 2025 SPRi AI Brief provides a comprehensive overview of the latest global trends in artificial intelligence across policy, industry, technology, research, talent, and education. Key developments include new policies and regulations from major governments and organizations (such as the US, EU, and OECD), significant product launches and advancements from leading AI companies (including OpenAI, Google, Midjourney, and Baidu), and research insights on AI’s economic, social, and workforce impacts. The brief also notes rapid growth in workplace AI adoption and features a calendar of major upcoming AI conferences worldwide.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 21526,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 21376\n",
      "    },\n",
      "    \"output_tokens\": 118,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 21644\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "Execution Time: 5.18s\n",
      "\n",
      "--- Performance Summary ---\n",
      "gpt-5: 57.67s\n",
      "gpt-4.1: 5.18s\n",
      "Time Difference: 52.49s (GPT-4.1 faster)\n"
     ]
    }
   ],
   "source": [
    "# Responses API PDF Upload and Analysis Performance Comparison\n",
    "# Upload a file with a purpose of \"assistants\"\n",
    "try:\n",
    "    file = client.files.create(\n",
    "      file=open(\"AI_Brief_Aug2025.pdf\", \"rb\"), # This assumes a .pdf file in the same directory as the executing script\n",
    "      purpose=\"assistants\"\n",
    "    )\n",
    "    print(\"File uploaded successfully:\")\n",
    "    print(file.model_dump_json(indent=2))\n",
    "    file_id = file.id\n",
    "    \n",
    "    def test_responses_pdf_analysis_gpt5():\n",
    "        response = client.responses.create(\n",
    "            model=azure_openai_gpt5_deployment_name,\n",
    "            input=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"input_file\",\n",
    "                            \"file_id\": file_id\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"input_text\",\n",
    "                            \"text\": \"Summarize this PDF in English in three sentences.\",\n",
    "                        },\n",
    "                    ],\n",
    "                },\n",
    "            ]\n",
    "        )\n",
    "        print(\"--- GPT-5 Responses API PDF Analysis ---\")\n",
    "        print(response.model_dump_json(indent=2))\n",
    "        return response.output_text if hasattr(response, 'output_text') else str(response.output)\n",
    "\n",
    "    def test_responses_pdf_analysis_gpt41():\n",
    "        response = client.responses.create(\n",
    "            model=azure_openai_gpt41_deployment_name,\n",
    "            input=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"input_file\",\n",
    "                            \"file_id\": file_id\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"input_text\",\n",
    "                            \"text\": \"Summarize this PDF in English in three sentences.\",\n",
    "                        },\n",
    "                    ],\n",
    "                },\n",
    "            ]\n",
    "        )\n",
    "        print(\"--- GPT-4.1 Responses API PDF Analysis ---\")\n",
    "        print(response.model_dump_json(indent=2))\n",
    "        return response.output_text if hasattr(response, 'output_text') else str(response.output)\n",
    "\n",
    "    # Performance comparison\n",
    "    results = measure_and_compare(\"Responses API PDF Analysis\", test_responses_pdf_analysis_gpt5, test_responses_pdf_analysis_gpt41)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"PDF file 'AI_Brief_Aug2025.pdf' not found. Please ensure the file exists in the current directory.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error uploading or processing PDF: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - Background Task (async)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"resp_68be7ea578f88195a24185c89125699f0d9b46b05a1c0d6e\",\n",
      "  \"created_at\": 1757314725.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": true,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"auto\",\n",
      "  \"status\": \"queued\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": null,\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model = azure_openai_gpt5_deployment_name,\n",
    "    input = \"Write me a bedtime story (1min)\",\n",
    "    background = True\n",
    ")\n",
    "\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current status: queued\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current status: queued\n",
      "Current status: queued\n",
      "Current status: queued\n",
      "Current status: queued\n",
      "Current status: queued\n",
      "Current status: queued\n",
      "Current status: queued\n",
      "Current status: queued\n",
      "Current status: queued\n",
      "Current status: queued\n",
      "Current status: queued\n",
      "Current status: queued\n",
      "Current status: queued\n",
      "Current status: queued\n",
      "Current status: queued\n",
      "Current status: queued\n",
      "Current status: queued\n",
      "Final status: completed\n",
      "Output:\n",
      "Each evening, when the sky turns the color of warm milk, a little moth named Luma lights her thimble-sized lantern. Inside it glows a drop of dew and a thread of moonlight, just enough to guide the sleepy world toward rest.\n",
      "\n",
      "She floats over the meadow where a young fawn’s knees still feel springy. Luma hums a soft, leaf-hush lullaby, and the lantern gathers the last bright bounce from the fawn’s eyes. The fawn sighs, folds its legs, and dreams of clover.\n",
      "\n",
      "By the stones, the brook keeps chattering about everywhere it has been. Luma dips the lantern close; the water takes a drowsy breath and begins to whisper instead.\n",
      "\n",
      "High on a branch, an owl blinks with thoughts too feathery to sort. Luma smooths the night around it like a blanket, and the owl rests one golden eye on the moon and lets it close.\n",
      "\n",
      "When the stars scatter like sugar, Luma carries one small sparkle to your window. She sets it beside your pillow and unfolds a quiet so soft it sounds like crickets knitting.\n",
      "\n",
      "“The world can wait,” she whispers. “Float now.”\n",
      "\n",
      "And the lantern’s little light rocks you gently across the dark, and into morning.\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "while response.status in {\"queued\", \"in_progress\"}:\n",
    "    print(f\"Current status: {response.status}\")\n",
    "    sleep(2)\n",
    "    response = client.responses.retrieve(response.id)\n",
    "\n",
    "print(f\"Final status: {response.status}\\nOutput:\\n{response.output_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - Function Calling Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Responses API Function Calling Performance Comparison ===\n",
      "\n",
      "--- gpt-5 Results ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- GPT-5 Responses API Function Calling ---\n",
      "{\n",
      "  \"id\": \"resp_68be7ece91e881909ac86fca4027a6b60ec983fd2c219773\",\n",
      "  \"created_at\": 1757314766.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"rs_68be7ecf18b88190bdf782e2b3787c5b0ec983fd2c219773\",\n",
      "      \"summary\": [],\n",
      "      \"type\": \"reasoning\",\n",
      "      \"content\": null,\n",
      "      \"encrypted_content\": null,\n",
      "      \"status\": null\n",
      "    },\n",
      "    {\n",
      "      \"arguments\": \"{\\\"location\\\":\\\"San Francisco\\\"}\",\n",
      "      \"call_id\": \"call_B83Ij3z0huV1QQyIX9xhDLBN\",\n",
      "      \"name\": \"get_weather\",\n",
      "      \"type\": \"function_call\",\n",
      "      \"id\": \"fc_68be7ed1b1d48190bb6dd2f0a2b58c8a0ec983fd2c219773\",\n",
      "      \"status\": \"completed\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"name\": \"get_weather\",\n",
      "      \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "          \"location\": {\n",
      "            \"type\": \"string\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"location\"\n",
      "        ],\n",
      "        \"additionalProperties\": false\n",
      "      },\n",
      "      \"strict\": true,\n",
      "      \"type\": \"function\",\n",
      "      \"description\": \"Get the weather for a location\"\n",
      "    }\n",
      "  ],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 50,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 149,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 128\n",
      "    },\n",
      "    \"total_tokens\": 199\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "--- GPT-5 Second Response ---\n",
      "{\n",
      "  \"id\": \"resp_68be7ed237cc819093176b61fac00b8e0ec983fd2c219773\",\n",
      "  \"created_at\": 1757314770.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"msg_68be7ed2cd6c8190bf34a9c85ed5ab6c0ec983fd2c219773\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"It’s about 70°F in San Francisco right now.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": \"resp_68be7ece91e881909ac86fca4027a6b60ec983fd2c219773\",\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 182,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 16,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 198\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "Execution Time: 5.14s\n",
      "\n",
      "--- gpt-4.1 Results ---\n",
      "--- GPT-4.1 Responses API Function Calling ---\n",
      "{\n",
      "  \"id\": \"resp_68be7ed3b6dc8196a9f215943edc351e0dc3261c9f605b95\",\n",
      "  \"created_at\": 1757314771.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4.1\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"arguments\": \"{\\\"location\\\":\\\"San Francisco\\\"}\",\n",
      "      \"call_id\": \"call_ik0iPm6hRzuWtgXpxbhrzGMh\",\n",
      "      \"name\": \"get_weather\",\n",
      "      \"type\": \"function_call\",\n",
      "      \"id\": \"fc_68be7ed4007881968b4e6aebc005dd4c0dc3261c9f605b95\",\n",
      "      \"status\": \"completed\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"name\": \"get_weather\",\n",
      "      \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "          \"location\": {\n",
      "            \"type\": \"string\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"location\"\n",
      "        ],\n",
      "        \"additionalProperties\": false\n",
      "      },\n",
      "      \"strict\": true,\n",
      "      \"type\": \"function\",\n",
      "      \"description\": \"Get the weather for a location\"\n",
      "    }\n",
      "  ],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 45,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 16,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 61\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "--- GPT-4.1 Second Response ---\n",
      "{\n",
      "  \"id\": \"resp_68be7ed45d688196bf6f0ca96f30dd130dc3261c9f605b95\",\n",
      "  \"created_at\": 1757314772.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4.1\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"msg_68be7ed4beb481969937010c7e53c6c40dc3261c9f605b95\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"Currently, the temperature in San Francisco is 70°F. Would you like a detailed forecast or more weather information?\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": \"resp_68be7ed3b6dc8196a9f215943edc351e0dc3261c9f605b95\",\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 45,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 24,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 69\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "Execution Time: 1.43s\n",
      "\n",
      "--- Performance Summary ---\n",
      "gpt-5: 5.14s\n",
      "gpt-4.1: 1.43s\n",
      "Time Difference: 3.70s (GPT-4.1 faster)\n"
     ]
    }
   ],
   "source": [
    "# Responses API Function Calling Performance Comparison\n",
    "tools_responses = [  \n",
    "    {  \n",
    "        \"type\": \"function\",  \n",
    "        \"name\": \"get_weather\",  \n",
    "        \"description\": \"Get the weather for a location\",  \n",
    "        \"parameters\": {  \n",
    "            \"type\": \"object\",  \n",
    "            \"properties\": {  \n",
    "                \"location\": {\"type\": \"string\"},  \n",
    "            },  \n",
    "            \"required\": [\"location\"],  \n",
    "        },  \n",
    "    }  \n",
    "]\n",
    "\n",
    "def test_responses_function_calling_gpt5():\n",
    "    response = client.responses.create(  \n",
    "        model=azure_openai_gpt5_deployment_name, \n",
    "        tools=tools_responses,\n",
    "        input=[{\"role\": \"user\", \"content\": \"What's the weather in San Francisco?\"}],  \n",
    "    )  \n",
    "    \n",
    "    print(\"--- GPT-5 Responses API Function Calling ---\")\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    \n",
    "    # To provide output to tools, add a response for each tool call to an array passed  \n",
    "    # to the next response as `input`  \n",
    "    input_data = []  \n",
    "    for output in response.output:  \n",
    "        if output.type == \"function_call\":  \n",
    "            match output.name:  \n",
    "                case \"get_weather\":  \n",
    "                    input_data.append(  \n",
    "                        {  \n",
    "                            \"type\": \"function_call_output\",  \n",
    "                            \"call_id\": output.call_id,  \n",
    "                            \"output\": '{\"temperature\": \"70 degrees\"}',  \n",
    "                        }  \n",
    "                    )  \n",
    "                case _:  \n",
    "                    raise ValueError(f\"Unknown function call: {output.name}\")  \n",
    "      \n",
    "    second_response = client.responses.create(  \n",
    "        model=azure_openai_gpt5_deployment_name,  \n",
    "        previous_response_id=response.id,  \n",
    "        input=input_data  \n",
    "    )  \n",
    "    \n",
    "    print(\"--- GPT-5 Second Response ---\")\n",
    "    print(second_response.model_dump_json(indent=2))\n",
    "    return second_response.output_text if hasattr(second_response, 'output_text') else str(second_response.output)\n",
    "\n",
    "def test_responses_function_calling_gpt41():\n",
    "    response = client.responses.create(  \n",
    "        model=azure_openai_gpt41_deployment_name, \n",
    "        tools=tools_responses,\n",
    "        input=[{\"role\": \"user\", \"content\": \"What's the weather in San Francisco?\"}],  \n",
    "    )  \n",
    "    \n",
    "    print(\"--- GPT-4.1 Responses API Function Calling ---\")\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    \n",
    "    # To provide output to tools, add a response for each tool call to an array passed  \n",
    "    # to the next response as `input`  \n",
    "    input_data = []  \n",
    "    for output in response.output:  \n",
    "        if output.type == \"function_call\":  \n",
    "            match output.name:  \n",
    "                case \"get_weather\":  \n",
    "                    input_data.append(  \n",
    "                        {  \n",
    "                            \"type\": \"function_call_output\",  \n",
    "                            \"call_id\": output.call_id,  \n",
    "                            \"output\": '{\"temperature\": \"70 degrees\"}',  \n",
    "                        }  \n",
    "                    )  \n",
    "                case _:  \n",
    "                    raise ValueError(f\"Unknown function call: {output.name}\")  \n",
    "      \n",
    "    second_response = client.responses.create(  \n",
    "        model=azure_openai_gpt41_deployment_name,  \n",
    "        previous_response_id=response.id,  \n",
    "        input=input_data  \n",
    "    )  \n",
    "    \n",
    "    print(\"--- GPT-4.1 Second Response ---\")\n",
    "    print(second_response.model_dump_json(indent=2))\n",
    "    return second_response.output_text if hasattr(second_response, 'output_text') else str(second_response.output)\n",
    "\n",
    "# Performance comparison\n",
    "results = measure_and_compare(\"Responses API Function Calling\", test_responses_function_calling_gpt5, test_responses_function_calling_gpt41) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - Structured Output Test with Json Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Responses API doen't support response_format.\n"
     ]
    }
   ],
   "source": [
    "# 5) Structured Output (Responses API - JSON Schema)\n",
    "# json_schema = {\n",
    "#     \"name\": \"product_summary\",\n",
    "#     \"schema\": {\n",
    "#         \"type\": \"object\",\n",
    "#         \"properties\": {\n",
    "#             \"title\": {\"type\": \"string\"},\n",
    "#             \"category\": {\"type\": \"string\"},\n",
    "#             \"price_krw\": {\"type\": \"number\"},\n",
    "#             \"pros\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "#             \"cons\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "#         },\n",
    "#         \"required\": [\"title\", \"category\", \"price_krw\"],\n",
    "#         \"additionalProperties\": False,\n",
    "#     },\n",
    "#     \"strict\": True,\n",
    "# }\n",
    "\n",
    "# inputs = [\n",
    "#     {\"role\": \"user\", \"content\": \"Pick a gaming laptop model randomly and generate a summary JSON. Include price in Korean Won with approximate values.\"}\n",
    "# ]\n",
    "\n",
    "# response = client.responses.create(\n",
    "#     model=azure_openai_gpt5_deployment_name,\n",
    "#     input=inputs,\n",
    "#     response_format={\"type\": \"json_schema\", \"json_schema\": json_schema},\n",
    "# )\n",
    "\n",
    "# print(response.model_dump_json(indent=2)) \n",
    "\n",
    "print(\"Responses API doen't support response_format.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - Streaming output Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Streaming Output Performance Comparison ===\n",
      "\n",
      "--- gpt-5 Results ---\n",
      "--- GPT-5 Streaming ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I told my smart fridge to make ice, and it sent me a calendar invite instead.\n",
      "The subject said, \"Let's circle back on your chilling needs.\"\n",
      "I replied, \"Just freeze water.\"\n",
      "It emailed, \"Per my last message, please find the attached ice forecast.\"\n",
      "Now my freezer is full of PDFs.\n",
      "Execution Time: 17.57s\n",
      "\n",
      "--- gpt-4.1 Results ---\n",
      "--- GPT-4.1 Streaming ---\n",
      "Why did the tomato turn red?  \n",
      "It saw the salad dressing!  \n",
      "The cucumber was so embarrassed,  \n",
      "The carrot turned beet red,  \n",
      "And the lettuce just leafed!\n",
      "Execution Time: 2.52s\n",
      "\n",
      "--- Performance Summary ---\n",
      "gpt-5: 17.57s\n",
      "gpt-4.1: 2.52s\n",
      "Time Difference: 15.05s (GPT-4.1 faster)\n"
     ]
    }
   ],
   "source": [
    "# 4) Streaming Output Performance Comparison\n",
    "def test_streaming_gpt5():\n",
    "    try:\n",
    "        print(\"--- GPT-5 Streaming ---\")\n",
    "        stream = client.chat.completions.create(\n",
    "            model=azure_openai_gpt5_deployment_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Tell me a five-line joke.\"}],\n",
    "            stream=True,\n",
    "        )\n",
    "        \n",
    "        content = \"\"\n",
    "        for chunk in stream:\n",
    "            if chunk.choices:\n",
    "                delta = chunk.choices[0].delta.content\n",
    "                if delta:\n",
    "                    print(delta, end=\"\", flush=True)\n",
    "                    content += delta\n",
    "                    time.sleep(0.05)\n",
    "        print()\n",
    "        return content\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Streaming error: {e}\")\n",
    "        return None\n",
    "\n",
    "def test_streaming_gpt41():\n",
    "    try:\n",
    "        print(\"--- GPT-4.1 Streaming ---\")\n",
    "        stream = client.chat.completions.create(\n",
    "            model=azure_openai_gpt41_deployment_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Tell me a five-line joke.\"}],\n",
    "            stream=True,\n",
    "        )\n",
    "        \n",
    "        content = \"\"\n",
    "        for chunk in stream:\n",
    "            if chunk.choices:\n",
    "                delta = chunk.choices[0].delta.content\n",
    "                if delta:\n",
    "                    print(delta, end=\"\", flush=True)\n",
    "                    content += delta\n",
    "                    time.sleep(0.05)\n",
    "        print()\n",
    "        return content\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Streaming error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Performance comparison\n",
    "results = measure_and_compare(\"Streaming Output\", test_streaming_gpt5, test_streaming_gpt41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - Code Interpreter Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Responses API Code Interpreter Performance Comparison ===\n",
      "\n",
      "--- gpt-5 Results ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- GPT-5 Responses API Code Interpreter ---\n",
      "{\n",
      "  \"id\": \"resp_68be7ee943f081959fa0f78de2adb16e08b4776c58f6eeef\",\n",
      "  \"created_at\": 1757314793.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": \"You are a personal math tutor. When asked a math question, write and run code using the python tool to answer the question.\",\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"rs_68be7eec19cc81959cf36e1c2d42fb8908b4776c58f6eeef\",\n",
      "      \"summary\": [],\n",
      "      \"type\": \"reasoning\",\n",
      "      \"content\": null,\n",
      "      \"encrypted_content\": null,\n",
      "      \"status\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ci_68be7eeff2a0819585bedffb0a7f911908b4776c58f6eeef\",\n",
      "      \"code\": \"# Solve 3x + 11 = 14\\r\\nx = (14 - 11) / 3\\r\\nx\",\n",
      "      \"container_id\": \"cntr_68be7ee9f3ac8190a78cd3d9c3ec72eb0d07b8dd4686997a\",\n",
      "      \"outputs\": null,\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"code_interpreter_call\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"msg_68be7ef1b4808195a4e48bd24e078cea08b4776c58f6eeef\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"x = 1\\n\\nExplanation:\\n- Subtract 11 from both sides: 3x = 14 − 11 = 3\\n- Divide by 3: x = 3 / 3 = 1\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"container\": {\n",
      "        \"type\": \"auto\",\n",
      "        \"file_ids\": null\n",
      "      },\n",
      "      \"type\": \"code_interpreter\"\n",
      "    }\n",
      "  ],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 1635,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 241,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 192\n",
      "    },\n",
      "    \"total_tokens\": 1876\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "Execution Time: 9.57s\n",
      "\n",
      "--- gpt-4.1 Results ---\n",
      "--- GPT-4.1 Responses API Code Interpreter ---\n",
      "{\n",
      "  \"id\": \"resp_68be7ef2d6148195817ded7b3648f68b006eb21a6266a9e2\",\n",
      "  \"created_at\": 1757314802.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": \"You are a personal math tutor. When asked a math question, write and run code using the python tool to answer the question.\",\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4.1\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"ci_68be7ef504d88195b58af202e4217c5a006eb21a6266a9e2\",\n",
      "      \"code\": \"from sympy import symbols, Eq, solve\\n\\n# Define the variable\\nx = symbols('x')\\n\\n# Define the equation\\nequation = Eq(3*x + 11, 14)\\n\\n# Solve the equation\\nsolution = solve(equation, x)\\nsolution\",\n",
      "      \"container_id\": \"cntr_68be7ef3aef88190b2d534c8e314405906cab502dc8c0509\",\n",
      "      \"outputs\": null,\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"code_interpreter_call\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"msg_68be7ef6ad708195ad095a26a8775fc4006eb21a6266a9e2\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"The solution to the equation \\\\( 3x + 11 = 14 \\\\) is \\\\( x = 1 \\\\).\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"container\": {\n",
      "        \"type\": \"auto\",\n",
      "        \"file_ids\": null\n",
      "      },\n",
      "      \"type\": \"code_interpreter\"\n",
      "    }\n",
      "  ],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 466,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 88,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 554\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "Execution Time: 4.63s\n",
      "\n",
      "--- Performance Summary ---\n",
      "gpt-5: 9.57s\n",
      "gpt-4.1: 4.63s\n",
      "Time Difference: 4.94s (GPT-4.1 faster)\n"
     ]
    }
   ],
   "source": [
    "# Responses API Code Interpreter Performance Comparison\n",
    "instructions = \"You are a personal math tutor. When asked a math question, write and run code using the python tool to answer the question.\"\n",
    "\n",
    "tools_code_interpreter = [\n",
    "    {\n",
    "        \"type\": \"code_interpreter\",\n",
    "        \"container\": {\"type\": \"auto\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "math_question = \"I need to solve the equation 3x + 11 = 14. Can you help me?\"\n",
    "\n",
    "def test_responses_code_interpreter_gpt5():\n",
    "    response = client.responses.create(\n",
    "        model=azure_openai_gpt5_deployment_name,\n",
    "        tools=tools_code_interpreter,\n",
    "        instructions=instructions,\n",
    "        input=math_question,\n",
    "    )\n",
    "    print(\"--- GPT-5 Responses API Code Interpreter ---\")\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    return response.output_text if hasattr(response, 'output_text') else str(response.output)\n",
    "\n",
    "def test_responses_code_interpreter_gpt41():\n",
    "    response = client.responses.create(\n",
    "        model=azure_openai_gpt41_deployment_name,\n",
    "        tools=tools_code_interpreter,\n",
    "        instructions=instructions,\n",
    "        input=math_question,\n",
    "    )\n",
    "    print(\"--- GPT-4.1 Responses API Code Interpreter ---\")\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    return response.output_text if hasattr(response, 'output_text') else str(response.output)\n",
    "\n",
    "# Performance comparison\n",
    "results = measure_and_compare(\"Responses API Code Interpreter\", test_responses_code_interpreter_gpt5, test_responses_code_interpreter_gpt41) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - Vision Support Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Responses API Vision Support Performance Comparison ===\n",
      "\n",
      "--- gpt-5 Results ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- GPT-5 Responses API Vision ---\n",
      "{\n",
      "  \"id\": \"resp_68be7ef77bec81958ca597b6aa45acbb05b0a0d8fd8a6c2b\",\n",
      "  \"created_at\": 1757314807.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"rs_68be7ef9ad408195a313635f2050be1105b0a0d8fd8a6c2b\",\n",
      "      \"summary\": [],\n",
      "      \"type\": \"reasoning\",\n",
      "      \"content\": null,\n",
      "      \"encrypted_content\": null,\n",
      "      \"status\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"msg_68be7efdac04819584088932975b2e5905b0a0d8fd8a6c2b\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"- Panoramic view of rugged, green mountains with steep cliffs and forested slopes.  \\n- Rolling meadows and small settlements scattered across the valleys below.  \\n- Clear blue sky with fluffy clouds above an alpine landscape.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 371,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 115,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 64\n",
      "    },\n",
      "    \"total_tokens\": 486\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "Execution Time: 8.68s\n",
      "\n",
      "--- gpt-4.1 Results ---\n",
      "--- GPT-4.1 Responses API Vision ---\n",
      "{\n",
      "  \"id\": \"resp_68be7f002f608190aba21943d247a81207e968720e6ccc02\",\n",
      "  \"created_at\": 1757314816.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4.1\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"msg_68be7f013f708190bcb8fb0f12643b1a07e968720e6ccc02\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"The image shows a lush, green mountain range under a bright blue sky with scattered clouds. The mountains have steep, rocky faces and are surrounded by forested areas and green valleys. Small patches of settlement or farmland can be seen at the base of the mountains.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 447,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 53,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 500\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "Execution Time: 2.08s\n",
      "\n",
      "--- Performance Summary ---\n",
      "gpt-5: 8.68s\n",
      "gpt-4.1: 2.08s\n",
      "Time Difference: 6.60s (GPT-4.1 faster)\n"
     ]
    }
   ],
   "source": [
    "# Responses API Vision Support Performance Comparison\n",
    "# Note: Requires the deployed model to support vision and your API version to allow image input.\n",
    "image_url = os.getenv(\"TEST_IMAGE_URL\", \"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Fronalpstock_big.jpg/640px-Fronalpstock_big.jpg\")\n",
    "\n",
    "inputs = [\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"input_text\", \"text\": \"Summarize the main features of this image in three lines in English.\"},\n",
    "        {\"type\": \"input_image\", \"image_url\": image_url},\n",
    "    ]}\n",
    "]\n",
    "\n",
    "def test_responses_vision_gpt5():\n",
    "    response = client.responses.create(\n",
    "        model=azure_openai_gpt5_deployment_name, \n",
    "        input=inputs\n",
    "    )\n",
    "    print(\"--- GPT-5 Responses API Vision ---\")\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    return response.output_text if hasattr(response, 'output_text') else str(response.output)\n",
    "\n",
    "def test_responses_vision_gpt41():\n",
    "    response = client.responses.create(\n",
    "        model=azure_openai_gpt41_deployment_name, \n",
    "        input=inputs\n",
    "    )\n",
    "    print(\"--- GPT-4.1 Responses API Vision ---\")\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    return response.output_text if hasattr(response, 'output_text') else str(response.output)\n",
    "\n",
    "# Performance comparison\n",
    "results = measure_and_compare(\"Responses API Vision Support\", test_responses_vision_gpt5, test_responses_vision_gpt41)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
