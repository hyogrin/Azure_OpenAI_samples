{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-5 Basic Test Notebook (Azure OpenAI)\n",
    "\n",
    "This notebook provides examples of the Chat Completions API and the Responses API to quickly validate the basic functionality of GPT-5 in Azure OpenAI. It uses the Azure OpenAI endpoint, key, and deployment name configured in the environment variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "## Requirements\n",
    "\n",
    "- Python 3.10+\n",
    "- `pip install -r GPT-5/requirements.txt`\n",
    "- `GPT-5/.env` \n",
    "  - AZURE_OPENAI_ENDPOINT\n",
    "  - AZURE_OPENAI_API_KEY\n",
    "  - AZURE_OPENAI_API_VERSION\n",
    "  - AZURE_OPENAI_DEPLOYMENT_NAME\n",
    "\n",
    "## GPT-5 series model comparision \n",
    "Reference: https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/models?tabs=global-standard%2Cstandard-chat-completions \n",
    "\n",
    "| Model           | Reasoning Support       | Chat Completions API | Responses API | Structured Outputs | Function/Tool Calling     | Context Window (tokens)     | Price per 1M tokens (input/output) |\n",
    "|-----------------|-------------------------|----------------------|---------------|--------------------|---------------------------|-----------------------------|------------------------------------|\n",
    "| **GPT-5**       | ✅​                     | ✅​                  | ✅​           | ✅​                | ✅​                        | 400,000 (272k in + 128k out) | $1.25 / $10                        |\n",
    "| **GPT-5-mini**  | ✅​                     | ✅​                  | ✅​           | ✅​                | ✅​                       | 400,000 (272k in + 128k out) | $0.25 / $2.00                      |\n",
    "| **GPT-5-nano**  | ✅​                     | ✅​                  | ✅​           | ✅​                | ✅​                       | 400,000 (272k in + 128k out) | $0.05 / $0.40                      |\n",
    "| **GPT-5-chat**  | 〰️ (undocumented)      | ✅​                  | ✅​           | 〰️ (undocumented)   | 〰️ (undocumented)          | 128,000 (16k max output)     | $1.25 / $10                        |\n",
    "| **GPT-4.1**     | ✅​                     | ✅​                  | ✅​           | ✅​                | ✅​                       | 1,000,000                   | $2.00 / $8.00                      |\n",
    "| **GPT-4.1-mini**| ✅​                     | ✅​                  | ✅​           | ✅​                | ✅​                       | 1,000,000                   | $0.40 / $1.60                      |\n",
    "| **GPT-4.1-nano**| ✅​                     | ✅​                  | ✅​           | ✅​                | ✅​                       | 1,000,000                   | $0.10 / $0.40                      |\n",
    "| **GPT-4o**      | ✅​                     | ✅​                  | 〰️ (undocumented) | ✅​           | ✅​                        | 128,000 (+16k out)          | $5.00 / $15.00                     |\n",
    "\n",
    "\n",
    "> - gpt-5 series models support Reasoning, Chat Completions API, Responses API, Structured Outputs API, and Function/Tool Calling (including parallel calls).\n",
    "> - As of September 8, 2025, gpt-5-chat (Preview) supports Chat Completions API and Responses API, but does not support Reasoning, Structured Outputs or Function/Tool Calling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Completions API Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Azure OpenAI Configuration ===\n",
      "Endpoint: https://hyo-ai-foundry-pjt1-resource.openai.azure.com/\n",
      "API Version: 2025-03-01-preview\n",
      "GPT-5 Deployment: gpt-5-mini\n",
      "GPT-4.1 Deployment: gpt-4.1\n",
      "Embedding Deployment: text-embedding-ada-002\n",
      "API Key set: True\n",
      "Client initialized: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "import base64\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential, EnvironmentCredential\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "from io import BytesIO\n",
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "import json\n",
    "load_dotenv(override=True)\n",
    "\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\", \"\") if len(os.getenv(\"AZURE_OPENAI_API_KEY\", \"\")) > 0 else None\n",
    "azure_openai_gpt5_deployment_name = \"gpt-5-mini\" # can be \"gpt-5\" or \"gpt-5-chat\" or \"gpt-5-mini\"\n",
    "azure_openai_gpt41_deployment_name = \"gpt-4.1\"  # can be \"gpt-4.1\" or \"gpt-4.1-mini\" or \"gpt-4o\"\n",
    "azure_openai_embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-ada-002\")\n",
    "aoai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"\") if len(os.getenv(\"AZURE_OPENAI_API_VERSION\", \"\")) > 0 else None\n",
    "\n",
    "try:\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=azure_openai_endpoint,\n",
    "        api_key=azure_openai_key,\n",
    "        api_version=aoai_api_version\n",
    "    )\n",
    "except (ValueError, TypeError) as e:\n",
    "    print(e)\n",
    "\n",
    "# Performance measurement utilities\n",
    "class PerformanceTimer:\n",
    "    def __init__(self, test_name):\n",
    "        self.test_name = test_name\n",
    "        self.start_time = None\n",
    "        \n",
    "    def __enter__(self):\n",
    "        self.start_time = time.time()\n",
    "        return self\n",
    "        \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        end_time = time.time()\n",
    "        self.execution_time = end_time - self.start_time\n",
    "        \n",
    "    def get_time(self):\n",
    "        return getattr(self, 'execution_time', None)\n",
    "\n",
    "def measure_and_compare(test_name, gpt5_func, gpt41_func):\n",
    "    \"\"\"Generic performance comparison for any test function\"\"\"\n",
    "    print(f\"\\n=== {test_name} Performance Comparison ===\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Test GPT-5\n",
    "    print(f\"\\n--- {azure_openai_gpt5_deployment_name} Results ---\")\n",
    "    try:\n",
    "        with PerformanceTimer(\"GPT-5\") as timer:\n",
    "            gpt5_result = gpt5_func()\n",
    "        results[\"GPT-5\"] = {\n",
    "            'time': timer.get_time(),\n",
    "            'result': gpt5_result,\n",
    "            'success': True\n",
    "        }\n",
    "        print(f\"Execution Time: {timer.get_time():.2f}s\")\n",
    "    except Exception as e:\n",
    "        results[\"GPT-5\"] = {'time': None, 'result': None, 'success': False, 'error': str(e)}\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    # Test GPT-4.1\n",
    "    print(f\"\\n--- {azure_openai_gpt41_deployment_name} Results ---\")\n",
    "    try:\n",
    "        with PerformanceTimer(\"GPT-4.1\") as timer:\n",
    "            gpt41_result = gpt41_func()\n",
    "        results[\"GPT-4.1\"] = {\n",
    "            'time': timer.get_time(),\n",
    "            'result': gpt41_result,\n",
    "            'success': True\n",
    "        }\n",
    "        print(f\"Execution Time: {timer.get_time():.2f}s\")\n",
    "    except Exception as e:\n",
    "        results[\"GPT-4.1\"] = {'time': None, 'result': None, 'success': False, 'error': str(e)}\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    # Comparison summary\n",
    "    if results[\"GPT-5\"]['success'] and results[\"GPT-4.1\"]['success']:\n",
    "        time_diff = results[\"GPT-5\"]['time'] - results[\"GPT-4.1\"]['time']\n",
    "        faster_model = \"GPT-5\" if time_diff < 0 else \"GPT-4.1\"\n",
    "        print(\"\\n--- Performance Summary ---\")\n",
    "        print(f\"{azure_openai_gpt5_deployment_name}: {results['GPT-5']['time']:.2f}s\")\n",
    "        print(f\"{azure_openai_gpt41_deployment_name}: {results['GPT-4.1']['time']:.2f}s\")\n",
    "        print(f\"Time Difference: {abs(time_diff):.2f}s ({faster_model} faster)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Print environment variables (excluding sensitive info)\n",
    "print(\"=== Azure OpenAI Configuration ===\")\n",
    "print(f\"Endpoint: {azure_openai_endpoint}\")\n",
    "print(f\"API Version: {aoai_api_version}\")\n",
    "print(f\"GPT-5 Deployment: {azure_openai_gpt5_deployment_name}\")\n",
    "print(f\"GPT-4.1 Deployment: {azure_openai_gpt41_deployment_name}\")\n",
    "print(f\"Embedding Deployment: {azure_openai_embedding_deployment}\")\n",
    "print(f\"API Key set: {azure_openai_key is not None}\")\n",
    "print(f\"Client initialized: {client is not None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Chat Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Basic Chat Performance Comparison ===\n",
      "\n",
      "--- gpt-5-mini Results ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Corporation is an American multinational technology company founded in 1975 by Bill Gates and Paul Allen. Headquartered in Redmond, Washington, it’s one of the world’s largest and most influential tech companies, known for software, cloud computing, hardware, gaming, developer tools, and many enterprise services.\n",
      "\n",
      "Key leadership and business focus\n",
      "- CEO: Satya Nadella (since 2014). Under his leadership Microsoft shifted strongly toward cloud services, subscription models, and enterprise AI.\n",
      "- Core strategy: cloud-first, AI-first — heavy investment in Microsoft Azure cloud platform and integrating AI capabilities across products.\n",
      "\n",
      "Major products and services\n",
      "- Windows: the company’s flagship desktop operating system (Windows 10, Windows 11).\n",
      "- Microsoft 365 (formerly Office 365): subscription suite including Word, Excel, PowerPoint, Outlook, Teams, and OneDrive.\n",
      "- Azure: cloud computing platform providing infrastructure-as-a-service (IaaS), platform-as-a-service (PaaS), and many managed services used by enterprises worldwide.\n",
      "- LinkedIn: professional networking platform (acquired 2016).\n",
      "- GitHub: developer platform for source code hosting and collaboration (acquired 2018).\n",
      "- Xbox: gaming hardware and services ecosystem, including Xbox consoles, Game Pass subscription service, and first-party studios.\n",
      "- Surface: line of Microsoft-designed PCs and tablets.\n",
      "- Dynamics 365 and Power Platform: enterprise CRM/ERP and low-code/no-code business application platforms.\n",
      "- AI initiatives: Microsoft integrates AI into many products (Copilot in Office, Azure AI services) and maintains a strategic partnership with OpenAI.\n",
      "\n",
      "Business structure and finances\n",
      "- Microsoft reports revenue across segments like Productivity and Business Processes (Office, LinkedIn), Intelligent Cloud (Azure, server products), and More Personal Computing (Windows, Surface, Xbox). It’s consistently among the most valuable public companies by market capitalization and generates substantial, recurring revenue from cloud and subscription services.\n",
      "\n",
      "Notable acquisitions and partnerships\n",
      "- Major acquisitions include LinkedIn, GitHub, and numerous gaming studios. Microsoft is an active acquirer to expand cloud, AI, and gaming capabilities.\n",
      "- Strategic partnerships include a long-term collaboration with OpenAI to bring advanced AI models to Azure and Microsoft products.\n",
      "\n",
      "Regulation and controversies\n",
      "- Microsoft has faced regulatory scrutiny historically (1990s/2000s antitrust cases) and occasionally over privacy, competition, and acquisitions. Ongoing large tech regulatory attention affects its business decisions.\n",
      "\n",
      "Workforce, culture, and social initiatives\n",
      "- Large global workforce (hundreds of thousands of employees). Nadella’s tenure emphasized cultural change toward empathy, collaboration, and growth mindset.\n",
      "- Corporate social responsibility includes sustainability commitments, accessibility work, philanthropic grants, and technology for civic use.\n",
      "\n",
      "How people interact with Microsoft\n",
      "- Consumers use Windows, Office apps, Xbox, Surface devices.\n",
      "- Businesses and developers use Azure, Microsoft 365, Dynamics, Power Platform, and GitHub.\n",
      "- Many enterprises rely on Microsoft for infrastructure, productivity, collaboration, security, and developer tooling.\n",
      "\n",
      "If you want, I can:\n",
      "- Summarize Microsoft’s recent financial results and market performance (through mid-2024).\n",
      "- Explain Azure’s services or pricing basics.\n",
      "- Compare Microsoft 365 plans or Windows editions.\n",
      "- Detail Microsoft’s AI products and how to use Copilot. Which would you like?\n",
      "Execution Time: 6.91s\n",
      "\n",
      "--- gpt-4.1 Results ---\n",
      "Certainly! Here’s an overview of **Microsoft**:\n",
      "\n",
      "**Microsoft Corporation** is one of the world’s largest and most influential technology companies. Founded in 1975 by Bill Gates and Paul Allen in Albuquerque, New Mexico, Microsoft revolutionized the personal computer industry with its software offerings, most notably the Windows operating system and Microsoft Office productivity suite.\n",
      "\n",
      "### 1. Key Products and Services\n",
      "- **Windows:** The Windows operating system dominates desktop computers worldwide.\n",
      "- **Microsoft Office:** A suite of productivity tools including Word, Excel, PowerPoint, and Outlook.\n",
      "- **Azure:** Microsoft’s cloud computing platform, providing a wide range of services including AI, analytics, storage, and networking.\n",
      "- **Surface:** Hardware products including laptops, tablets, and hybrid devices.\n",
      "- **Xbox:** A leading gaming console and related services.\n",
      "- **LinkedIn:** A professional networking platform, acquired in 2016.\n",
      "- **GitHub:** A code repository platform for developers, acquired in 2018.\n",
      "- **Teams:** Collaboration and video conferencing tool, part of Microsoft 365.\n",
      "\n",
      "### 2. Recent Activities (as of 2024)\n",
      "- Heavy investment in artificial intelligence (e.g., partnership with OpenAI, AI integration in Bing, Office, and more).\n",
      "- Expansion of cloud services with Azure, now a market leader alongside AWS and Google Cloud.\n",
      "- Development of Copilot, an AI assistant integrated into Office, Windows, and other Microsoft products.\n",
      "- Increased focus on cybersecurity.\n",
      "- Continues to acquire and invest in companies to expand its reach (e.g., pending acquisition of Activision Blizzard).\n",
      "\n",
      "### 3. Leadership\n",
      "- **Satya Nadella** is the current Chairman and CEO, having been in the role since 2014. Under his leadership, Microsoft has embraced cloud computing and AI, leading to significant business growth.\n",
      "\n",
      "### 4. Financials & Scale\n",
      "- Microsoft is one of the world’s most valuable companies, frequently trading places with Apple for the title of the largest market capitalization.\n",
      "- Operates globally with offices, data centers, and subsidiaries in numerous countries.\n",
      "\n",
      "### 5. Corporate Responsibility\n",
      "Microsoft emphasizes sustainability, accessibility, and diversity. The company has set ambitious goals for carbon negativity and aims to empower people and organizations everywhere to achieve more.\n",
      "\n",
      "### Fun Fact\n",
      "The company’s name comes from “microcomputer software.”\n",
      "\n",
      "If you’d like more information about a specific Microsoft product, history, leadership, or future plans, let me know!\n",
      "Execution Time: 5.42s\n",
      "\n",
      "--- Performance Summary ---\n",
      "gpt-5-mini: 6.91s\n",
      "gpt-4.1: 5.42s\n",
      "Time Difference: 1.49s (GPT-4.1 faster)\n"
     ]
    }
   ],
   "source": [
    "# 1) Basic Chat Test with Performance Comparison\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Microsoft\"}\n",
    "]\n",
    "\n",
    "def test_basic_chat_gpt5():\n",
    "    response = client.chat.completions.create(\n",
    "        model=azure_openai_gpt5_deployment_name,\n",
    "        messages=messages,\n",
    "        reasoning_effort = \"low\"  # low, medium, or high\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def test_basic_chat_gpt41():\n",
    "    response = client.chat.completions.create(\n",
    "        model=azure_openai_gpt41_deployment_name,\n",
    "        messages=messages\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Performance comparison\n",
    "results = measure_and_compare(\"Basic Chat\", test_basic_chat_gpt5, test_basic_chat_gpt41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Calling Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Function Calling Performance Comparison ===\n",
      "\n",
      "--- gpt-5-mini Results ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function calling: get_weather({'city': 'Seoul'})\n",
      "function result: Clear, 22°C\n",
      "final response: Right now in Seoul it's clear and 22°C. Would you like a forecast for today or the next few days?\n",
      "Execution Time: 2.59s\n",
      "\n",
      "--- gpt-4.1 Results ---\n",
      "function calling: get_weather({'city': 'Seoul'})\n",
      "function result: Clear, 22°C\n",
      "final response: The current weather in Seoul is clear with a temperature of 22°C. Let me know if you need a forecast or more details!\n",
      "Execution Time: 0.97s\n",
      "\n",
      "--- Performance Summary ---\n",
      "gpt-5-mini: 2.59s\n",
      "gpt-4.1: 0.97s\n",
      "Time Difference: 1.62s (GPT-4.1 faster)\n"
     ]
    }
   ],
   "source": [
    "# 2) Function Calling Performance Comparison\n",
    "def get_weather(city: str):\n",
    "    \"\"\"Mock weather function\"\"\"\n",
    "    weather_data = {\n",
    "        \"Seoul\": \"Clear, 22°C\",\n",
    "        \"Busan\": \"Cloudy, 19°C\"\n",
    "    }\n",
    "    return weather_data.get(city, f\"{city}: Weather information not available\")\n",
    "\n",
    "# function schema\n",
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get weather for a city\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"city\": {\"type\": \"string\", \"description\": \"City name\"}\n",
    "            },\n",
    "            \"required\": [\"city\"]\n",
    "        }\n",
    "    }\n",
    "}]\n",
    "\n",
    "# query include function calling\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Tell me the weather in Seoul\"}\n",
    "]\n",
    "\n",
    "def test_function_calling_gpt5():\n",
    "    response = client.chat.completions.create(\n",
    "        model=azure_openai_gpt5_deployment_name,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\"\n",
    "    )\n",
    "    \n",
    "    # function call check and execution\n",
    "    if response.choices[0].message.tool_calls:\n",
    "        tool_call = response.choices[0].message.tool_calls[0]\n",
    "        function_name = tool_call.function.name\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        \n",
    "        print(f\"function calling: {function_name}({arguments})\")\n",
    "        \n",
    "        if function_name == \"get_weather\":\n",
    "            result = get_weather(arguments[\"city\"])\n",
    "            print(f\"function result: {result}\")\n",
    "\n",
    "            # generate final response with function result\n",
    "            final_messages = messages.copy()\n",
    "            final_messages.append(response.choices[0].message)\n",
    "            final_messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": result\n",
    "            })\n",
    "            \n",
    "            final_response = client.chat.completions.create(\n",
    "                model=azure_openai_gpt5_deployment_name,\n",
    "                messages=final_messages,\n",
    "                reasoning_effort = \"low\"  # low, medium, or high\n",
    "            )\n",
    "\n",
    "            print(f\"final response: {final_response.choices[0].message.content}\")\n",
    "            return final_response.choices[0].message.content\n",
    "    else:\n",
    "        print(f\"direct response: {response.choices[0].message.content}\")\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "def test_function_calling_gpt41():\n",
    "    response = client.chat.completions.create(\n",
    "        model=azure_openai_gpt41_deployment_name,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\"\n",
    "    )\n",
    "    \n",
    "    # function call check and execution\n",
    "    if response.choices[0].message.tool_calls:\n",
    "        tool_call = response.choices[0].message.tool_calls[0]\n",
    "        function_name = tool_call.function.name\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        \n",
    "        print(f\"function calling: {function_name}({arguments})\")\n",
    "        \n",
    "        if function_name == \"get_weather\":\n",
    "            result = get_weather(arguments[\"city\"])\n",
    "            print(f\"function result: {result}\")\n",
    "\n",
    "            # generate final response with function result\n",
    "            final_messages = messages.copy()\n",
    "            final_messages.append(response.choices[0].message)\n",
    "            final_messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": result\n",
    "            })\n",
    "            \n",
    "            final_response = client.chat.completions.create(\n",
    "                model=azure_openai_gpt41_deployment_name,\n",
    "                messages=final_messages\n",
    "            )\n",
    "\n",
    "            print(f\"final response: {final_response.choices[0].message.content}\")\n",
    "            return final_response.choices[0].message.content\n",
    "    else:\n",
    "        print(f\"direct response: {response.choices[0].message.content}\")\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "# Performance comparison\n",
    "results = measure_and_compare(\"Function Calling\", test_function_calling_gpt5, test_function_calling_gpt41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Output Test with Json Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Structured Output (JSON Schema) Performance Comparison ===\n",
      "\n",
      "--- gpt-5-mini Results ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"title\":\"Lenovo Legion 5 Pro (16) - Ryzen 7 / RTX 3070 Ti\",\"category\":\"Gaming Laptop\",\"price_krw\":2490000,\"pros\":[\"Excellent CPU+GPU performance for modern AAA titles\",\"16-inch 165Hz QHD display with good color and brightness\",\"Robust cooling and sustained performance under load\",\"Comfortable keyboard and solid build quality\",\"Generally good value for performance compared to rivals\"],\"cons\":[\"Relatively heavy and not very portable for frequent travel\",\"Battery life is limited under gaming load\",\"Webcam quality is mediocre\",\"Can run warm and loud at max settings\",\"Preinstalled software/bloatware on some units\"]}\n",
      "Execution Time: 4.61s\n",
      "\n",
      "--- gpt-4.1 Results ---\n",
      "{\"title\":\"MSI Katana 15 B13VFK\",\"category\":\"Gaming Laptop\",\"price_krw\":1800000,\"pros\":[\"Powerful Intel Core i7-13700H processor\",\"NVIDIA GeForce RTX 4060 graphics\",\"144Hz Full HD display for smooth gameplay\",\"Good cooling system\",\"Reasonable price for the specs\"],\"cons\":[\"Average battery life\",\"Plastic-heavy build quality\",\"No Thunderbolt port\",\"Speakers lack depth\"]}\n",
      "Execution Time: 1.94s\n",
      "\n",
      "--- Performance Summary ---\n",
      "gpt-5-mini: 4.61s\n",
      "gpt-4.1: 1.94s\n",
      "Time Difference: 2.67s (GPT-4.1 faster)\n"
     ]
    }
   ],
   "source": [
    "# 3) Structured Output Performance Comparison (Chat Completions API - JSON Schema)\n",
    "json_schema = {\n",
    "    \"name\": \"product_summary\",\n",
    "    \"schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"title\": {\"type\": \"string\"},\n",
    "            \"category\": {\"type\": \"string\"},\n",
    "            \"price_krw\": {\"type\": \"number\"},\n",
    "            \"pros\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "            \"cons\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "        },\n",
    "        \"required\": [\"title\", \"category\", \"price_krw\", \"pros\", \"cons\"], \n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "    \"strict\": True,\n",
    "}\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Pick a gaming laptop model randomly and generate a summary JSON. Include price in Korean Won with approximate values.\"}\n",
    "]\n",
    "\n",
    "def test_structured_output_gpt5():\n",
    "    response = client.chat.completions.create(\n",
    "        model=azure_openai_gpt5_deployment_name,\n",
    "        messages=messages,\n",
    "        response_format={\"type\": \"json_schema\", \"json_schema\": json_schema},\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def test_structured_output_gpt41():\n",
    "    response = client.chat.completions.create(\n",
    "        model=azure_openai_gpt41_deployment_name,\n",
    "        messages=messages,\n",
    "        response_format={\"type\": \"json_schema\", \"json_schema\": json_schema},\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Performance comparison\n",
    "results = measure_and_compare(\"Structured Output (JSON Schema)\", test_structured_output_gpt5, test_structured_output_gpt41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API (stateful chat for 30days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"resp_68be9a63df0c8195b9c221c01de2b7bd0041fbe4cc2f6317\",\n",
      "  \"created_at\": 1757321827.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5-mini\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"rs_68be9a646ad08195997dbfdc528f44660041fbe4cc2f6317\",\n",
      "      \"summary\": [],\n",
      "      \"type\": \"reasoning\",\n",
      "      \"content\": null,\n",
      "      \"encrypted_content\": null,\n",
      "      \"status\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"msg_68be9a64e8748195bf8617116bb595560041fbe4cc2f6317\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"Received. I'm here — how can I help you test or what would you like to try?\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 11,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 25,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 36\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(   \n",
    "  model=azure_openai_gpt5_deployment_name, \n",
    "  input=\"This is a test.\",\n",
    ")\n",
    "\n",
    "print(response.model_dump_json(indent=2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - List previous chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"id\": \"msg_68be60657c2c8194a339915244faadfe0d97914cd52a20b6\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"text\": \"This is a test.\",\n",
      "          \"type\": \"input_text\"\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"user\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"has_more\": false,\n",
      "  \"object\": \"list\",\n",
      "  \"first_id\": \"msg_68be60657c2c8194a339915244faadfe0d97914cd52a20b6\",\n",
      "  \"last_id\": \"msg_68be60657c2c8194a339915244faadfe0d97914cd52a20b6\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.input_items.list(\"resp_68be60657b208194a9c1549d18e9223a0d97914cd52a20b6\")\n",
    "\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - Upload PDF and analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded successfully:\n",
      "{\n",
      "  \"id\": \"assistant-H8NQWkRDFeGHkoYnZuvBWE\",\n",
      "  \"bytes\": 1165436,\n",
      "  \"created_at\": 1757321832,\n",
      "  \"filename\": \"AI_Brief_Aug2025.pdf\",\n",
      "  \"object\": \"file\",\n",
      "  \"purpose\": \"assistants\",\n",
      "  \"status\": \"processed\",\n",
      "  \"expires_at\": null,\n",
      "  \"status_details\": null\n",
      "}\n",
      "\n",
      "=== Responses API PDF Analysis Performance Comparison ===\n",
      "\n",
      "--- gpt-5-mini Results ---\n",
      "--- GPT-5 Responses API PDF Analysis ---\n",
      "{\n",
      "  \"id\": \"resp_68be9a690e488197be7f16d5563f49d40351cb2d174a3df2\",\n",
      "  \"created_at\": 1757321835.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5-mini\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"rs_68be9a6d344881978764eef4512ed4ce0351cb2d174a3df2\",\n",
      "      \"summary\": [],\n",
      "      \"type\": \"reasoning\",\n",
      "      \"content\": null,\n",
      "      \"encrypted_content\": null,\n",
      "      \"status\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"msg_68be9a7161a48197904aa920143ab9d80351cb2d174a3df2\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"The brief surveys a mid‑2025 surge in global AI policy and regulatory activity—governments and supranational bodies (Taiwan’s MODA, the OECD, the U.S. Senate and Administration, and the EU Commission) are issuing strategies, executive orders and guidance aimed at accelerating innovation and infrastructure, reinforcing leadership and exports, and addressing transparency, safety, and ethical/legal risks. At the same time, industry delivered major product and talent moves: launches include Midjourney’s V1 video model, Baidu’s AI‑powered Smart Search and MuseSteamer, Moonshot’s open‑source Kimi K2, xAI’s Grok 4 and “Grok for Government,” Perplexity’s Comet browser, OpenAI’s ChatGPT Agents, plus notable hiring and M&A activity around AI coding firms. Research and workforce signals were mixed—DeepMind’s AlphaGenome, Google’s MedGemma and Microsoft’s MAI‑DxO demonstrate strong domain progress in genomics and health, while studies highlight issues like hidden prompts, transparency penalties, slower task completion for some experienced developers using AI, rapidly rising everyday AI adoption, and new programs to study AI’s economic impacts.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 21525,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 823,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 576\n",
      "    },\n",
      "    \"total_tokens\": 22348\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "Execution Time: 11.07s\n",
      "\n",
      "--- gpt-4.1 Results ---\n",
      "--- GPT-4.1 Responses API PDF Analysis ---\n",
      "{\n",
      "  \"id\": \"resp_68be9a7422188190b4a2223bfe281e4708a14a9677924d61\",\n",
      "  \"created_at\": 1757321845.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4.1\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"msg_68be9a76f97c8190ae5e95104f93ffa108a14a9677924d61\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"This August 2025 issue of the SPRi AI Brief provides an overview of the latest trends in the artificial intelligence industry, including recent developments in global AI policies, corporate innovations, technological research, and workforce impacts. Key highlights include major AI policy updates from the US, EU, and Taiwan; significant product releases such as Midjourney’s video generation model and OpenAI’s ChatGPT Agent; and research findings related to AI productivity, regulatory challenges, and workforce adoption. The report also presents upcoming industry events and recent corporate moves, such as talent acquisitions and new AI-powered tools.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 21526,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 21376\n",
      "    },\n",
      "    \"output_tokens\": 117,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 21643\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "Execution Time: 5.95s\n",
      "\n",
      "--- Performance Summary ---\n",
      "gpt-5-mini: 11.07s\n",
      "gpt-4.1: 5.95s\n",
      "Time Difference: 5.12s (GPT-4.1 faster)\n"
     ]
    }
   ],
   "source": [
    "# Responses API PDF Upload and Analysis Performance Comparison\n",
    "# Upload a file with a purpose of \"assistants\"\n",
    "try:\n",
    "    file = client.files.create(\n",
    "      file=open(\"AI_Brief_Aug2025.pdf\", \"rb\"), # This assumes a .pdf file in the same directory as the executing script\n",
    "      purpose=\"assistants\"\n",
    "    )\n",
    "    print(\"File uploaded successfully:\")\n",
    "    print(file.model_dump_json(indent=2))\n",
    "    file_id = file.id\n",
    "    \n",
    "    def test_responses_pdf_analysis_gpt5():\n",
    "        response = client.responses.create(\n",
    "            model=azure_openai_gpt5_deployment_name,\n",
    "            input=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"input_file\",\n",
    "                            \"file_id\": file_id\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"input_text\",\n",
    "                            \"text\": \"Summarize this PDF in English in three sentences.\",\n",
    "                        },\n",
    "                    ],\n",
    "                },\n",
    "            ]\n",
    "        )\n",
    "        print(\"--- GPT-5 Responses API PDF Analysis ---\")\n",
    "        print(response.model_dump_json(indent=2))\n",
    "        return response.output_text if hasattr(response, 'output_text') else str(response.output)\n",
    "\n",
    "    def test_responses_pdf_analysis_gpt41():\n",
    "        response = client.responses.create(\n",
    "            model=azure_openai_gpt41_deployment_name,\n",
    "            input=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"input_file\",\n",
    "                            \"file_id\": file_id\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"input_text\",\n",
    "                            \"text\": \"Summarize this PDF in English in three sentences.\",\n",
    "                        },\n",
    "                    ],\n",
    "                },\n",
    "            ]\n",
    "        )\n",
    "        print(\"--- GPT-4.1 Responses API PDF Analysis ---\")\n",
    "        print(response.model_dump_json(indent=2))\n",
    "        return response.output_text if hasattr(response, 'output_text') else str(response.output)\n",
    "\n",
    "    # Performance comparison\n",
    "    results = measure_and_compare(\"Responses API PDF Analysis\", test_responses_pdf_analysis_gpt5, test_responses_pdf_analysis_gpt41)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"PDF file 'AI_Brief_Aug2025.pdf' not found. Please ensure the file exists in the current directory.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error uploading or processing PDF: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - Background Task (async)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"resp_68be9a7a19388190bdca4060ffa4bda50cf3668f435c231b\",\n",
      "  \"created_at\": 1757321850.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5-mini\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": true,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"auto\",\n",
      "  \"status\": \"queued\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": null,\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model = azure_openai_gpt5_deployment_name,\n",
    "    input = \"Write me a bedtime story (1min)\",\n",
    "    background = True\n",
    ")\n",
    "\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current status: queued\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current status: queued\n",
      "Current status: queued\n",
      "Final status: completed\n",
      "Output:\n",
      "A tiny star named Lila lived above a quiet village, tucked into the soft blue of the evening sky. Each night she would stretch her silver arms and hum very softly so the crickets could hear. Down below, a little fox curled up under a lantern, listening to Lila's hum as if it were a lullaby just for him. The moon leaned close and wrapped them both in a warm, pearly light. Trees sighed like sleepy giants and the river whispered secrets as it slid past smooth stones. Lila winked, sending one gentle sparkle that landed on the fox’s nose and made him smile in his sleep. All around, the world breathed out and settled, cozy as a blanket. The star whispered, \"Rest now,\" and the night kept watch until morning. Sleep easy.\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "while response.status in {\"queued\", \"in_progress\"}:\n",
    "    print(f\"Current status: {response.status}\")\n",
    "    sleep(2)\n",
    "    response = client.responses.retrieve(response.id)\n",
    "\n",
    "print(f\"Final status: {response.status}\\nOutput:\\n{response.output_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - Function Calling Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Responses API Function Calling Performance Comparison ===\n",
      "\n",
      "--- gpt-5-mini Results ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- GPT-5 Responses API Function Calling ---\n",
      "{\n",
      "  \"id\": \"resp_68be9a813d9881938f447c2b66f36429024af8c1fa8f4650\",\n",
      "  \"created_at\": 1757321857.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5-mini\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"rs_68be9a81c03481939c140e50b7465446024af8c1fa8f4650\",\n",
      "      \"summary\": [],\n",
      "      \"type\": \"reasoning\",\n",
      "      \"content\": null,\n",
      "      \"encrypted_content\": null,\n",
      "      \"status\": null\n",
      "    },\n",
      "    {\n",
      "      \"arguments\": \"{\\\"location\\\":\\\"San Francisco, CA\\\"}\",\n",
      "      \"call_id\": \"call_1y68o5Ev4wiQTZCMWMuGaOGI\",\n",
      "      \"name\": \"get_weather\",\n",
      "      \"type\": \"function_call\",\n",
      "      \"id\": \"fc_68be9a831f6081938ad4350ba836d3f3024af8c1fa8f4650\",\n",
      "      \"status\": \"completed\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"name\": \"get_weather\",\n",
      "      \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "          \"location\": {\n",
      "            \"type\": \"string\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"location\"\n",
      "        ],\n",
      "        \"additionalProperties\": false\n",
      "      },\n",
      "      \"strict\": true,\n",
      "      \"type\": \"function\",\n",
      "      \"description\": \"Get the weather for a location\"\n",
      "    }\n",
      "  ],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 50,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 87,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 64\n",
      "    },\n",
      "    \"total_tokens\": 137\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "--- GPT-5 Second Response ---\n",
      "{\n",
      "  \"id\": \"resp_68be9a8453048193853cebc8a4ebf0a6024af8c1fa8f4650\",\n",
      "  \"created_at\": 1757321860.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5-mini\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"msg_68be9a84d8308193ade35880c64790df024af8c1fa8f4650\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"It's about 70 degrees in San Francisco right now.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": \"resp_68be9a813d9881938f447c2b66f36429024af8c1fa8f4650\",\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 160,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 15,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 175\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "Execution Time: 4.79s\n",
      "\n",
      "--- gpt-4.1 Results ---\n",
      "--- GPT-4.1 Responses API Function Calling ---\n",
      "{\n",
      "  \"id\": \"resp_68be9a85e9fc81909cd2a362ec321da10b4ae993e7dc75f8\",\n",
      "  \"created_at\": 1757321861.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4.1\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"arguments\": \"{\\\"location\\\":\\\"San Francisco\\\"}\",\n",
      "      \"call_id\": \"call_1U8WZW48sQ28oIlyrhCdROna\",\n",
      "      \"name\": \"get_weather\",\n",
      "      \"type\": \"function_call\",\n",
      "      \"id\": \"fc_68be9a8637188190a59e695c8d34352f0b4ae993e7dc75f8\",\n",
      "      \"status\": \"completed\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"name\": \"get_weather\",\n",
      "      \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "          \"location\": {\n",
      "            \"type\": \"string\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"location\"\n",
      "        ],\n",
      "        \"additionalProperties\": false\n",
      "      },\n",
      "      \"strict\": true,\n",
      "      \"type\": \"function\",\n",
      "      \"description\": \"Get the weather for a location\"\n",
      "    }\n",
      "  ],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 45,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 16,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 61\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "--- GPT-4.1 Second Response ---\n",
      "{\n",
      "  \"id\": \"resp_68be9a8679bc8190be051b002be7e5ab0b4ae993e7dc75f8\",\n",
      "  \"created_at\": 1757321862.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4.1\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"msg_68be9a86cbc08190b5c5c54c1c9990840b4ae993e7dc75f8\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"The current temperature in San Francisco is around 70°F. If you need more details, such as forecasts or humidity, let me know!\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": \"resp_68be9a85e9fc81909cd2a362ec321da10b4ae993e7dc75f8\",\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 45,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 29,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 74\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "Execution Time: 1.38s\n",
      "\n",
      "--- Performance Summary ---\n",
      "gpt-5-mini: 4.79s\n",
      "gpt-4.1: 1.38s\n",
      "Time Difference: 3.42s (GPT-4.1 faster)\n"
     ]
    }
   ],
   "source": [
    "# Responses API Function Calling Performance Comparison\n",
    "tools_responses = [  \n",
    "    {  \n",
    "        \"type\": \"function\",  \n",
    "        \"name\": \"get_weather\",  \n",
    "        \"description\": \"Get the weather for a location\",  \n",
    "        \"parameters\": {  \n",
    "            \"type\": \"object\",  \n",
    "            \"properties\": {  \n",
    "                \"location\": {\"type\": \"string\"},  \n",
    "            },  \n",
    "            \"required\": [\"location\"],  \n",
    "        },  \n",
    "    }  \n",
    "]\n",
    "\n",
    "def test_responses_function_calling_gpt5():\n",
    "    response = client.responses.create(  \n",
    "        model=azure_openai_gpt5_deployment_name, \n",
    "        tools=tools_responses,\n",
    "        input=[{\"role\": \"user\", \"content\": \"What's the weather in San Francisco?\"}],  \n",
    "    )  \n",
    "    \n",
    "    print(\"--- GPT-5 Responses API Function Calling ---\")\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    \n",
    "    # To provide output to tools, add a response for each tool call to an array passed  \n",
    "    # to the next response as `input`  \n",
    "    input_data = []  \n",
    "    for output in response.output:  \n",
    "        if output.type == \"function_call\":  \n",
    "            match output.name:  \n",
    "                case \"get_weather\":  \n",
    "                    input_data.append(  \n",
    "                        {  \n",
    "                            \"type\": \"function_call_output\",  \n",
    "                            \"call_id\": output.call_id,  \n",
    "                            \"output\": '{\"temperature\": \"70 degrees\"}',  \n",
    "                        }  \n",
    "                    )  \n",
    "                case _:  \n",
    "                    raise ValueError(f\"Unknown function call: {output.name}\")  \n",
    "      \n",
    "    second_response = client.responses.create(  \n",
    "        model=azure_openai_gpt5_deployment_name,  \n",
    "        previous_response_id=response.id,  \n",
    "        input=input_data  \n",
    "    )  \n",
    "    \n",
    "    print(\"--- GPT-5 Second Response ---\")\n",
    "    print(second_response.model_dump_json(indent=2))\n",
    "    return second_response.output_text if hasattr(second_response, 'output_text') else str(second_response.output)\n",
    "\n",
    "def test_responses_function_calling_gpt41():\n",
    "    response = client.responses.create(  \n",
    "        model=azure_openai_gpt41_deployment_name, \n",
    "        tools=tools_responses,\n",
    "        input=[{\"role\": \"user\", \"content\": \"What's the weather in San Francisco?\"}],  \n",
    "    )  \n",
    "    \n",
    "    print(\"--- GPT-4.1 Responses API Function Calling ---\")\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    \n",
    "    # To provide output to tools, add a response for each tool call to an array passed  \n",
    "    # to the next response as `input`  \n",
    "    input_data = []  \n",
    "    for output in response.output:  \n",
    "        if output.type == \"function_call\":  \n",
    "            match output.name:  \n",
    "                case \"get_weather\":  \n",
    "                    input_data.append(  \n",
    "                        {  \n",
    "                            \"type\": \"function_call_output\",  \n",
    "                            \"call_id\": output.call_id,  \n",
    "                            \"output\": '{\"temperature\": \"70 degrees\"}',  \n",
    "                        }  \n",
    "                    )  \n",
    "                case _:  \n",
    "                    raise ValueError(f\"Unknown function call: {output.name}\")  \n",
    "      \n",
    "    second_response = client.responses.create(  \n",
    "        model=azure_openai_gpt41_deployment_name,  \n",
    "        previous_response_id=response.id,  \n",
    "        input=input_data  \n",
    "    )  \n",
    "    \n",
    "    print(\"--- GPT-4.1 Second Response ---\")\n",
    "    print(second_response.model_dump_json(indent=2))\n",
    "    return second_response.output_text if hasattr(second_response, 'output_text') else str(second_response.output)\n",
    "\n",
    "# Performance comparison\n",
    "results = measure_and_compare(\"Responses API Function Calling\", test_responses_function_calling_gpt5, test_responses_function_calling_gpt41) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - Structured Output Test with Json Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Responses API doen't support response_format.\n"
     ]
    }
   ],
   "source": [
    "# 5) Structured Output (Responses API - JSON Schema)\n",
    "# json_schema = {\n",
    "#     \"name\": \"product_summary\",\n",
    "#     \"schema\": {\n",
    "#         \"type\": \"object\",\n",
    "#         \"properties\": {\n",
    "#             \"title\": {\"type\": \"string\"},\n",
    "#             \"category\": {\"type\": \"string\"},\n",
    "#             \"price_krw\": {\"type\": \"number\"},\n",
    "#             \"pros\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "#             \"cons\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "#         },\n",
    "#         \"required\": [\"title\", \"category\", \"price_krw\"],\n",
    "#         \"additionalProperties\": False,\n",
    "#     },\n",
    "#     \"strict\": True,\n",
    "# }\n",
    "\n",
    "# inputs = [\n",
    "#     {\"role\": \"user\", \"content\": \"Pick a gaming laptop model randomly and generate a summary JSON. Include price in Korean Won with approximate values.\"}\n",
    "# ]\n",
    "\n",
    "# response = client.responses.create(\n",
    "#     model=azure_openai_gpt5_deployment_name,\n",
    "#     input=inputs,\n",
    "#     response_format={\"type\": \"json_schema\", \"json_schema\": json_schema},\n",
    "# )\n",
    "\n",
    "# print(response.model_dump_json(indent=2)) \n",
    "\n",
    "print(\"Responses API doen't support response_format.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - Streaming output Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Streaming Output Performance Comparison ===\n",
      "\n",
      "--- gpt-5-mini Results ---\n",
      "--- GPT-5 Streaming ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I told my smart speaker a joke.\n",
      "It laughed for ten minutes.\n",
      "I asked why it was so hyper.\n",
      "It said, \"Sorry, I was buffering.\"\n",
      "Now we're both still processing.\n",
      "Execution Time: 6.09s\n",
      "\n",
      "--- gpt-4.1 Results ---\n",
      "--- GPT-4.1 Streaming ---\n",
      "Why did the scarecrow win an award?  \n",
      "Because he was outstanding in his field!  \n",
      "But then he got lonely,  \n",
      "So he asked the corn for company—  \n",
      "But it was too ear-resistible to leave!\n",
      "Execution Time: 3.18s\n",
      "\n",
      "--- Performance Summary ---\n",
      "gpt-5-mini: 6.09s\n",
      "gpt-4.1: 3.18s\n",
      "Time Difference: 2.91s (GPT-4.1 faster)\n"
     ]
    }
   ],
   "source": [
    "# 4) Streaming Output Performance Comparison\n",
    "def test_streaming_gpt5():\n",
    "    try:\n",
    "        print(\"--- GPT-5 Streaming ---\")\n",
    "        stream = client.chat.completions.create(\n",
    "            model=azure_openai_gpt5_deployment_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Tell me a five-line joke.\"}],\n",
    "            stream=True,\n",
    "        )\n",
    "        \n",
    "        content = \"\"\n",
    "        for chunk in stream:\n",
    "            if chunk.choices:\n",
    "                delta = chunk.choices[0].delta.content\n",
    "                if delta:\n",
    "                    print(delta, end=\"\", flush=True)\n",
    "                    content += delta\n",
    "                    time.sleep(0.05)\n",
    "        print()\n",
    "        return content\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Streaming error: {e}\")\n",
    "        return None\n",
    "\n",
    "def test_streaming_gpt41():\n",
    "    try:\n",
    "        print(\"--- GPT-4.1 Streaming ---\")\n",
    "        stream = client.chat.completions.create(\n",
    "            model=azure_openai_gpt41_deployment_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Tell me a five-line joke.\"}],\n",
    "            stream=True,\n",
    "        )\n",
    "        \n",
    "        content = \"\"\n",
    "        for chunk in stream:\n",
    "            if chunk.choices:\n",
    "                delta = chunk.choices[0].delta.content\n",
    "                if delta:\n",
    "                    print(delta, end=\"\", flush=True)\n",
    "                    content += delta\n",
    "                    time.sleep(0.05)\n",
    "        print()\n",
    "        return content\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Streaming error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Performance comparison\n",
    "results = measure_and_compare(\"Streaming Output\", test_streaming_gpt5, test_streaming_gpt41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - Code Interpreter Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Responses API Code Interpreter Performance Comparison ===\n",
      "\n",
      "--- gpt-5-mini Results ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- GPT-5 Responses API Code Interpreter ---\n",
      "{\n",
      "  \"id\": \"resp_68be9a9099bc8190a1a98786b8d8b5c0069c4e70f2d46a9a\",\n",
      "  \"created_at\": 1757321872.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": \"You are a personal math tutor. When asked a math question, write and run code using the python tool to answer the question.\",\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5-mini\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"rs_68be9a924acc8190819b051efcf8830e069c4e70f2d46a9a\",\n",
      "      \"summary\": [],\n",
      "      \"type\": \"reasoning\",\n",
      "      \"content\": null,\n",
      "      \"encrypted_content\": null,\n",
      "      \"status\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ci_68be9a940a1081908d949618543be2b5069c4e70f2d46a9a\",\n",
      "      \"code\": \"# Solve the equation 3x + 11 = 14\\nfrom fractions import Fraction\\nx = Fraction(14 - 11, 3)\\nx, float(x), 3*x + 11\\n\",\n",
      "      \"container_id\": \"cntr_68be9a9152c08190bd0f857cb28c72110994bf39b83cf55d\",\n",
      "      \"outputs\": null,\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"code_interpreter_call\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"msg_68be9a95a1288190bf4966095a502ede069c4e70f2d46a9a\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"Solve 3x + 11 = 14:\\n\\nStep 1: Subtract 11 from both sides: 3x = 14 - 11 = 3.\\nStep 2: Divide both sides by 3: x = 3/3 = 1.\\n\\nCheck: 3(1) + 11 = 3 + 11 = 14.\\n\\nAnswer: x = 1.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"container\": {\n",
      "        \"type\": \"auto\",\n",
      "        \"file_ids\": null\n",
      "      },\n",
      "      \"type\": \"code_interpreter\"\n",
      "    }\n",
      "  ],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 1652,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 280,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 192\n",
      "    },\n",
      "    \"total_tokens\": 1932\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "Execution Time: 6.47s\n",
      "\n",
      "--- gpt-4.1 Results ---\n",
      "--- GPT-4.1 Responses API Code Interpreter ---\n",
      "{\n",
      "  \"id\": \"resp_68be9a9712808194b85cfcd1c9c6d5030946a5afd38e6c01\",\n",
      "  \"created_at\": 1757321879.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": \"You are a personal math tutor. When asked a math question, write and run code using the python tool to answer the question.\",\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4.1\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"msg_68be9a98871881948715fa3306682e240946a5afd38e6c01\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"Let's solve the equation step by step:\\n\\nGiven equation:  \\n\\\\( 3x + 11 = 14 \\\\)\\n\\nLet's isolate \\\\( x \\\\):\\n\\n1. Subtract 11 from both sides:\\n   \\\\( 3x = 14 - 11 \\\\)\\n2. Simplify:\\n   \\\\( 3x = 3 \\\\)\\n3. Divide both sides by 3:\\n   \\\\( x = \\\\frac{3}{3} \\\\)\\n   \\\\( x = 1 \\\\)\\n\\nSo, \\\\( x = 1 \\\\).\\n\\nLet's confirm this with code.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ci_68be9a99bb5c819487990dea0ee291ce0946a5afd38e6c01\",\n",
      "      \"code\": \"from sympy import symbols, Eq, solve\\n\\n# Define the variable and equation\\nx = symbols('x')\\nequation = Eq(3*x + 11, 14)\\n\\n# Solve the equation\\nsolution = solve(equation, x)\\nsolution\",\n",
      "      \"container_id\": \"cntr_68be9a97bfbc8190ac67f2a7a88e200e01f34a39899c935a\",\n",
      "      \"outputs\": null,\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"code_interpreter_call\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"msg_68be9a9b0c188194800617b4b1d952d40946a5afd38e6c01\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"The solution to the equation \\\\( 3x + 11 = 14 \\\\) is \\\\( x = 1 \\\\).\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"container\": {\n",
      "        \"type\": \"auto\",\n",
      "        \"file_ids\": null\n",
      "      },\n",
      "      \"type\": \"code_interpreter\"\n",
      "    }\n",
      "  ],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 582,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 200,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 782\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "Execution Time: 4.83s\n",
      "\n",
      "--- Performance Summary ---\n",
      "gpt-5-mini: 6.47s\n",
      "gpt-4.1: 4.83s\n",
      "Time Difference: 1.65s (GPT-4.1 faster)\n"
     ]
    }
   ],
   "source": [
    "# Responses API Code Interpreter Performance Comparison\n",
    "instructions = \"You are a personal math tutor. When asked a math question, write and run code using the python tool to answer the question.\"\n",
    "\n",
    "tools_code_interpreter = [\n",
    "    {\n",
    "        \"type\": \"code_interpreter\",\n",
    "        \"container\": {\"type\": \"auto\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "math_question = \"I need to solve the equation 3x + 11 = 14. Can you help me?\"\n",
    "\n",
    "def test_responses_code_interpreter_gpt5():\n",
    "    response = client.responses.create(\n",
    "        model=azure_openai_gpt5_deployment_name,\n",
    "        tools=tools_code_interpreter,\n",
    "        instructions=instructions,\n",
    "        input=math_question,\n",
    "    )\n",
    "    print(\"--- GPT-5 Responses API Code Interpreter ---\")\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    return response.output_text if hasattr(response, 'output_text') else str(response.output)\n",
    "\n",
    "def test_responses_code_interpreter_gpt41():\n",
    "    response = client.responses.create(\n",
    "        model=azure_openai_gpt41_deployment_name,\n",
    "        tools=tools_code_interpreter,\n",
    "        instructions=instructions,\n",
    "        input=math_question,\n",
    "    )\n",
    "    print(\"--- GPT-4.1 Responses API Code Interpreter ---\")\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    return response.output_text if hasattr(response, 'output_text') else str(response.output)\n",
    "\n",
    "# Performance comparison\n",
    "results = measure_and_compare(\"Responses API Code Interpreter\", test_responses_code_interpreter_gpt5, test_responses_code_interpreter_gpt41) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - Vision Support Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Responses API Vision Support Performance Comparison ===\n",
      "\n",
      "--- gpt-5-mini Results ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- GPT-5 Responses API Vision ---\n",
      "{\n",
      "  \"id\": \"resp_68be9a9be9708190a59ab0c53edc30f50264ac3979a5c368\",\n",
      "  \"created_at\": 1757321884.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5-mini\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"rs_68be9a9f1fc08190b5abf0853617c8f90264ac3979a5c368\",\n",
      "      \"summary\": [],\n",
      "      \"type\": \"reasoning\",\n",
      "      \"content\": null,\n",
      "      \"encrypted_content\": null,\n",
      "      \"status\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"msg_68be9aa06d64819089f8cbe4bd5e1c7e0264ac3979a5c368\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"Panoramic mountain range with steep rocky cliffs and layered ridges.  \\nLush green valleys and forests with scattered pastures and small buildings.  \\nClear blue sky dotted with fluffy clouds and distant snow-capped peaks.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 238,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 178,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 128\n",
      "    },\n",
      "    \"total_tokens\": 416\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "Execution Time: 6.52s\n",
      "\n",
      "--- gpt-4.1 Results ---\n",
      "--- GPT-4.1 Responses API Vision ---\n",
      "{\n",
      "  \"id\": \"resp_68be9aa271e081908c78f5766040bfc90a47b820df270088\",\n",
      "  \"created_at\": 1757321890.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4.1\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"msg_68be9aa377108190acd7b8e8928265790a47b820df270088\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"The image shows a lush green mountain range under a bright blue sky with scattered clouds.  \\nForested slopes and grassy patches are visible, with rocky cliffs on the higher elevations.  \\nSmall settlements or buildings are scattered at the base, nestled among the rolling hills.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 447,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 53,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 500\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "Execution Time: 1.77s\n",
      "\n",
      "--- Performance Summary ---\n",
      "gpt-5-mini: 6.52s\n",
      "gpt-4.1: 1.77s\n",
      "Time Difference: 4.75s (GPT-4.1 faster)\n"
     ]
    }
   ],
   "source": [
    "# Responses API Vision Support Performance Comparison\n",
    "# Note: Requires the deployed model to support vision and your API version to allow image input.\n",
    "image_url = os.getenv(\"TEST_IMAGE_URL\", \"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Fronalpstock_big.jpg/640px-Fronalpstock_big.jpg\")\n",
    "\n",
    "inputs = [\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"input_text\", \"text\": \"Summarize the main features of this image in three lines in English.\"},\n",
    "        {\"type\": \"input_image\", \"image_url\": image_url},\n",
    "    ]}\n",
    "]\n",
    "\n",
    "def test_responses_vision_gpt5():\n",
    "    response = client.responses.create(\n",
    "        model=azure_openai_gpt5_deployment_name, \n",
    "        input=inputs\n",
    "    )\n",
    "    print(\"--- GPT-5 Responses API Vision ---\")\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    return response.output_text if hasattr(response, 'output_text') else str(response.output)\n",
    "\n",
    "def test_responses_vision_gpt41():\n",
    "    response = client.responses.create(\n",
    "        model=azure_openai_gpt41_deployment_name, \n",
    "        input=inputs\n",
    "    )\n",
    "    print(\"--- GPT-4.1 Responses API Vision ---\")\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    return response.output_text if hasattr(response, 'output_text') else str(response.output)\n",
    "\n",
    "# Performance comparison\n",
    "results = measure_and_compare(\"Responses API Vision Support\", test_responses_vision_gpt5, test_responses_vision_gpt41)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
