{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-5 Basic Test Notebook (Azure OpenAI)\n",
    "\n",
    "This notebook provides examples of the Chat Completions API and the Responses API to quickly validate the basic functionality of GPT-5 in Azure OpenAI. It uses the Azure OpenAI endpoint, key, and deployment name configured in the environment variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "## Requirements\n",
    "\n",
    "- Python 3.10+\n",
    "- `pip install -r GPT-5/requirements.txt`\n",
    "- `GPT-5/.env` \n",
    "  - AZURE_OPENAI_ENDPOINT\n",
    "  - AZURE_OPENAI_API_KEY\n",
    "  - AZURE_OPENAI_API_VERSION\n",
    "  - AZURE_OPENAI_DEPLOYMENT_NAME\n",
    "\n",
    "## GPT-5 series model comparision \n",
    "Reference: https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/models?tabs=global-standard%2Cstandard-chat-completions \n",
    "\n",
    "| Model           | Reasoning Support       | Chat Completions API | Responses API | Structured Outputs | Function/Tool Calling     | Context Window (tokens)     | Price per 1M tokens (input/output) |\n",
    "|-----------------|-------------------------|----------------------|---------------|--------------------|---------------------------|-----------------------------|------------------------------------|\n",
    "| **GPT-5**       | ✅​                     | ✅​                  | ✅​           | ✅​                | ✅​                        | 400,000 (272k in + 128k out) | $1.25 / $10                        |\n",
    "| **GPT-5-mini**  | ✅​                     | ✅​                  | ✅​           | ✅​                | ✅​                       | 400,000 (272k in + 128k out) | $0.25 / $2.00                      |\n",
    "| **GPT-5-nano**  | ✅​                     | ✅​                  | ✅​           | ✅​                | ✅​                       | 400,000 (272k in + 128k out) | $0.05 / $0.40                      |\n",
    "| **GPT-5-chat**  | 〰️ (undocumented)      | ✅​                  | ✅​           | 〰️ (undocumented)   | 〰️ (undocumented)          | 128,000 (16k max output)     | $1.25 / $10                        |\n",
    "| **GPT-4.1**     | ✅​                     | ✅​                  | ✅​           | ✅​                | ✅​                       | 1,000,000                   | $2.00 / $8.00                      |\n",
    "| **GPT-4.1-mini**| ✅​                     | ✅​                  | ✅​           | ✅​                | ✅​                       | 1,000,000                   | $0.40 / $1.60                      |\n",
    "| **GPT-4.1-nano**| ✅​                     | ✅​                  | ✅​           | ✅​                | ✅​                       | 1,000,000                   | $0.10 / $0.40                      |\n",
    "| **GPT-4o**      | ✅​                     | ✅​                  | 〰️ (undocumented) | ✅​           | ✅​                        | 128,000 (+16k out)          | $5.00 / $15.00                     |\n",
    "\n",
    "\n",
    "> - gpt-5 series models support Reasoning, Chat Completions API, Responses API, Structured Outputs API, and Function/Tool Calling (including parallel calls).\n",
    "> - As of September 8, 2025, gpt-5-chat (Preview) supports Chat Completions API and Responses API, but does not support Reasoning, Structured Outputs or Function/Tool Calling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Completions API Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afh/code/Azure_OpenAI_samples/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Azure OpenAI Configuration ===\n",
      "Endpoint: https://hyo-ai-foundry-pjt1-resource.openai.azure.com/\n",
      "API Version: 2025-03-01-preview\n",
      "GPT-5 Deployment: gpt-5-mini\n",
      "GPT-4.1 Deployment: gpt-4.1\n",
      "Embedding Deployment: text-embedding-ada-002\n",
      "API Key set: True\n",
      "Client initialized: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "import base64\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential, EnvironmentCredential\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "from io import BytesIO\n",
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "import json\n",
    "load_dotenv(override=True)\n",
    "\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\", \"\") if len(os.getenv(\"AZURE_OPENAI_API_KEY\", \"\")) > 0 else None\n",
    "azure_openai_gpt5_deployment_name = \"gpt-5-mini\" # can be \"gpt-5\" or \"gpt-5-chat\" or \"gpt-5-mini\"\n",
    "azure_openai_gpt41_deployment_name = \"gpt-4.1\"  # can be \"gpt-4.1\" or \"gpt-4.1-mini\" or \"gpt-4o\"\n",
    "azure_openai_embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-ada-002\")\n",
    "aoai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"\") if len(os.getenv(\"AZURE_OPENAI_API_VERSION\", \"\")) > 0 else None\n",
    "\n",
    "try:\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=azure_openai_endpoint,\n",
    "        api_key=azure_openai_key,\n",
    "        api_version=aoai_api_version\n",
    "    )\n",
    "except (ValueError, TypeError) as e:\n",
    "    print(e)\n",
    "\n",
    "# Performance measurement utilities\n",
    "class PerformanceTimer:\n",
    "    def __init__(self, test_name):\n",
    "        self.test_name = test_name\n",
    "        self.start_time = None\n",
    "        \n",
    "    def __enter__(self):\n",
    "        self.start_time = time.time()\n",
    "        return self\n",
    "        \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        end_time = time.time()\n",
    "        self.execution_time = end_time - self.start_time\n",
    "        \n",
    "    def get_time(self):\n",
    "        return getattr(self, 'execution_time', None)\n",
    "\n",
    "def measure_and_compare(test_name, gpt5_func, gpt41_func):\n",
    "    \"\"\"Generic performance comparison for any test function\"\"\"\n",
    "    print(f\"\\n=== {test_name} Performance Comparison ===\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Test GPT-5\n",
    "    print(f\"\\n--- {azure_openai_gpt5_deployment_name} Results ---\")\n",
    "    try:\n",
    "        with PerformanceTimer(\"GPT-5\") as timer:\n",
    "            gpt5_result = gpt5_func()\n",
    "        results[\"GPT-5\"] = {\n",
    "            'time': timer.get_time(),\n",
    "            'result': gpt5_result,\n",
    "            'success': True\n",
    "        }\n",
    "        print(f\"Execution Time: {timer.get_time():.2f}s\")\n",
    "    except Exception as e:\n",
    "        results[\"GPT-5\"] = {'time': None, 'result': None, 'success': False, 'error': str(e)}\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    # Test GPT-4.1\n",
    "    print(f\"\\n--- {azure_openai_gpt41_deployment_name} Results ---\")\n",
    "    try:\n",
    "        with PerformanceTimer(\"GPT-4.1\") as timer:\n",
    "            gpt41_result = gpt41_func()\n",
    "        results[\"GPT-4.1\"] = {\n",
    "            'time': timer.get_time(),\n",
    "            'result': gpt41_result,\n",
    "            'success': True\n",
    "        }\n",
    "        print(f\"Execution Time: {timer.get_time():.2f}s\")\n",
    "    except Exception as e:\n",
    "        results[\"GPT-4.1\"] = {'time': None, 'result': None, 'success': False, 'error': str(e)}\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    # Comparison summary\n",
    "    if results[\"GPT-5\"]['success'] and results[\"GPT-4.1\"]['success']:\n",
    "        time_diff = results[\"GPT-5\"]['time'] - results[\"GPT-4.1\"]['time']\n",
    "        faster_model = \"GPT-5\" if time_diff < 0 else \"GPT-4.1\"\n",
    "        print(\"\\n--- Performance Summary ---\")\n",
    "        print(f\"{azure_openai_gpt5_deployment_name}: {results['GPT-5']['time']:.2f}s\")\n",
    "        print(f\"{azure_openai_gpt41_deployment_name}: {results['GPT-4.1']['time']:.2f}s\")\n",
    "        print(f\"Time Difference: {abs(time_diff):.2f}s ({faster_model} faster)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Print environment variables (excluding sensitive info)\n",
    "print(\"=== Azure OpenAI Configuration ===\")\n",
    "print(f\"Endpoint: {azure_openai_endpoint}\")\n",
    "print(f\"API Version: {aoai_api_version}\")\n",
    "print(f\"GPT-5 Deployment: {azure_openai_gpt5_deployment_name}\")\n",
    "print(f\"GPT-4.1 Deployment: {azure_openai_gpt41_deployment_name}\")\n",
    "print(f\"Embedding Deployment: {azure_openai_embedding_deployment}\")\n",
    "print(f\"API Key set: {azure_openai_key is not None}\")\n",
    "print(f\"Client initialized: {client is not None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Chat Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Basic Chat Performance Comparison ===\n",
      "\n",
      "--- gpt-5-mini Results ---\n",
      "Microsoft Corporation is a major U.S. technology company founded in 1975 by Bill Gates and Paul Allen and headquartered in Redmond, Washington. Over nearly five decades it has grown from a software-startup to one of the world’s largest and most influential tech firms.\n",
      "\n",
      "Key areas and products\n",
      "- Operating systems and PC software: Windows (desktop and server) and Microsoft 365 (Office apps like Word, Excel, Outlook).\n",
      "- Cloud computing and enterprise services: Azure (cloud platform and services), Windows Server, SQL Server, and enterprise management tools.\n",
      "- Productivity and business services: Microsoft 365, Teams (collaboration/communications), LinkedIn (professional social network).\n",
      "- Developer and platform tools: Visual Studio, GitHub (acquired 2018), developer frameworks and APIs.\n",
      "- Devices and consumer hardware: Surface PCs and tablets, Xbox gaming consoles and services (including Xbox Game Pass).\n",
      "- AI and emerging services: Copilot/AI integrations across Microsoft 365 and developer tools, partnerships with AI providers (including Azure OpenAI Service).\n",
      "- Gaming and entertainment: Major presence via Xbox and the acquisition of Activision Blizzard (closed 2023), expanding Microsoft’s gaming portfolio.\n",
      "\n",
      "Business structure\n",
      "Microsoft reports results across three broad segments:\n",
      "- Productivity and Business Processes (Office, LinkedIn, Dynamics).\n",
      "- Intelligent Cloud (Azure, server products, enterprise services).\n",
      "- More Personal Computing (Windows, Surface, Xbox, search advertising).\n",
      "\n",
      "Leadership and strategy\n",
      "- Satya Nadella has been CEO since 2014. Under his leadership Microsoft shifted strongly toward cloud-first, mobile-first and now AI-first strategies and has emphasized hybrid cloud, developer tools, subscriptions, and enterprise services.\n",
      "- The company has focused heavily on AI integration across products, cloud infrastructure, and partnerships with leading AI research and product teams.\n",
      "\n",
      "Size and influence\n",
      "- Microsoft is one of the world’s most valuable companies, with a large global workforce and operations in most countries. It is a major supplier to enterprises, governments, software developers and consumers.\n",
      "\n",
      "Notable acquisitions and moves\n",
      "- LinkedIn (2016), GitHub (2018), Activision Blizzard (2023), and numerous smaller strategic deals in cloud, AI, gaming and enterprise software.\n",
      "- Heavy investments in Azure infrastructure and AI capabilities, including services that let businesses deploy large language models and AI-powered features in productivity tools.\n",
      "\n",
      "Challenges and controversies\n",
      "- Regulatory and antitrust scrutiny in multiple jurisdictions, particularly around acquisitions, cloud market power and competition.\n",
      "- Ongoing issues common to large tech firms: security incidents, privacy concerns, and workforce/organizational changes.\n",
      "\n",
      "Where to learn more\n",
      "- Microsoft’s official site and investor relations pages for up-to-date financials and strategy.\n",
      "- Recent news coverage and regulatory filings for the latest product launches, deals and legal developments.\n",
      "\n",
      "If you want, I can give more detail about any specific area—Azure services, Microsoft’s AI initiatives, a product like Windows or Office, or its recent financial performance. Which would you like?\n",
      "Execution Time: 10.67s\n",
      "\n",
      "--- gpt-4.1 Results ---\n",
      "Certainly! Here’s an overview of **Microsoft**:\n",
      "\n",
      "### Overview\n",
      "**Microsoft Corporation** is a multinational technology company based in Redmond, Washington, USA. Founded in 1975 by **Bill Gates** and **Paul Allen**, Microsoft started as a developer for BASIC interpreters for the Altair 8800, but grew to become one of the world’s largest and most influential technology companies.\n",
      "\n",
      "### Key Products & Services\n",
      "\n",
      "- **Windows Operating System:** Microsoft’s flagship product, Windows, is the most widely used desktop operating system globally.\n",
      "- **Microsoft Office:** A suite of productivity applications including Word, Excel, PowerPoint, and Outlook.\n",
      "- **Azure:** Microsoft’s cloud computing platform, offering services such as computing power, databases, AI, and more.\n",
      "- **Xbox:** A popular line of gaming consoles and services.\n",
      "- **Surface:** A series of touchscreen-based personal computers and interactive whiteboards.\n",
      "- **LinkedIn:** A professional networking platform acquired by Microsoft in 2016.\n",
      "- **GitHub:** A platform for software development and version control, acquired in 2018.\n",
      "- **Bing:** Microsoft’s web search engine.\n",
      "\n",
      "### Innovation & Initiatives\n",
      "- **Artificial Intelligence:** Microsoft invests heavily in AI, including integrating AI features into its products (such as Copilot in Microsoft 365) and collaborating with companies like OpenAI.\n",
      "- **Cloud Computing:** Competes with Amazon AWS and Google Cloud through Microsoft Azure.\n",
      "- **Enterprise Solutions:** Offers business-centric products including Dynamics (ERP and CRM), Teams (collaboration), and SharePoint (content management).\n",
      "\n",
      "### Financials & Global Impact\n",
      "Microsoft is among the five highest-valued companies worldwide, often trading as one of the “Big Tech” firms alongside Apple, Google (Alphabet), Amazon, and Meta (Facebook). It is publicly traded on the NASDAQ under the ticker **MSFT**.\n",
      "\n",
      "### Leadership\n",
      "As of June 2024:\n",
      "- **Satya Nadella** is Chairman and CEO, having taken over from Steve Ballmer in 2014. Nadella has driven a transformation toward cloud services and AI.\n",
      "\n",
      "### Culture & Social Commitment\n",
      "Microsoft emphasizes corporate responsibility, sustainability, and diversity & inclusion. It has committed to being carbon negative by 2030 and invests in digital skills and social impact initiatives worldwide.\n",
      "\n",
      "---\n",
      "\n",
      "If you want information about a specific aspect of Microsoft (history, products, leadership, etc.), let me know!\n",
      "Execution Time: 4.95s\n",
      "\n",
      "--- Performance Summary ---\n",
      "gpt-5-mini: 10.67s\n",
      "gpt-4.1: 4.95s\n",
      "Time Difference: 5.72s (GPT-4.1 faster)\n"
     ]
    }
   ],
   "source": [
    "# 1) Basic Chat Test with Performance Comparison\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Microsoft\"}\n",
    "]\n",
    "\n",
    "def test_basic_chat_gpt5():\n",
    "    response = client.chat.completions.create(\n",
    "        model=azure_openai_gpt5_deployment_name,\n",
    "        messages=messages,\n",
    "        reasoning_effort = \"low\"  # low, medium, or high\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def test_basic_chat_gpt41():\n",
    "    response = client.chat.completions.create(\n",
    "        model=azure_openai_gpt41_deployment_name,\n",
    "        messages=messages\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Performance comparison\n",
    "results = measure_and_compare(\"Basic Chat\", test_basic_chat_gpt5, test_basic_chat_gpt41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Calling Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Function Calling Performance Comparison ===\n",
      "\n",
      "--- gpt-5-mini Results ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function calling: get_weather({'city': 'Seoul'})\n",
      "function result: Clear, 22°C\n",
      "final response: Right now in Seoul it's clear and 22°C. Light jacket or long-sleeve should be fine. Would you like an hourly forecast or the next few days?\n",
      "Execution Time: 3.34s\n",
      "\n",
      "--- gpt-4.1 Results ---\n",
      "function calling: get_weather({'city': 'Seoul'})\n",
      "function result: Clear, 22°C\n",
      "final response: The current weather in Seoul is clear with a temperature of 22°C.\n",
      "Execution Time: 1.30s\n",
      "\n",
      "--- Performance Summary ---\n",
      "gpt-5-mini: 3.34s\n",
      "gpt-4.1: 1.30s\n",
      "Time Difference: 2.04s (GPT-4.1 faster)\n"
     ]
    }
   ],
   "source": [
    "# 2) Function Calling Performance Comparison\n",
    "def get_weather(city: str):\n",
    "    \"\"\"Mock weather function\"\"\"\n",
    "    weather_data = {\n",
    "        \"Seoul\": \"Clear, 22°C\",\n",
    "        \"Busan\": \"Cloudy, 19°C\"\n",
    "    }\n",
    "    return weather_data.get(city, f\"{city}: Weather information not available\")\n",
    "\n",
    "# function schema\n",
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get weather for a city\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"city\": {\"type\": \"string\", \"description\": \"City name\"}\n",
    "            },\n",
    "            \"required\": [\"city\"]\n",
    "        }\n",
    "    }\n",
    "}]\n",
    "\n",
    "# query include function calling\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Tell me the weather in Seoul\"}\n",
    "]\n",
    "\n",
    "def test_function_calling_gpt5():\n",
    "    response = client.chat.completions.create(\n",
    "        model=azure_openai_gpt5_deployment_name,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\"\n",
    "    )\n",
    "    \n",
    "    # function call check and execution\n",
    "    if response.choices[0].message.tool_calls:\n",
    "        tool_call = response.choices[0].message.tool_calls[0]\n",
    "        function_name = tool_call.function.name\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        \n",
    "        print(f\"function calling: {function_name}({arguments})\")\n",
    "        \n",
    "        if function_name == \"get_weather\":\n",
    "            result = get_weather(arguments[\"city\"])\n",
    "            print(f\"function result: {result}\")\n",
    "\n",
    "            # generate final response with function result\n",
    "            final_messages = messages.copy()\n",
    "            final_messages.append(response.choices[0].message)\n",
    "            final_messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": result\n",
    "            })\n",
    "            \n",
    "            final_response = client.chat.completions.create(\n",
    "                model=azure_openai_gpt5_deployment_name,\n",
    "                messages=final_messages,\n",
    "                reasoning_effort = \"low\"  # low, medium, or high\n",
    "            )\n",
    "\n",
    "            print(f\"final response: {final_response.choices[0].message.content}\")\n",
    "            return final_response.choices[0].message.content\n",
    "    else:\n",
    "        print(f\"direct response: {response.choices[0].message.content}\")\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "def test_function_calling_gpt41():\n",
    "    response = client.chat.completions.create(\n",
    "        model=azure_openai_gpt41_deployment_name,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\"\n",
    "    )\n",
    "    \n",
    "    # function call check and execution\n",
    "    if response.choices[0].message.tool_calls:\n",
    "        tool_call = response.choices[0].message.tool_calls[0]\n",
    "        function_name = tool_call.function.name\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        \n",
    "        print(f\"function calling: {function_name}({arguments})\")\n",
    "        \n",
    "        if function_name == \"get_weather\":\n",
    "            result = get_weather(arguments[\"city\"])\n",
    "            print(f\"function result: {result}\")\n",
    "\n",
    "            # generate final response with function result\n",
    "            final_messages = messages.copy()\n",
    "            final_messages.append(response.choices[0].message)\n",
    "            final_messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": result\n",
    "            })\n",
    "            \n",
    "            final_response = client.chat.completions.create(\n",
    "                model=azure_openai_gpt41_deployment_name,\n",
    "                messages=final_messages\n",
    "            )\n",
    "\n",
    "            print(f\"final response: {final_response.choices[0].message.content}\")\n",
    "            return final_response.choices[0].message.content\n",
    "    else:\n",
    "        print(f\"direct response: {response.choices[0].message.content}\")\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "# Performance comparison\n",
    "results = measure_and_compare(\"Function Calling\", test_function_calling_gpt5, test_function_calling_gpt41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Output Test with Json Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Structured Output (JSON Schema) Performance Comparison ===\n",
      "\n",
      "--- gpt-5-mini Results ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"title\":\"Lenovo Legion 5 Pro (16-inch)\",\"category\":\"Gaming Laptop\",\"price_krw\":1950000,\"pros\":[\"High-performance AMD CPU options and NVIDIA GPU configurations for strong gaming and content creation performance\",\"16:10 QHD (2560×1600) high-refresh display option (120–165Hz+) with good color and detail\",\"Robust cooling system that sustains boost clocks under load\",\"Comfortable, responsive keyboard and solid build quality for the price\",\"Generally good value compared to competing gaming laptops in the same class\"],\"cons\":[\"Relatively heavy and not very thin — less portable than ultrabooks\",\"Battery life is limited under gaming or heavy workloads\",\"Fans can get loud under sustained load\",\"Some configurations use a mostly plastic chassis and limited upgrade options on certain SKUs\"]}\n",
      "Execution Time: 5.27s\n",
      "\n",
      "--- gpt-4.1 Results ---\n",
      "{\"title\":\"ASUS ROG Strix G16 (2023)\",\"category\":\"Gaming Laptop\",\"price_krw\":2000000,\"pros\":[\"Powerful Intel Core i7-13650HX processor\",\"RTX 4060 GPU for high-performance gaming\",\"16-inch, 165Hz Full HD display\",\"Effective cooling system\",\"RGB keyboard customization\"],\"cons\":[\"Somewhat heavy and bulky (approx 2.5kg)\",\"Battery life is average for gaming laptops\",\"May be noisy under heavy load\",\"No SD card reader\",\"Limited upgradeability on certain components\"]}\n",
      "Execution Time: 3.89s\n",
      "\n",
      "--- Performance Summary ---\n",
      "gpt-5-mini: 5.27s\n",
      "gpt-4.1: 3.89s\n",
      "Time Difference: 1.38s (GPT-4.1 faster)\n"
     ]
    }
   ],
   "source": [
    "# 3) Structured Output Performance Comparison (Chat Completions API - JSON Schema)\n",
    "json_schema = {\n",
    "    \"name\": \"product_summary\",\n",
    "    \"schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"title\": {\"type\": \"string\"},\n",
    "            \"category\": {\"type\": \"string\"},\n",
    "            \"price_krw\": {\"type\": \"number\"},\n",
    "            \"pros\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "            \"cons\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "        },\n",
    "        \"required\": [\"title\", \"category\", \"price_krw\", \"pros\", \"cons\"], \n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "    \"strict\": True,\n",
    "}\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Pick a gaming laptop model randomly and generate a summary JSON. Include price in Korean Won with approximate values.\"}\n",
    "]\n",
    "\n",
    "def test_structured_output_gpt5():\n",
    "    response = client.chat.completions.create(\n",
    "        model=azure_openai_gpt5_deployment_name,\n",
    "        messages=messages,\n",
    "        response_format={\"type\": \"json_schema\", \"json_schema\": json_schema},\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def test_structured_output_gpt41():\n",
    "    response = client.chat.completions.create(\n",
    "        model=azure_openai_gpt41_deployment_name,\n",
    "        messages=messages,\n",
    "        response_format={\"type\": \"json_schema\", \"json_schema\": json_schema},\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Performance comparison\n",
    "results = measure_and_compare(\"Structured Output (JSON Schema)\", test_structured_output_gpt5, test_structured_output_gpt41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API (stateful chat for 30days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"resp_68be9808e27c8195b87f4a524b6706bd08bd28640864d135\",\n",
      "  \"created_at\": 1757321224.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5-mini\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"rs_68be98092b18819588204d8e5b1c2cb708bd28640864d135\",\n",
      "      \"summary\": [],\n",
      "      \"type\": \"reasoning\",\n",
      "      \"content\": null,\n",
      "      \"encrypted_content\": null,\n",
      "      \"status\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"msg_68be9809aa588195b6986c763239378c08bd28640864d135\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"Got it — test received. How can I help you today?\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 11,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 19,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 30\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(   \n",
    "  model=azure_openai_gpt5_deployment_name, \n",
    "  input=\"This is a test.\",\n",
    ")\n",
    "\n",
    "print(response.model_dump_json(indent=2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - List previous chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"id\": \"msg_68be60657c2c8194a339915244faadfe0d97914cd52a20b6\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"text\": \"This is a test.\",\n",
      "          \"type\": \"input_text\"\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"user\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"has_more\": false,\n",
      "  \"object\": \"list\",\n",
      "  \"first_id\": \"msg_68be60657c2c8194a339915244faadfe0d97914cd52a20b6\",\n",
      "  \"last_id\": \"msg_68be60657c2c8194a339915244faadfe0d97914cd52a20b6\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.input_items.list(\"resp_68be60657b208194a9c1549d18e9223a0d97914cd52a20b6\")\n",
    "\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - Upload PDF and analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded successfully:\n",
      "{\n",
      "  \"id\": \"assistant-4araX5d3oTVQaMCJYfJ4W4\",\n",
      "  \"bytes\": 1165436,\n",
      "  \"created_at\": 1757321228,\n",
      "  \"filename\": \"AI_Brief_Aug2025.pdf\",\n",
      "  \"object\": \"file\",\n",
      "  \"purpose\": \"assistants\",\n",
      "  \"status\": \"processed\",\n",
      "  \"expires_at\": null,\n",
      "  \"status_details\": null\n",
      "}\n",
      "\n",
      "=== Responses API PDF Analysis Performance Comparison ===\n",
      "\n",
      "--- gpt-5-mini Results ---\n",
      "--- GPT-5 Responses API PDF Analysis ---\n",
      "{\n",
      "  \"id\": \"resp_68be980d2b14819698f271eb47c9d08a089243cd418c7c7c\",\n",
      "  \"created_at\": 1757321231.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5-mini\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"rs_68be9810537481968d2a23d22a4526dd089243cd418c7c7c\",\n",
      "      \"summary\": [],\n",
      "      \"type\": \"reasoning\",\n",
      "      \"content\": null,\n",
      "      \"encrypted_content\": null,\n",
      "      \"status\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"msg_68be98175c388196a367182f58497ea2089243cd418c7c7c\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"The Aug 2025 SPRi AI Brief summarizes major global policy moves—including Taiwan’s five‑part AI industry plan (compute, data opening, talent, marketing, funding), the OECD’s framing of generative AI as a general‑purpose technology with policy implications, the U.S. Senate’s rejection of a 10‑year moratorium on state AI regulation, the Trump administration’s AI Action Plan and executive orders, and the EU’s GPAI code of practice and guidance for implementing the AI Act.  \\n\\nOn the industry front, many product and talent developments were reported: Midjourney’s V1 video model, Baidu’s AI‑powered Smart Search and MuseSteamer video tools, Moonshot’s open‑source agentic Kimi K2, xAI’s Grok 4 and “Grok for Government,” Perplexity’s Comet browser, OpenAI’s ChatGPT agents, plus DeepMind hiring key Windsurf personnel and Cognition acquiring Windsurf assets.  \\n\\nThe brief also covers technical advances and societal issues—DeepMind’s AlphaGenome, Google’s MedGemma/MedSigLIP, Microsoft’s MAI‑DxO, and Sakana AI’s multi‑LLM AB‑MCTS—together with concerns about research integrity (hidden AI prompts in papers), studies showing disclosure of AI use lowers evaluations, mixed productivity effects of AI coding tools, and initiatives (surveys and programs) to study and manage AI’s labor‑market impact.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 21525,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 1071,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 768\n",
      "    },\n",
      "    \"total_tokens\": 22596\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "Execution Time: 13.12s\n",
      "\n",
      "--- gpt-4.1 Results ---\n",
      "--- GPT-4.1 Responses API PDF Analysis ---\n",
      "{\n",
      "  \"id\": \"resp_68be981a48b8819090c9d2a276a1031d0db197a15dfc7123\",\n",
      "  \"created_at\": 1757321244.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4.1\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"msg_68be981ef1688190b9872981bf7189360db197a15dfc7123\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"This report, \\\"SPRi AI Brief August 2025,\\\" provides an overview of the latest trends and developments in the artificial intelligence industry, covering global policy updates, industry innovations, technological research, and workforce changes. Key highlights include major AI policy actions in the US, EU, and Taiwan, the launch of new generative and agentic AI models by top companies such as OpenAI, Google DeepMind, xAI, and Midjourney, as well as the growing integration of AI tools into everyday work, particularly among millennials. The brief also addresses emerging challenges around AI regulation, productivity impacts, workforce adaptation, and the need for comprehensive policies to support responsible AI adoption worldwide.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 21526,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 137,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 21663\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "Execution Time: 7.21s\n",
      "\n",
      "--- Performance Summary ---\n",
      "gpt-5-mini: 13.12s\n",
      "gpt-4.1: 7.21s\n",
      "Time Difference: 5.91s (GPT-4.1 faster)\n"
     ]
    }
   ],
   "source": [
    "# Responses API PDF Upload and Analysis Performance Comparison\n",
    "# Upload a file with a purpose of \"assistants\"\n",
    "try:\n",
    "    file = client.files.create(\n",
    "      file=open(\"AI_Brief_Aug2025.pdf\", \"rb\"), # This assumes a .pdf file in the same directory as the executing script\n",
    "      purpose=\"assistants\"\n",
    "    )\n",
    "    print(\"File uploaded successfully:\")\n",
    "    print(file.model_dump_json(indent=2))\n",
    "    file_id = file.id\n",
    "    \n",
    "    def test_responses_pdf_analysis_gpt5():\n",
    "        response = client.responses.create(\n",
    "            model=azure_openai_gpt5_deployment_name,\n",
    "            input=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"input_file\",\n",
    "                            \"file_id\": file_id\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"input_text\",\n",
    "                            \"text\": \"Summarize this PDF in English in three sentences.\",\n",
    "                        },\n",
    "                    ],\n",
    "                },\n",
    "            ]\n",
    "        )\n",
    "        print(\"--- GPT-5 Responses API PDF Analysis ---\")\n",
    "        print(response.model_dump_json(indent=2))\n",
    "        return response.output_text if hasattr(response, 'output_text') else str(response.output)\n",
    "\n",
    "    def test_responses_pdf_analysis_gpt41():\n",
    "        response = client.responses.create(\n",
    "            model=azure_openai_gpt41_deployment_name,\n",
    "            input=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"input_file\",\n",
    "                            \"file_id\": file_id\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"input_text\",\n",
    "                            \"text\": \"Summarize this PDF in English in three sentences.\",\n",
    "                        },\n",
    "                    ],\n",
    "                },\n",
    "            ]\n",
    "        )\n",
    "        print(\"--- GPT-4.1 Responses API PDF Analysis ---\")\n",
    "        print(response.model_dump_json(indent=2))\n",
    "        return response.output_text if hasattr(response, 'output_text') else str(response.output)\n",
    "\n",
    "    # Performance comparison\n",
    "    results = measure_and_compare(\"Responses API PDF Analysis\", test_responses_pdf_analysis_gpt5, test_responses_pdf_analysis_gpt41)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"PDF file 'AI_Brief_Aug2025.pdf' not found. Please ensure the file exists in the current directory.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error uploading or processing PDF: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - Background Task (async)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"resp_68be982180dc81948fc220192b268fce0e576ae11a88bb1c\",\n",
      "  \"created_at\": 1757321249.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5-mini\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": true,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"auto\",\n",
      "  \"status\": \"queued\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": null,\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model = azure_openai_gpt5_deployment_name,\n",
    "    input = \"Write me a bedtime story (1min)\",\n",
    "    background = True\n",
    ")\n",
    "\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current status: queued\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current status: queued\n",
      "Current status: queued\n",
      "Final status: completed\n",
      "Output:\n",
      "Once upon a time, in a tiny cottage at the edge of a sleepy forest, a little fox named Mira couldn’t fall asleep. The stars were twinkling like tiny lanterns, and the moon hung low and round, watching quietly.\n",
      "\n",
      "Mira wrapped herself in a warm blanket of soft moss and listened. The trees whispered lullabies, and a slow breeze carried the scent of lavender and honey. A firefly came by and drew a silver path through the air, inviting Mira to follow with her eyes. Each blink of light felt like a gentle promise: you are safe, you are calm, you are loved.\n",
      "\n",
      "Soon Mira’s breathing matched the steady rhythm of the night. Her eyes grew heavy, and the moon tucked a silvery curl around her cheek. In the hush, she slipped into a dream where the forest hummed a soft, happy tune.\n",
      "\n",
      "Sleep now, little one. The night keeps watch, and morning will come when it’s time. Good night.\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "while response.status in {\"queued\", \"in_progress\"}:\n",
    "    print(f\"Current status: {response.status}\")\n",
    "    sleep(2)\n",
    "    response = client.responses.retrieve(response.id)\n",
    "\n",
    "print(f\"Final status: {response.status}\\nOutput:\\n{response.output_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - Function Calling Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Responses API Function Calling Performance Comparison ===\n",
      "\n",
      "--- gpt-5-mini Results ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- GPT-5 Responses API Function Calling ---\n",
      "{\n",
      "  \"id\": \"resp_68be98289ffc8197ab156eb3417821e70d0407089a45ab97\",\n",
      "  \"created_at\": 1757321256.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5-mini\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"rs_68be98290a188197a3768578d25163f20d0407089a45ab97\",\n",
      "      \"summary\": [],\n",
      "      \"type\": \"reasoning\",\n",
      "      \"content\": null,\n",
      "      \"encrypted_content\": null,\n",
      "      \"status\": null\n",
      "    },\n",
      "    {\n",
      "      \"arguments\": \"{\\\"location\\\":\\\"San Francisco\\\"}\",\n",
      "      \"call_id\": \"call_eN0GmsyWJaby19erNp4VS7sO\",\n",
      "      \"name\": \"get_weather\",\n",
      "      \"type\": \"function_call\",\n",
      "      \"id\": \"fc_68be982a294c8197afa573c7d607008f0d0407089a45ab97\",\n",
      "      \"status\": \"completed\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"name\": \"get_weather\",\n",
      "      \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "          \"location\": {\n",
      "            \"type\": \"string\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"location\"\n",
      "        ],\n",
      "        \"additionalProperties\": false\n",
      "      },\n",
      "      \"strict\": true,\n",
      "      \"type\": \"function\",\n",
      "      \"description\": \"Get the weather for a location\"\n",
      "    }\n",
      "  ],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 50,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 21,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 71\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "--- GPT-5 Second Response ---\n",
      "{\n",
      "  \"id\": \"resp_68be982b61608197b316a50347c0e1bb0d0407089a45ab97\",\n",
      "  \"created_at\": 1757321259.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5-mini\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"msg_68be982bcea4819798a71c72878f61050d0407089a45ab97\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"It's 70 degrees in San Francisco right now.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": \"resp_68be98289ffc8197ab156eb3417821e70d0407089a45ab97\",\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 108,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 14,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 122\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "Execution Time: 3.68s\n",
      "\n",
      "--- gpt-4.1 Results ---\n",
      "--- GPT-4.1 Responses API Function Calling ---\n",
      "{\n",
      "  \"id\": \"resp_68be982c58cc8195b4e42be30908f31f0936b45b89572386\",\n",
      "  \"created_at\": 1757321260.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4.1\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"arguments\": \"{\\\"location\\\":\\\"San Francisco\\\"}\",\n",
      "      \"call_id\": \"call_Kqp5Um5JQojXcMHVOKUC1NyA\",\n",
      "      \"name\": \"get_weather\",\n",
      "      \"type\": \"function_call\",\n",
      "      \"id\": \"fc_68be982cbccc81959f1f4e90035d6b740936b45b89572386\",\n",
      "      \"status\": \"completed\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"name\": \"get_weather\",\n",
      "      \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "          \"location\": {\n",
      "            \"type\": \"string\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"location\"\n",
      "        ],\n",
      "        \"additionalProperties\": false\n",
      "      },\n",
      "      \"strict\": true,\n",
      "      \"type\": \"function\",\n",
      "      \"description\": \"Get the weather for a location\"\n",
      "    }\n",
      "  ],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 45,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 16,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 61\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "--- GPT-4.1 Second Response ---\n",
      "{\n",
      "  \"id\": \"resp_68be982d18cc8195a94aee51e42cffae0936b45b89572386\",\n",
      "  \"created_at\": 1757321261.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4.1\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"msg_68be982d83088195a0f9a3ebb690493b0936b45b89572386\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"The current temperature in San Francisco is about 70 degrees Fahrenheit. If you need more specifics (like forecast, conditions, or a certain date), let me know!\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": \"resp_68be982c58cc8195b4e42be30908f31f0936b45b89572386\",\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 45,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 34,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 79\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "Execution Time: 1.97s\n",
      "\n",
      "--- Performance Summary ---\n",
      "gpt-5-mini: 3.68s\n",
      "gpt-4.1: 1.97s\n",
      "Time Difference: 1.71s (GPT-4.1 faster)\n"
     ]
    }
   ],
   "source": [
    "# Responses API Function Calling Performance Comparison\n",
    "tools_responses = [  \n",
    "    {  \n",
    "        \"type\": \"function\",  \n",
    "        \"name\": \"get_weather\",  \n",
    "        \"description\": \"Get the weather for a location\",  \n",
    "        \"parameters\": {  \n",
    "            \"type\": \"object\",  \n",
    "            \"properties\": {  \n",
    "                \"location\": {\"type\": \"string\"},  \n",
    "            },  \n",
    "            \"required\": [\"location\"],  \n",
    "        },  \n",
    "    }  \n",
    "]\n",
    "\n",
    "def test_responses_function_calling_gpt5():\n",
    "    response = client.responses.create(  \n",
    "        model=azure_openai_gpt5_deployment_name, \n",
    "        tools=tools_responses,\n",
    "        input=[{\"role\": \"user\", \"content\": \"What's the weather in San Francisco?\"}],  \n",
    "    )  \n",
    "    \n",
    "    print(\"--- GPT-5 Responses API Function Calling ---\")\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    \n",
    "    # To provide output to tools, add a response for each tool call to an array passed  \n",
    "    # to the next response as `input`  \n",
    "    input_data = []  \n",
    "    for output in response.output:  \n",
    "        if output.type == \"function_call\":  \n",
    "            match output.name:  \n",
    "                case \"get_weather\":  \n",
    "                    input_data.append(  \n",
    "                        {  \n",
    "                            \"type\": \"function_call_output\",  \n",
    "                            \"call_id\": output.call_id,  \n",
    "                            \"output\": '{\"temperature\": \"70 degrees\"}',  \n",
    "                        }  \n",
    "                    )  \n",
    "                case _:  \n",
    "                    raise ValueError(f\"Unknown function call: {output.name}\")  \n",
    "      \n",
    "    second_response = client.responses.create(  \n",
    "        model=azure_openai_gpt5_deployment_name,  \n",
    "        previous_response_id=response.id,  \n",
    "        input=input_data  \n",
    "    )  \n",
    "    \n",
    "    print(\"--- GPT-5 Second Response ---\")\n",
    "    print(second_response.model_dump_json(indent=2))\n",
    "    return second_response.output_text if hasattr(second_response, 'output_text') else str(second_response.output)\n",
    "\n",
    "def test_responses_function_calling_gpt41():\n",
    "    response = client.responses.create(  \n",
    "        model=azure_openai_gpt41_deployment_name, \n",
    "        tools=tools_responses,\n",
    "        input=[{\"role\": \"user\", \"content\": \"What's the weather in San Francisco?\"}],  \n",
    "    )  \n",
    "    \n",
    "    print(\"--- GPT-4.1 Responses API Function Calling ---\")\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    \n",
    "    # To provide output to tools, add a response for each tool call to an array passed  \n",
    "    # to the next response as `input`  \n",
    "    input_data = []  \n",
    "    for output in response.output:  \n",
    "        if output.type == \"function_call\":  \n",
    "            match output.name:  \n",
    "                case \"get_weather\":  \n",
    "                    input_data.append(  \n",
    "                        {  \n",
    "                            \"type\": \"function_call_output\",  \n",
    "                            \"call_id\": output.call_id,  \n",
    "                            \"output\": '{\"temperature\": \"70 degrees\"}',  \n",
    "                        }  \n",
    "                    )  \n",
    "                case _:  \n",
    "                    raise ValueError(f\"Unknown function call: {output.name}\")  \n",
    "      \n",
    "    second_response = client.responses.create(  \n",
    "        model=azure_openai_gpt41_deployment_name,  \n",
    "        previous_response_id=response.id,  \n",
    "        input=input_data  \n",
    "    )  \n",
    "    \n",
    "    print(\"--- GPT-4.1 Second Response ---\")\n",
    "    print(second_response.model_dump_json(indent=2))\n",
    "    return second_response.output_text if hasattr(second_response, 'output_text') else str(second_response.output)\n",
    "\n",
    "# Performance comparison\n",
    "results = measure_and_compare(\"Responses API Function Calling\", test_responses_function_calling_gpt5, test_responses_function_calling_gpt41) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - Structured Output Test with Json Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Responses API doen't support response_format.\n"
     ]
    }
   ],
   "source": [
    "# 5) Structured Output (Responses API - JSON Schema)\n",
    "# json_schema = {\n",
    "#     \"name\": \"product_summary\",\n",
    "#     \"schema\": {\n",
    "#         \"type\": \"object\",\n",
    "#         \"properties\": {\n",
    "#             \"title\": {\"type\": \"string\"},\n",
    "#             \"category\": {\"type\": \"string\"},\n",
    "#             \"price_krw\": {\"type\": \"number\"},\n",
    "#             \"pros\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "#             \"cons\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "#         },\n",
    "#         \"required\": [\"title\", \"category\", \"price_krw\"],\n",
    "#         \"additionalProperties\": False,\n",
    "#     },\n",
    "#     \"strict\": True,\n",
    "# }\n",
    "\n",
    "# inputs = [\n",
    "#     {\"role\": \"user\", \"content\": \"Pick a gaming laptop model randomly and generate a summary JSON. Include price in Korean Won with approximate values.\"}\n",
    "# ]\n",
    "\n",
    "# response = client.responses.create(\n",
    "#     model=azure_openai_gpt5_deployment_name,\n",
    "#     input=inputs,\n",
    "#     response_format={\"type\": \"json_schema\", \"json_schema\": json_schema},\n",
    "# )\n",
    "\n",
    "# print(response.model_dump_json(indent=2)) \n",
    "\n",
    "print(\"Responses API doen't support response_format.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - Streaming output Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Streaming Output Performance Comparison ===\n",
      "\n",
      "--- gpt-5-mini Results ---\n",
      "--- GPT-5 Streaming ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm reading a book about anti-gravity.\n",
      "It's impossible to put down.\n",
      "I tried to lend it to a friend,\n",
      "but he said he couldn't hold onto it either.\n",
      "Now we're both floating through literature.\n",
      "Execution Time: 6.80s\n",
      "\n",
      "--- gpt-4.1 Results ---\n",
      "--- GPT-4.1 Streaming ---\n",
      "Why did the scarecrow win an award?  \n",
      "Because he was outstanding in his field.  \n",
      "But the corn was a little husky about it.  \n",
      "The potatoes felt they’d been peeled off from the team.  \n",
      "And the tomatoes just couldn’t ketchup!\n",
      "Execution Time: 3.38s\n",
      "\n",
      "--- Performance Summary ---\n",
      "gpt-5-mini: 6.80s\n",
      "gpt-4.1: 3.38s\n",
      "Time Difference: 3.42s (GPT-4.1 faster)\n"
     ]
    }
   ],
   "source": [
    "# 4) Streaming Output Performance Comparison\n",
    "def test_streaming_gpt5():\n",
    "    try:\n",
    "        print(\"--- GPT-5 Streaming ---\")\n",
    "        stream = client.chat.completions.create(\n",
    "            model=azure_openai_gpt5_deployment_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Tell me a five-line joke.\"}],\n",
    "            stream=True,\n",
    "        )\n",
    "        \n",
    "        content = \"\"\n",
    "        for chunk in stream:\n",
    "            if chunk.choices:\n",
    "                delta = chunk.choices[0].delta.content\n",
    "                if delta:\n",
    "                    print(delta, end=\"\", flush=True)\n",
    "                    content += delta\n",
    "                    time.sleep(0.05)\n",
    "        print()\n",
    "        return content\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Streaming error: {e}\")\n",
    "        return None\n",
    "\n",
    "def test_streaming_gpt41():\n",
    "    try:\n",
    "        print(\"--- GPT-4.1 Streaming ---\")\n",
    "        stream = client.chat.completions.create(\n",
    "            model=azure_openai_gpt41_deployment_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Tell me a five-line joke.\"}],\n",
    "            stream=True,\n",
    "        )\n",
    "        \n",
    "        content = \"\"\n",
    "        for chunk in stream:\n",
    "            if chunk.choices:\n",
    "                delta = chunk.choices[0].delta.content\n",
    "                if delta:\n",
    "                    print(delta, end=\"\", flush=True)\n",
    "                    content += delta\n",
    "                    time.sleep(0.05)\n",
    "        print()\n",
    "        return content\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Streaming error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Performance comparison\n",
    "results = measure_and_compare(\"Streaming Output\", test_streaming_gpt5, test_streaming_gpt41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - Code Interpreter Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Responses API Code Interpreter Performance Comparison ===\n",
      "\n",
      "--- gpt-5-mini Results ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- GPT-5 Responses API Code Interpreter ---\n",
      "{\n",
      "  \"id\": \"resp_68be983896f881949c3337b4d855abd108a67e224c76594f\",\n",
      "  \"created_at\": 1757321272.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": \"You are a personal math tutor. When asked a math question, write and run code using the python tool to answer the question.\",\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5-mini\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"rs_68be983a5fc48194b24df42a9c8d675d08a67e224c76594f\",\n",
      "      \"summary\": [],\n",
      "      \"type\": \"reasoning\",\n",
      "      \"content\": null,\n",
      "      \"encrypted_content\": null,\n",
      "      \"status\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ci_68be983ce32881949a1530af8158a3b708a67e224c76594f\",\n",
      "      \"code\": \"# Solve the equation 3x + 11 = 14\\r\\nx = (14 - 11) / 3\\r\\nsolution = x\\r\\ncheck = 3 * x + 11\\r\\nsolution, check\\n\",\n",
      "      \"container_id\": \"cntr_68be98397d708190bc4fbcebced4331d093b85ca32480b8c\",\n",
      "      \"outputs\": null,\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"code_interpreter_call\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"msg_68be983e39cc8194ae550bab437ca97f08a67e224c76594f\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"Solve 3x + 11 = 14:\\n\\nStep 1: subtract 11 from both sides: 3x = 14 − 11 = 3.\\nStep 2: divide both sides by 3: x = 3 / 3 = 1.\\n\\nCheck: 3(1) + 11 = 14.\\n\\nSolution: x = 1.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"container\": {\n",
      "        \"type\": \"auto\",\n",
      "        \"file_ids\": null\n",
      "      },\n",
      "      \"type\": \"code_interpreter\"\n",
      "    }\n",
      "  ],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 1666,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 274,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 192\n",
      "    },\n",
      "    \"total_tokens\": 1940\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "Execution Time: 7.25s\n",
      "\n",
      "--- gpt-4.1 Results ---\n",
      "--- GPT-4.1 Responses API Code Interpreter ---\n",
      "{\n",
      "  \"id\": \"resp_68be983fc44c8196b308ef69b869b01a02b17eb82af3d0e3\",\n",
      "  \"created_at\": 1757321279.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": \"You are a personal math tutor. When asked a math question, write and run code using the python tool to answer the question.\",\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4.1\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"msg_68be984116d48196b359278eef0a86d902b17eb82af3d0e3\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"Let's solve the equation step by step:\\n\\nGiven:  \\n\\\\( 3x + 11 = 14 \\\\)\\n\\nLet's isolate \\\\( x \\\\):\\n\\n1. Subtract 11 from both sides:\\n   \\\\( 3x + 11 - 11 = 14 - 11 \\\\)\\n   \\\\( 3x = 3 \\\\)\\n\\n2. Divide both sides by 3:\\n   \\\\( x = \\\\frac{3}{3} \\\\)\\n   \\\\( x = 1 \\\\)\\n\\nLet's verify this solution using Python.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ci_68be984266148196bc81e309077e9dfd02b17eb82af3d0e3\",\n",
      "      \"code\": \"from sympy import symbols, Eq, solve\\n\\n# Define the variable\\nx = symbols('x')\\n\\n# Define the equation\\nequation = Eq(3*x + 11, 14)\\n\\n# Solve the equation\\nsolution = solve(equation, x)\\nsolution\",\n",
      "      \"container_id\": \"cntr_68be9840667c819093dee2c2319be01e0351424f025bae8d\",\n",
      "      \"outputs\": null,\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"code_interpreter_call\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"msg_68be9843c16c8196864e2e5e929a1cd202b17eb82af3d0e3\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"The solution to the equation \\\\( 3x + 11 = 14 \\\\) is \\\\( x = 1 \\\\).\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"container\": {\n",
      "        \"type\": \"auto\",\n",
      "        \"file_ids\": null\n",
      "      },\n",
      "      \"type\": \"code_interpreter\"\n",
      "    }\n",
      "  ],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 577,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 195,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 772\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "Execution Time: 4.99s\n",
      "\n",
      "--- Performance Summary ---\n",
      "gpt-5-mini: 7.25s\n",
      "gpt-4.1: 4.99s\n",
      "Time Difference: 2.26s (GPT-4.1 faster)\n"
     ]
    }
   ],
   "source": [
    "# Responses API Code Interpreter Performance Comparison\n",
    "instructions = \"You are a personal math tutor. When asked a math question, write and run code using the python tool to answer the question.\"\n",
    "\n",
    "tools_code_interpreter = [\n",
    "    {\n",
    "        \"type\": \"code_interpreter\",\n",
    "        \"container\": {\"type\": \"auto\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "math_question = \"I need to solve the equation 3x + 11 = 14. Can you help me?\"\n",
    "\n",
    "def test_responses_code_interpreter_gpt5():\n",
    "    response = client.responses.create(\n",
    "        model=azure_openai_gpt5_deployment_name,\n",
    "        tools=tools_code_interpreter,\n",
    "        instructions=instructions,\n",
    "        input=math_question,\n",
    "    )\n",
    "    print(\"--- GPT-5 Responses API Code Interpreter ---\")\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    return response.output_text if hasattr(response, 'output_text') else str(response.output)\n",
    "\n",
    "def test_responses_code_interpreter_gpt41():\n",
    "    response = client.responses.create(\n",
    "        model=azure_openai_gpt41_deployment_name,\n",
    "        tools=tools_code_interpreter,\n",
    "        instructions=instructions,\n",
    "        input=math_question,\n",
    "    )\n",
    "    print(\"--- GPT-4.1 Responses API Code Interpreter ---\")\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    return response.output_text if hasattr(response, 'output_text') else str(response.output)\n",
    "\n",
    "# Performance comparison\n",
    "results = measure_and_compare(\"Responses API Code Interpreter\", test_responses_code_interpreter_gpt5, test_responses_code_interpreter_gpt41) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses API - Vision Support Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Responses API Vision Support Performance Comparison ===\n",
      "\n",
      "--- gpt-5-mini Results ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- GPT-5 Responses API Vision ---\n",
      "{\n",
      "  \"id\": \"resp_68be9844c0b48194a86d57297e8270ad03ddd670ee72823a\",\n",
      "  \"created_at\": 1757321284.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5-mini\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"rs_68be9845b3c0819499202e6ac6e0137a03ddd670ee72823a\",\n",
      "      \"summary\": [],\n",
      "      \"type\": \"reasoning\",\n",
      "      \"content\": null,\n",
      "      \"encrypted_content\": null,\n",
      "      \"status\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"msg_68be9847b8cc819488073838dce7274f03ddd670ee72823a\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"A wide alpine mountain range with steep rocky cliffs and densely forested slopes.  \\nGreen meadows and patchwork valleys with scattered clearings at the base.  \\nBright blue sky with scattered white clouds and distant snow-capped peaks.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 238,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 180,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 128\n",
      "    },\n",
      "    \"total_tokens\": 418\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "Execution Time: 4.14s\n",
      "\n",
      "--- gpt-4.1 Results ---\n",
      "--- GPT-4.1 Responses API Vision ---\n",
      "{\n",
      "  \"id\": \"resp_68be9848f0388190a3d003b005618e460ea6b65191f14a80\",\n",
      "  \"created_at\": 1757321289.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4.1\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"msg_68be984a0f248190a7d872c621c642500ea6b65191f14a80\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"This image shows a range of lush green mountains under a partly cloudy blue sky.  \\nThe landscape features steep cliffs, forested slopes, and scattered grassy clearings.  \\nSmall settlements and farmlands can be seen at the foot of the mountains.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": null\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": null\n",
      "  },\n",
      "  \"top_logprobs\": null,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 447,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 51,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 498\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "Execution Time: 2.20s\n",
      "\n",
      "--- Performance Summary ---\n",
      "gpt-5-mini: 4.14s\n",
      "gpt-4.1: 2.20s\n",
      "Time Difference: 1.94s (GPT-4.1 faster)\n"
     ]
    }
   ],
   "source": [
    "# Responses API Vision Support Performance Comparison\n",
    "# Note: Requires the deployed model to support vision and your API version to allow image input.\n",
    "image_url = os.getenv(\"TEST_IMAGE_URL\", \"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Fronalpstock_big.jpg/640px-Fronalpstock_big.jpg\")\n",
    "\n",
    "inputs = [\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"input_text\", \"text\": \"Summarize the main features of this image in three lines in English.\"},\n",
    "        {\"type\": \"input_image\", \"image_url\": image_url},\n",
    "    ]}\n",
    "]\n",
    "\n",
    "def test_responses_vision_gpt5():\n",
    "    response = client.responses.create(\n",
    "        model=azure_openai_gpt5_deployment_name, \n",
    "        input=inputs\n",
    "    )\n",
    "    print(\"--- GPT-5 Responses API Vision ---\")\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    return response.output_text if hasattr(response, 'output_text') else str(response.output)\n",
    "\n",
    "def test_responses_vision_gpt41():\n",
    "    response = client.responses.create(\n",
    "        model=azure_openai_gpt41_deployment_name, \n",
    "        input=inputs\n",
    "    )\n",
    "    print(\"--- GPT-4.1 Responses API Vision ---\")\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    return response.output_text if hasattr(response, 'output_text') else str(response.output)\n",
    "\n",
    "# Performance comparison\n",
    "results = measure_and_compare(\"Responses API Vision Support\", test_responses_vision_gpt5, test_responses_vision_gpt41)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
