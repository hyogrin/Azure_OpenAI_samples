{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure AI Search Query Patterns\n",
    "Azure OpenAI and Azure AI Search Code samples for various search methods in Azure AI Search based on the Azure AI Search Python client library. forked from [https://github.com/Azure/azure-search-vector-samples]\n",
    "\n",
    "## Prerequisites\n",
    "Configure a Python virtual environment for 3.10 or later: \n",
    " 1. open the Command Palette (Ctrl+Shift+P).\n",
    " 1. Search for Python: Create Environment.\n",
    " 1. select Venv / Conda and choose where to create the new environment.\n",
    " 1. Select the Python interpreter version. Create with version 3.10 or later.\n",
    "\n",
    "For a dependency installation, run the code below to install the packages required to run it. \n",
    "\n",
    "```bash\n",
    "# Create a virtual environment\n",
    "python -m venv venv\n",
    "\n",
    "# Activate the virtual environment\n",
    "# On Windows\n",
    "venv\\Scripts\\activate\n",
    "\n",
    "# On macOS/Linux\n",
    "source venv/bin/activate\n",
    "\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "## Set up your environment\n",
    "Git clone the repository to your local machine. \n",
    "\n",
    "```bash\n",
    "git clone https://github.com/hyogrin/Azure_OpenAI_samples.git\n",
    "```\n",
    "\n",
    "Create an .env file based on the .env-sample file. Copy the new .env file to the folder containing your notebook and update the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "import sys\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SimpleField,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIVectorizerParameters,\n",
    "    SemanticConfiguration,\n",
    "    SemanticSearch,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    "    SearchIndex\n",
    ")\n",
    "\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure environment variables\n",
    "load_dotenv()\n",
    "index_name = \"quickdemo\"\n",
    "MAX_RETRIES = 3\n",
    "search_endpoint = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),        # Azure OpenAI base URL\n",
    "    api_key        = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version    = os.getenv(\"AZURE_OPENAI_CHAT_API_VERSION\"),\n",
    "    max_retries    = MAX_RETRIES\n",
    ")\n",
    "\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "deployment_embedding_name = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "\n",
    "credential = AzureKeyCredential(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings\n",
    "- Insert Azure AI Search indexes by reading data, creating OpenAI embeddings, and exporting to a valid format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 azureuser azureuser 74K Mar  5 03:22 data/text-sample.json\n"
     ]
    }
   ],
   "source": [
    "!ls data/text-sample.json -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Document Embeddings using OpenAI Ada 002\n",
    "\n",
    "# Read the text-sample.json\n",
    "# with open(\"text-sample.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "#     input_data = json.load(file)\n",
    "\n",
    "df_input_data = pd.read_json(os.path.join(os.getcwd(),'data/text-sample.json'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.options.mode.chained_assignment = None #https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#evaluation-order-matters\n",
    "\n",
    "# s is input text\n",
    "def normalize_text(s, sep_token = \" \\n \"):\n",
    "    s = re.sub(r'\\s+',  ' ', s).strip()\n",
    "    s = re.sub(r\". ,\",\"\",s)\n",
    "    # remove all instances of multiple spaces\n",
    "    s = s.replace(\"..\",\".\")\n",
    "    s = s.replace(\". .\",\".\")\n",
    "    s = s.replace(\"\\n\", \"\")\n",
    "    s = s.strip()\n",
    "    \n",
    "    return s\n",
    "\n",
    "df_input_data['content']= df_input_data[\"content\"].apply(lambda x : normalize_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To take advantage of the Embedding API provided by Azure OpenAI, we check that the document does not have more than 8,192 tokens of text in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Azure App Service</td>\n",
       "      <td>Azure App Service is a fully managed platform ...</td>\n",
       "      <td>Web</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Azure Functions</td>\n",
       "      <td>Azure Functions is a serverless compute servic...</td>\n",
       "      <td>Compute</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Azure Cognitive Services</td>\n",
       "      <td>Azure Cognitive Services are a set of AI servi...</td>\n",
       "      <td>AI + Machine Learning</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Azure Storage</td>\n",
       "      <td>Azure Storage is a scalable, durable, and high...</td>\n",
       "      <td>Storage</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Azure SQL Database</td>\n",
       "      <td>Azure SQL Database is a fully managed relation...</td>\n",
       "      <td>Databases</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>104</td>\n",
       "      <td>Azure Site Recovery</td>\n",
       "      <td>Azure Site Recovery is a fully managed, disast...</td>\n",
       "      <td>Management + Governance</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>105</td>\n",
       "      <td>Azure Web PubSub</td>\n",
       "      <td>Azure Web PubSub is a fully managed, real-time...</td>\n",
       "      <td>Web</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>106</td>\n",
       "      <td>Azure Data Factory</td>\n",
       "      <td>Azure Data Factory is a cloud-based data integ...</td>\n",
       "      <td>Analytics</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>107</td>\n",
       "      <td>Azure Data Bricks</td>\n",
       "      <td>Azure Data Bricks is a fully managed, Apache S...</td>\n",
       "      <td>Analytics</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>108</td>\n",
       "      <td>Azure Bastion</td>\n",
       "      <td>Azure Bastion is a fully managed, secure, and ...</td>\n",
       "      <td>Security</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                     title  \\\n",
       "0      1         Azure App Service   \n",
       "1      2           Azure Functions   \n",
       "2      3  Azure Cognitive Services   \n",
       "3      4             Azure Storage   \n",
       "4      5        Azure SQL Database   \n",
       "..   ...                       ...   \n",
       "103  104       Azure Site Recovery   \n",
       "104  105          Azure Web PubSub   \n",
       "105  106        Azure Data Factory   \n",
       "106  107         Azure Data Bricks   \n",
       "107  108             Azure Bastion   \n",
       "\n",
       "                                               content  \\\n",
       "0    Azure App Service is a fully managed platform ...   \n",
       "1    Azure Functions is a serverless compute servic...   \n",
       "2    Azure Cognitive Services are a set of AI servi...   \n",
       "3    Azure Storage is a scalable, durable, and high...   \n",
       "4    Azure SQL Database is a fully managed relation...   \n",
       "..                                                 ...   \n",
       "103  Azure Site Recovery is a fully managed, disast...   \n",
       "104  Azure Web PubSub is a fully managed, real-time...   \n",
       "105  Azure Data Factory is a cloud-based data integ...   \n",
       "106  Azure Data Bricks is a fully managed, Apache S...   \n",
       "107  Azure Bastion is a fully managed, secure, and ...   \n",
       "\n",
       "                    category  n_tokens  \n",
       "0                        Web        93  \n",
       "1                    Compute        85  \n",
       "2      AI + Machine Learning        91  \n",
       "3                    Storage        95  \n",
       "4                  Databases        93  \n",
       "..                       ...       ...  \n",
       "103  Management + Governance       103  \n",
       "104                      Web       100  \n",
       "105                Analytics       108  \n",
       "106                Analytics       110  \n",
       "107                 Security       106  \n",
       "\n",
       "[108 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "df_input_data['n_tokens'] = df_input_data[\"content\"].apply(lambda x: len(tokenizer.encode(x)))\n",
    "df_input_data = df_input_data[df_input_data.n_tokens<8192]\n",
    "len(df_input_data)\n",
    "df_input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After completing the verification, delete the columns that are no longer needed, and save the data for insertion into Azure AI Search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input_data = df_input_data.drop('n_tokens', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Document Embeddings using OpenAI Ada 002\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "# Function to generate embeddings for title and content fields, also used for query embeddings\n",
    "def get_embedding(text, model=deployment_embedding_name): # model = \"deployment_name\"\n",
    "    return client.embeddings.create(input = [text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model should be set to the deployment name you chose when you deployed the text-embedding-ada-002 (Version 2) model\n",
    "df_input_data['titleVector'] = df_input_data[\"title\"].apply(lambda x : get_embedding (x, model = deployment_embedding_name)) \n",
    "df_input_data['contentVector'] = df_input_data[\"content\"].apply(lambda x : get_embedding (x, model = deployment_embedding_name)) \n",
    "df_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input_data.to_csv(os.path.join(os.getcwd(),'data/embedding_input_data.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your search index\n",
    "Create your search index schema and vector search configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a search index\n",
    "index_client = SearchIndexClient(endpoint=search_endpoint, credential=credential)\n",
    "fields = [\n",
    "    SearchField(name=\"id\", key=True, type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False),  \n",
    "    SearchField(name=\"title\", type=SearchFieldDataType.String, searchable=True),\n",
    "    SearchField(name=\"content\", type=SearchFieldDataType.String, searchable=True),\n",
    "    SearchField(name=\"content_ko\", type=SearchFieldDataType.String, searchable=True, analyzer_name=\"ko.lucene\"),\n",
    "    SearchField(name=\"category\", type=SearchFieldDataType.String, filterable=True),\n",
    "    SearchField(\n",
    "        name=\"titleVector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        searchable=True,\n",
    "        vector_search_dimensions=1536,\n",
    "        vector_search_profile_name=\"myHnswProfile\",  # Ensure vector_search_profile is set\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"contentVector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        searchable=True,\n",
    "        vector_search_dimensions=1536,\n",
    "        vector_search_profile_name=\"myHnswProfile\",  # Ensure vector_search_profile is set\n",
    "    ),\n",
    "]\n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(  \n",
    "    algorithms=[  \n",
    "        HnswAlgorithmConfiguration(name=\"myHnsw\"),\n",
    "    ],  \n",
    "    profiles=[  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myHnswProfile\",  \n",
    "            algorithm_configuration_name=\"myHnsw\",  \n",
    "            vectorizer_name=\"myOpenAI\",  \n",
    "        )\n",
    "    ],  \n",
    "    vectorizers=[  \n",
    "        AzureOpenAIVectorizer(  \n",
    "            vectorizer_name=\"myOpenAI\",  \n",
    "            kind=\"azureOpenAI\",  \n",
    "            azure_open_ai_parameters=AzureOpenAIVectorizerParameters(  \n",
    "                resource_uri=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),  \n",
    "                deployment_id=deployment_embedding_name,\n",
    "                model_name=deployment_embedding_name,\n",
    "                api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "            ),\n",
    "        ),  \n",
    "    ],  \n",
    ")  \n",
    "\n",
    "\n",
    "  \n",
    "semantic_config = SemanticConfiguration(  \n",
    "    name=\"my-semantic-config\",  \n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"title\"),\n",
    "        content_fields=[SemanticField(field_name=\"content\")]  \n",
    "    ),  \n",
    ")\n",
    "\n",
    "# Create the semantic search with the configuration  \n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])  \n",
    "  \n",
    "# Create the search index\n",
    "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search, semantic_search=semantic_search)  \n",
    "result = index_client.create_or_update_index(index)  \n",
    "print(f\"{result.name} created\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert text and embeddings into vector store\n",
    "Add texts and metadata from the JSON data to the vector store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data_embeddings.csv to search_client.upload_documents to create the index \n",
    "ddocuments = df_input_data.to_dict(orient='records')\n",
    "for doc in documents:\n",
    "    doc['id'] = str(doc['id'])\n",
    "search_client = SearchClient(\n",
    "    endpoint=search_endpoint, index_name=index_name, credential=credential\n",
    ")\n",
    "result = search_client.upload_documents(documents)\n",
    "\n",
    "print(f\"Uploaded {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a vector similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.models import VectorizedQuery\n",
    "\n",
    "# Pure Vector Search\n",
    "query = \"I want to monitor my applications\"\n",
    "\n",
    "\n",
    "search_client = SearchClient(search_endpoint, index_name, credential=credential)\n",
    "embedding = get_embedding (query, model = deployment_embedding_name)\n",
    "\n",
    "vector_query = VectorizedQuery(vector=embedding, k_nearest_neighbors=3, fields=\"contentVector\")\n",
    "\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=None,\n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "    print(f\"Category: {result['category']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We utilize the VectorizableTextQuery class provided by Azure AI Search to find similar documents immediately without embedding and querying the query separately.\n",
    "- The same can be used for queries in other languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure Vector Search multi-lingual (e.g 'tools for software development' in Dutch)\n",
    "query = \"Application을 모니터링하고 싶어\"\n",
    "\n",
    "search_client = SearchClient(search_endpoint, index_name, credential=credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=3, fields=\"contentVector\")\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=None,\n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "    print(f\"Category: {result['category']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This method ignores indexing and performs an exhaustive KNN search on the vector index. This can be used in combination with filters. Allows you to check the ground-truth value as a reference point for tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure Vector Search\n",
    "query = \"tools for software development\"  \n",
    "  \n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=3, fields=\"contentVector\", exhaustive=True)\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['content']}\")  \n",
    "    print(f\"Category: {result['category']}\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Field Vector Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In addition to ContentVector, you can use titleVector to perform Cross-Field Vector Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Field Vector Search\n",
    "query = \"I want to monitor my applications\"\n",
    "\n",
    "search_client = SearchClient(search_endpoint, index_name, credential=credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=3, fields=\"titleVector, contentVector\")\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=None,\n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "    print(f\"Category: {result['category']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a Multi-Vector Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can use one query for two VectorFields or two queries for one VectorField to perform a Multi-Vector Search.\n",
    "- For example, you can perform a Multi-Vector Search by creating additional queries through query rewrite.\n",
    "- This can be weighted to adjust the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Vector Search\n",
    "query1 = \"software development for ds\"\n",
    "query2 = \"데이터를 가지고 실험을 하거나 통계를 보고 모델을 제작할 때 사용할 수 있는 도구\"\n",
    "\n",
    "search_client = SearchClient(search_endpoint, index_name, credential=credential)\n",
    "vector_query1 = VectorizableTextQuery(text=query1, k_nearest_neighbors=3, fields=\"titleVector, contentVector\", weight=2)\n",
    "vector_query2 = VectorizableTextQuery(text=query2, k_nearest_neighbors=3, fields=\"titleVector, contentVector\", weight=0.5)\n",
    "# vector_query1 = VectorizableTextQuery(text=query1, k_nearest_neighbors=3, fields=\"titleVector, contentVector\", weight=2)\n",
    "# vector_query2 = VectorizableTextQuery(text=query2, k_nearest_neighbors=3, fields=\"titleVector, contentVector\", weight=0.5)\n",
    "\n",
    "\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=None,\n",
    "    vector_queries=[vector_query1, vector_query2],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "    print(f\"Category: {result['category']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a Pure Vector Search with a filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can add filters to your Vector Search to limit your results, especially if your search is broad and you have a lot of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.models import VectorFilterMode\n",
    "\n",
    "# Pure Vector Search with Filter\n",
    "query = \"tools for software development\"\n",
    "\n",
    "search_client = SearchClient(search_endpoint, index_name, credential=credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=3, fields=\"contentVector\")\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=None,\n",
    "    vector_queries=[vector_query],\n",
    "    vector_filter_mode=VectorFilterMode.PRE_FILTER,\n",
    "    filter=\"category eq 'Developer Tools'\",\n",
    "    select=[\"title\", \"content\", \"category\"]\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "    print(f\"Category: {result['category']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a Hybrid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can perform searches using a mix of searchtext and vector search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Search\n",
    "query = \"integration\"\n",
    "\n",
    "search_client = SearchClient(search_endpoint, index_name, AzureKeyCredential(key))\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=3, fields=\"contentVector\")\n",
    "\n",
    "vector_query_result = search_client.search(\n",
    "    search_text=None, vector_queries=[vector_query], select=[\"title\", \"content\", \"category\"], top=3)\n",
    "\n",
    "hybrid_query_result = search_client.search(\n",
    "    search_text=query, vector_queries=[vector_query], select=[\"title\", \"content\", \"category\"], top=3)\n",
    "\n",
    "print(\"----------------------------vector search---------------------------------\")\n",
    "\n",
    "for result in vector_query_result:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "    print(f\"Category: {result['category']}\\n\")\n",
    "\n",
    "print(\"----------------------------hybrid search---------------------------------\")\n",
    "\n",
    "for result in hybrid_query_result:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "    print(f\"Category: {result['category']}\\n\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can adjust the results by weighting the vector query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Search\n",
    "query = \"integration\"\n",
    "\n",
    "search_client = SearchClient(search_endpoint, index_name, AzureKeyCredential(key))\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=3, fields=\"contentVector\", weight=0.2)\n",
    "\n",
    "vector_query_result = search_client.search(\n",
    "    search_text=None, vector_queries=[vector_query], select=[\"title\", \"content\", \"category\"], top=3)\n",
    "\n",
    "hybrid_query_result = search_client.search(\n",
    "    search_text=query, vector_queries=[vector_query], select=[\"title\", \"content\", \"category\"], top=3)\n",
    "\n",
    "print(\"----------------------------vector search---------------------------------\")\n",
    "\n",
    "for result in vector_query_result:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "    print(f\"Category: {result['category']}\\n\")\n",
    "\n",
    "print(\"----------------------------hybrid search---------------------------------\")\n",
    "\n",
    "for result in hybrid_query_result:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "    print(f\"Category: {result['category']}\\n\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hybrid search + Semantic reranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can perform hybrid searches by mixing semantic reranking with the results of a hybrid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.models import QueryType, QueryCaptionType, QueryAnswerType\n",
    "\n",
    "# Semantic Hybrid Search\n",
    "query = \"what is azure sarch?\"\n",
    "\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=3, fields=\"contentVector\", exhaustive=True)\n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=query,  \n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    "    query_type=QueryType.SEMANTIC, semantic_configuration_name='my-semantic-config', query_caption=QueryCaptionType.EXTRACTIVE, query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "    top=3\n",
    ")\n",
    "\n",
    "semantic_answers = results.get_answers()\n",
    "for answer in semantic_answers:\n",
    "    if answer.highlights:\n",
    "        print(f\"Semantic Answer: {answer.highlights}\")\n",
    "    else:\n",
    "        print(f\"Semantic Answer: {answer.text}\")\n",
    "    print(f\"Semantic Answer Score: {answer.score}\\n\")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Reranker Score: {result['@search.reranker_score']}\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "    print(f\"Category: {result['category']}\")\n",
    "\n",
    "    captions = result[\"@search.captions\"]\n",
    "    if captions:\n",
    "        caption = captions[0]\n",
    "        if caption.highlights:\n",
    "            print(f\"Caption: {caption.highlights}\\n\")\n",
    "        else:\n",
    "            print(f\"Caption: {caption.text}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_aisearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
