{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure AI Foundry trace \n",
    "You can trace your application with Azure AI Foundry project library. This provides support for tracing with OpenTelemetry.\n",
    "\n",
    "> ✨ ***Note*** <br>\n",
    "> Please check the prerequisites and set up your environment before running the code below. First follow steps to create an AI Project if you don't have one already. To enable tracing, first ensure your project has an attached Application Insights resource. Go to the Tracing page of your project in Azure AI Foundry portal and follow instructions to create or attach Application Insights.\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "Configure a Python virtual environment for 3.10 or later: \n",
    " 1. An Azure Subscription.\n",
    " 1. An Azure AI project, see Create a project in Azure AI Foundry portal.\n",
    " 1. An AI model supporting the Azure AI model inference API deployed through Azure AI Foundry.\n",
    " 1. Ensure your project has an attached Application Insights resource\n",
    " 1. Open the Command Palette (Ctrl+Shift+P).\n",
    " 1. Search for Python: Create Environment.\n",
    " 1. select Venv / Conda and choose where to create the new environment.\n",
    " 1. Select the Python interpreter version. Create with version 3.10 or later.\n",
    "\n",
    "For a dependency installation, run the code below to install the packages required to run it. \n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "## Set up your environment\n",
    "Git clone the repository to your local machine. \n",
    "\n",
    "```bash\n",
    "git clone https://github.com/hyogrin/Azure_OpenAI_samples.git\n",
    "```\n",
    "\n",
    "Create an .env file based on the .env-sample file. Copy the new .env file to the folder containing your notebook and update the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "from opentelemetry import trace\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "from azure.ai.inference.models import (\n",
    "    ToolMessage,\n",
    "    AssistantMessage,\n",
    "    ChatCompletionsToolCall,\n",
    "    ChatCompletionsToolDefinition,\n",
    "    FunctionDefinition,\n",
    ")\n",
    "\n",
    "# Install opentelemetry with command \"pip install opentelemetry-sdk\".\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor, ConsoleSpanExporter\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage, CompletionsFinishReason\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "\n",
    "azure_model_inference_endpoint = os.getenv(\"AZURE_MODEL_INFERENCE_ENDPOINT\")\n",
    "aoai_api_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "aoai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "aoai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "aoai_deployment_name = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "project_connection_string = os.getenv(\"PROJECT_CONNECTION_STRING\")\n",
    "application_insights_connection_string = os.getenv(\"APPLICATIONINSIGHTS_CONNECTION_STRING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Copy the connection string from your Application Insights resource\n",
    "The connection string is unique and specifies where the Azure Monitor OpenTelemetry Distro sends the telemetry it collects.\n",
    "To copy the connection string:\n",
    "<br>\n",
    "- Go to the Overview pane of your Application Insights resource.\n",
    "- Find your connection string.\n",
    "- Hover over the connection string and select the Copy to clipboard icon.\n",
    "\n",
    "![Migrate from instrumentation keys to connection strings](migrate-from-instrumentation-keys-to-connection-strings.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Configure Azure Monitor with AIProject client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#Use Azure Monitor for OpenTelemetry via project client\n",
    "from azure.identity import DefaultAzureCredential\n",
    "credential = DefaultAzureCredential()\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=credential,\n",
    "    conn_str=project_connection_string,\n",
    ")\n",
    "\n",
    "# Enable Azure Monitor tracing\n",
    "application_insights_connection_string = project_client.telemetry.get_connection_string()\n",
    "if not application_insights_connection_string:\n",
    "    print(\"Application Insights was not enabled for this project.\")\n",
    "    print(\"Enable it via the 'Tracing' tab in your AI Foundry project page.\")\n",
    "    exit()\n",
    "\n",
    "# Enable additional instrumentations if openai and langchain \n",
    "# langchain - https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/trace-local-sdk?tabs=python#enable-tracing-for-langchain\n",
    "# which are not included by Azure Monitor out of the box\n",
    "project_client.telemetry.enable()\n",
    "# you can also use the application insights connection string directly\n",
    "configure_azure_monitor(connection_string=application_insights_connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Set up OpenAIInstrumentor to test Azure Open AI tracing \n",
    "- https://pypi.org/project/opentelemetry-instrumentation-openai-v2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry.instrumentation.openai_v2 import OpenAIInstrumentor\n",
    "\n",
    "# OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT - Optional. Set to `true` to trace the content of chat messages, which may contain personal data. False by default.\n",
    "os.environ[\"OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT\"] = \"true\"\n",
    "\n",
    "# Instrument Azure Open AI API \n",
    "OpenAIInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    aoai_client = AzureOpenAI(\n",
    "        azure_endpoint = aoai_api_endpoint,\n",
    "        api_key        = aoai_api_key,\n",
    "        api_version    = aoai_api_version\n",
    "    )\n",
    "except (ValueError, TypeError) as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Corporation, one of the largest and most influential technology companies in the world, has a rich history that spans several decades. Here’s an overview of its development:\n",
      "\n",
      "### Foundation and Early Years (1975-1980)\n",
      "\n",
      "- **1975**: Microsoft was founded by Bill Gates and Paul Allen in Albuquerque, New Mexico. Initially, the company focused on developing and selling a version of the BASIC programming language for the Altair 8800 microcomputer.\n",
      "\n",
      "- **1976-1980**: Following their initial success, Microsoft relocated to Washington State. The company began expanding its software offerings, creating a variety of programming languages and tools for different computer systems.\n",
      "\n",
      "### Rise to Prominence (1980-1990)\n",
      "\n",
      "- **1980**: Microsoft entered into a partnership with IBM to create an operating system for their first personal computer (PC). Although they didn’t develop the OS themselves, they purchased QDOS (Quick and Dirty Operating System) from Seattle Computer Products, modified it, and licensed it to IBM. This operating system later became known as MS-DOS.\n",
      "\n",
      "- **1983**: Microsoft launched Microsoft Word, its word processing software. \n",
      "\n",
      "- **1985**: The first version of Microsoft Windows was released, designed as a graphical extension for MS-DOS. This marked the beginning of Microsoft's shift towards graphical interfaces.\n",
      "\n",
      "- **1986**: Microsoft went public with an initial public offering (IPO) that made many employees and investors wealthy. It also solidified Gates and Allen’s fortunes and status in the tech world.\n",
      "\n",
      "### Dominance and Growth (1990s)\n",
      "\n",
      "- **1990**: Microsoft introduced Windows 3.0, which enjoyed tremendous popularity and became a significant success, establishing Windows as an industry standard for PC operating systems.\n",
      "\n",
      "- **1995**: Windows 95 was released, a major upgrade that included a new user interface and supported long filenames. It became a cultural phenomenon and was a commercial success. Microsoft also launched Internet Explorer during this time.\n",
      "\n",
      "- **1998**: Microsoft faced antitrust lawsuits in the United States and Europe due to its monopolistic practices, particularly concerning its dominance in the PC operating system market and bundling Internet Explorer with Windows.\n",
      "\n",
      "### Legal Challenges and Diversification (2000-2010)\n",
      "\n",
      "- **2001**: Microsoft released Windows XP, which became one of the most popular operating systems of all time. The same year, Microsoft launched the Xbox gaming console, entering the gaming market with significant ambition.\n",
      "\n",
      "- **2007**: Microsoft introduced Windows Vista, aimed at improving security and usability, though it received mixed reviews.\n",
      "\n",
      "- **2010**: Microsoft faced various challenges, including the rise of competitors in both the operating system and the online space (e.g., Google with search and Android). The company began exploring new areas such as cloud computing with products like Windows Azure.\n",
      "\n",
      "### Cloud and Mobile Era (2010-Present)\n",
      "\n",
      "- **2012**: Microsoft launched Windows 8, designed for touch interfaces and aimed to unify the experience across devices. However, it received criticism and mixed reviews.\n",
      "\n",
      "- **2014**: Satya Nadella succeeded Steve Ballmer as CEO. Under his leadership, Microsoft shifted its focus towards cloud computing (with Azure) and productivity (with Office 365).\n",
      "\n",
      "- **2015**: Microsoft released Windows 10, which aimed to address previous criticisms and unify the Windows experience across devices. \n",
      "\n",
      "- **2016**: Microsoft acquired LinkedIn for approximately $26.2 billion, significantly expanding its influence in the professional social networking space.\n",
      "\n",
      "- **2020**: The COVID-19 pandemic accelerated the adoption of remote work technologies, leading to increased demand for Microsoft Teams and other cloud services.\n",
      "\n",
      "- **2023**: Microsoft continued to enhance AI integration, leveraging investments in OpenAI and other advanced technologies to integrate AI capabilities across its products.\n",
      "\n",
      "### Ongoing Impact\n",
      "\n",
      "Today, Microsoft is a leading player in various technology sectors, including software, hardware, gaming, and cloud computing. Its products and services, such as Microsoft Office, Windows, Azure, and Xbox, are widely used around the globe. The company remains influential in setting industry standards and driving technological advancements.\n"
     ]
    }
   ],
   "source": [
    "question = \"Tell me the history of OpenAI and its models.\"\n",
    "\n",
    "user_message = f\"\"\"\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "# Simple API Call\n",
    "response = aoai_client.chat.completions.create(\n",
    "    model=aoai_deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_message},\n",
    "    ],\n",
    "  \n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12 inches in a foot.\n"
     ]
    }
   ],
   "source": [
    "response = aoai_client.chat.completions.create(\n",
    "    model=aoai_deployment_name,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How many inches are in a feet?\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trace function calling with Azure OpenAI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry import trace\n",
    "#The tracer.start_as_current_span decorator will trace the function call and enable adding additional attributes\n",
    "#to the span in the function implementation. Note that this will trace the function parameters and their values.\n",
    "tracer = trace.get_tracer(__name__)\n",
    "\n",
    "@tracer.start_as_current_span(\"get_temperature\")  # type: ignore\n",
    "def get_temperature(city: str) -> str:\n",
    "\n",
    "    # Adding attributes to the current span\n",
    "    span = trace.get_current_span()\n",
    "    span.set_attribute(\"requested_city\", city)\n",
    "\n",
    "    if city == \"Seattle\":\n",
    "        return \"75\"\n",
    "    elif city == \"New York City\":\n",
    "        return \"80\"\n",
    "    else:\n",
    "        return \"Unavailable\"\n",
    "\n",
    "\n",
    "# [END trace_function]\n",
    "\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    if city == \"Seattle\":\n",
    "        return \"Nice weather\"\n",
    "    elif city == \"New York City\":\n",
    "        return \"Good weather\"\n",
    "    else:\n",
    "        return \"Unavailable\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "weather_description = ChatCompletionsToolDefinition(\n",
    "    function=FunctionDefinition(\n",
    "        name=\"get_weather\",\n",
    "        description=\"Returns description of the weather in the specified city\",\n",
    "        parameters={\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"city\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the city for which weather info is requested\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"city\"],\n",
    "        },\n",
    "    )\n",
    ")\n",
    "\n",
    "temperature_in_city = ChatCompletionsToolDefinition(\n",
    "    function=FunctionDefinition(\n",
    "        name=\"get_temperature\",\n",
    "        description=\"Returns the current temperature for the specified city\",\n",
    "        parameters={\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"city\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the city for which temperature info is requested\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"city\"],\n",
    "        },\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling function `get_weather` with arguments {'city': 'Korea'}\n",
      "Function response = Unavailable\n",
      "Calling function `get_temperature` with arguments {'city': 'Korea'}\n",
      "Function response = Unavailable\n",
      "Model response = It seems that the weather and temperature information for \"Korea\" is unavailable at the moment. If you need information for a specific city in Korea, please provide the name of that city.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "        SystemMessage(\"You are a helpful assistant.\"),\n",
    "        UserMessage(\"What is the weather and temperature in Korea?\"),\n",
    "    ]\n",
    "\n",
    "tools = [weather_description, temperature_in_city]\n",
    "\n",
    "response = aoai_client.chat.completions.create(model=aoai_deployment_name, messages=messages, tools=tools)\n",
    "\n",
    "if response.choices[0].finish_reason == \"tool_calls\":\n",
    "    messages.append(AssistantMessage(\n",
    "        tool_calls=response.choices[0].message.tool_calls\n",
    "    ))\n",
    "\n",
    "    if response.choices[0].message.tool_calls is not None and len(response.choices[0].message.tool_calls) > 0:\n",
    "        for tool_call in response.choices[0].message.tool_calls:\n",
    "            function_args = json.loads(tool_call.function.arguments.replace(\"'\", '\"'))\n",
    "            print(f\"Calling function `{tool_call.function.name}` with arguments {function_args}\")\n",
    "            callable_func = globals()[tool_call.function.name]\n",
    "            function_response = callable_func(**function_args)\n",
    "            print(f\"Function response = {function_response}\")\n",
    "\n",
    "            messages.append(ToolMessage(\n",
    "                content=function_response,\n",
    "                tool_call_id=tool_call.id\n",
    "            ))\n",
    "\n",
    "        response = aoai_client.chat.completions.create(\n",
    "            model=aoai_deployment_name, \n",
    "            messages=messages,\n",
    "            tools=tools\n",
    "        )\n",
    "\n",
    "print(f\"Model response = {response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Set up AIInferenceInstrumentor to test AI Inference tracing\n",
    "- https://pypi.org/project/azure-ai-inference/\n",
    "- https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/trace-local-sdk?tabs=python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference.tracing import AIInferenceInstrumentor \n",
    "\n",
    "os.environ[\"AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED\"] = 'true'\n",
    "\n",
    "# Instrument AI Inference API \n",
    "AIInferenceInstrumentor().instrument() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trace function calling with Azure OpenAI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_inference_client = ChatCompletionsClient(endpoint=azure_model_inference_endpoint, credential=AzureKeyCredential(aoai_api_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Corporation, a multinational technology company, was founded on April 4, 1975, by Bill Gates and Paul Allen in Albuquerque, New Mexico. The company initially focused on creating software for the Altair 8800, an early personal computer. \n",
      "\n",
      "### 1970s: Formation and Early Products\n",
      "- **1975:** Bill Gates and Paul Allen write a version of the BASIC programming language for the Altair 8800, marking Microsoft’s first product.\n",
      "- **1976:** The company is officially incorporated as \"Microsoft,\" a blend of \"microcomputer\" and \"software.\"\n",
      "- **1979:** Microsoft relocates to Bellevue, Washington, to accommodate growth.\n",
      "\n",
      "### 1980s: Rise to Prominence\n",
      "- **1980:** Microsoft enters into a contract with IBM to provide an operating system (OS) for their first personal computer (PC). They purchase an OS called QDOS (Quick and Dirty Operating System) and adapt it into MS-DOS.\n",
      "- **1981:** Microsoft becomes a leading PC software vendor.\n",
      "- **1985:** Microsoft launches Windows 1.0, a graphical operating environment running on top of MS-DOS. \n",
      "\n",
      "### 1990s: Expansion and Windows Dominance\n",
      "- **1990:** Microsoft releases Windows 3.0, which becomes a massive success, leading to the widespread adoption of Windows.\n",
      "- **1995:** The launch of Windows 95 marks a significant milestone, featuring an integrated Start menu and taskbar. It sells millions of copies within weeks.\n",
      "- **1998:** Microsoft releases Windows 98 and faces increasing scrutiny and legal challenges regarding antitrust issues.\n",
      "\n",
      "### 2000s: Legal Challenges and New Directions\n",
      "- **2000:** Windows 2000 and Windows ME are released, though the latter receives criticism.\n",
      "- **2001:** The release of Windows XP, known for its improved stability and user-friendly interface. Microsoft also enters the gaming industry with the launch of the Xbox console.\n",
      "- **2007:** Microsoft launches Windows Vista, which receives mixed reviews. They also introduce the Microsoft Office 2007 suite.\n",
      "\n",
      "### 2010s: Adaptation and Cloud Strategy\n",
      "- **2010:** Microsoft releases Windows Phone and starts to shift towards a cloud-centric approach with Azure.\n",
      "- **2012:** The launch of Windows 8, a radical overhaul focused on touch interfaces, attracts mixed feedback and leads to a backlash from traditional users.\n",
      "- **2014:** Satya Nadella becomes CEO, initiating a cultural transformation and a focus on cloud services and productivity tools.\n",
      "\n",
      "### 2020s: Continued Innovation and Growth\n",
      "- **2021:** Microsoft emerges as a leader in cloud computing with Azure, and their focus on remote work tools like Teams sees significant growth due to the COVID-19 pandemic.\n",
      "- **2023:** Microsoft expands its AI capabilities, notably integrating AI tools into its Office suite and Azure services, significantly enhancing productivity for users.\n",
      "\n",
      "### Legacy and Impact\n",
      "Microsoft's legacy includes pivotal contributions to the software industry, the personal computing revolution, and ongoing influence in cloud computing and artificial intelligence. With a commitment to innovation, Microsoft continues to be a major player in the global technology landscape, impacting millions of users and businesses worldwide.\n"
     ]
    }
   ],
   "source": [
    "question = \"Tell me the history of Microsoft\"\n",
    "\n",
    "user_message = f\"\"\"\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "# Simple API Call\n",
    "response = ai_inference_client.complete(\n",
    "    model=aoai_deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_message},\n",
    "    ],\n",
    "  \n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5,280 feet in a mile.\n"
     ]
    }
   ],
   "source": [
    "response = aoai_client.chat.completions.create(\n",
    "    model=aoai_deployment_name,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How many feet are in a mile?\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling function `get_weather` with arguments {'city': 'Seattle'}\n",
      "Function response = Nice weather\n",
      "Calling function `get_temperature` with arguments {'city': 'Seattle'}\n",
      "Function response = 75\n",
      "Model response = The weather in Seattle is nice, and the current temperature is 75°F.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant.\"),\n",
    "    UserMessage(\"What is the weather and temperature in Seattle?\"),\n",
    "]\n",
    "\n",
    "response = ai_inference_client.complete(messages=messages, tools=[weather_description, temperature_in_city], model=aoai_deployment_name)\n",
    "\n",
    "if response.choices[0].finish_reason == CompletionsFinishReason.TOOL_CALLS:\n",
    "    # Append the previous model response to the chat history\n",
    "    messages.append(AssistantMessage(tool_calls=response.choices[0].message.tool_calls))\n",
    "    # The tool should be of type function call.\n",
    "    if response.choices[0].message.tool_calls is not None and len(response.choices[0].message.tool_calls) > 0:\n",
    "        for tool_call in response.choices[0].message.tool_calls:\n",
    "            if type(tool_call) is ChatCompletionsToolCall:\n",
    "                function_args = json.loads(tool_call.function.arguments.replace(\"'\", '\"'))\n",
    "                print(f\"Calling function `{tool_call.function.name}` with arguments {function_args}\")\n",
    "                callable_func = globals()[tool_call.function.name]\n",
    "                function_response = callable_func(**function_args)\n",
    "                print(f\"Function response = {function_response}\")\n",
    "                # Provide the tool response to the model, by appending it to the chat history\n",
    "                messages.append(ToolMessage(function_response, tool_call_id=tool_call.id))\n",
    "                # With the additional tools information on hand, get another response from the model\n",
    "        response = ai_inference_client.complete(messages=messages, tools=[weather_description, temperature_in_city], model=aoai_deployment_name)\n",
    "\n",
    "print(f\"Model response = {response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Use tracing to view performance and optimize your application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tracing in AI Foundry](tracing_in_ai_foundry.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tracing in AI Foundry](tracing_in_ai_foundry2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. uninstrument the OpenAIInstrumentor and AIInferenceInstrumentor\n",
    "> 📍 ***important*** <br>\n",
    "> The OpenAIInstrumentor and AIInferenceInstrumentor are not uninstrumented automatically when the program ends. You must call the uninstrument method to stop tracing.\n",
    "> This is important to avoid memory leaks and ensure that the tracing data is sent to the Azure Monitor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry.instrumentation.openai_v2 import OpenAIInstrumentor\n",
    "\n",
    "# Instrument Azure Open AI API \n",
    "OpenAIInstrumentor().uninstrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference.tracing import AIInferenceInstrumentor \n",
    "\n",
    "AIInferenceInstrumentor().uninstrument()\n",
    "# [END uninstrument_inferencing]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_trace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
