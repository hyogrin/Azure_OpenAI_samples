{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Eval] Evaluate Trained Custom Speech Models\n",
    "This sample demonstrates how to evaluate Trained Custom Speech models calling REST API. \n",
    "\n",
    "> ‚ú® ***Note*** <br>\n",
    "> You can test the accuracy of your custom model by creating a test. A test requires a collection of audio files and their corresponding transcriptions. You can compare a custom model's accuracy with a speech to text base model or another custom model. After you get the test results, evaluate the word error rate (WER) compared to speech recognition results. \n",
    "\n",
    "## Prerequisites\n",
    "Configure a Python virtual environment for 3.10 or later: \n",
    " 1. open the Command Palette (Ctrl+Shift+P).\n",
    " 1. Search for Python: Create Environment.\n",
    " 1. select Venv / Conda and choose where to create the new environment.\n",
    " 1. Select the Python interpreter version. Create with version 3.10 or later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "## Setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352518e0-0bb0-41fa-a57a-c1acb9b49a8a 7897ebf8-059c-442c-8a33-86f4b5842123 b331efb4-915f-41cc-8bb9-f074f39a3fdb\n"
     ]
    }
   ],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import os\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from utils.common import *\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient, generate_blob_sas, BlobSasPermissions\n",
    "import os\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "SPEECH_KEY = os.getenv(\"AZURE_AI_SPEECH_API_KEY\")\n",
    "SPEECH_REGION = os.getenv(\"AZURE_AI_SPEECH_REGION\")\n",
    "CUSTOM_SPEECH_LANG = os.getenv(\"CUSTOM_SPEECH_LANG\")\n",
    "CUSTOM_SPEECH_LOCALE = os.getenv(\"CUSTOM_SPEECH_LOCALE\")\n",
    "\n",
    "# Get the project and custom model IDs from the previous notebook\n",
    "project_id = \"\"\n",
    "custom_model_with_plain_id = \"\"\n",
    "custom_model_with_acoustic_id = \"\"\n",
    "%store -r project_id\n",
    "%store -r custom_model_with_plain_id\n",
    "%store -r custom_model_with_acoustic_id\n",
    "\n",
    "try:\n",
    "    project_id, custom_model_with_plain_id, custom_model_with_acoustic_id\n",
    "except NameError:\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] Please run the previous notebook again.\")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "print(project_id, custom_model_with_plain_id, custom_model_with_acoustic_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Test based speech models\n",
    "- In order to learn how to quantitatively measure and improve the accuracy of the base speech to text model or your own custom models check this link\n",
    "- https://learn.microsoft.com/en-us/azure/ai-services/speech-service/how-to-custom-speech-evaluate-data?pivots=speech-cli#create-a-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the word error rate (WER) of a base model in Azure AI‚Äôs Speech service, follow these steps:\n",
    "\n",
    "Sign in to the Speech Studio:\n",
    "Go to the Azure Speech Studio.\n",
    "Create a Test:\n",
    "Navigate to Custom speech and select your project.\n",
    "Go to Test models and click on Create new test.\n",
    "Select Evaluate accuracy and click Next.\n",
    "Choose an audio + human-labeled transcription dataset. If you don‚Äôt have any datasets, upload them in the Speech datasets menu.\n",
    "Select up to two models to evaluate, then click Next.\n",
    "Enter the test name and description, then click Next.\n",
    "Review the test details and click Save and close.\n",
    "Get Test Results:\n",
    "After the test is complete, indicated by the status set to Succeeded, you will see the results, including the WER for each tested model.\n",
    "Evaluate WER:\n",
    "WER is calculated as the sum of insertion, deletion, and substitution errors divided by the total number of words in the reference transcript, multiplied by 100 to get a percentage1.\n",
    "For more detailed instructions, you can refer to this link - https://learn.microsoft.com/en-us/azure/ai-services/speech-service/how-to-custom-speech-evaluate-data?pivots=rest-api.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL for the Speech Services REST API\n",
    "base_url = f'https://{SPEECH_REGION}.api.cognitive.microsoft.com/speechtotext'\n",
    "\n",
    "# Headers for authentication\n",
    "headers = {\n",
    "    'Ocp-Apim-Subscription-Key': SPEECH_KEY,\n",
    "    'Content-Type': 'application/json'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the custom speech model ids to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest model supporting 'Language' adaptations:\n",
      "{'links': {'manifest': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/base/8066b5fb-0114-4837-90b6-0c245928a896/manifest'}, 'properties': {'deprecationDates': {'adaptationDateTime': '2025-04-15T00:00:00Z', 'transcriptionDateTime': '2025-04-15T00:00:00Z'}, 'features': {'supportsAdaptationsWith': ['Language'], 'supportsTranscriptions': True, 'supportsEndpoints': True, 'supportsTranscriptionsOnSpeechContainers': False, 'supportedOutputFormats': ['Display', 'Lexical']}, 'chargeForAdaptation': False}, 'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/base/8066b5fb-0114-4837-90b6-0c245928a896', 'displayName': '20230111', 'description': 'vi-VN base model', 'locale': 'vi-VN', 'createdDateTime': '2023-01-31T12:16:46Z', 'lastActionDateTime': '2023-01-31T13:08:53Z', 'status': 'Succeeded'}\n"
     ]
    }
   ],
   "source": [
    "#option1. check the model id from the train a new model (UI) in the Azure Speech Studio. \n",
    "base_model_id = \"8066b5fb-0114-4837-90b6-0c245928a896\"  # Vietnamese base model id\n",
    "\n",
    "#option2. check the model id from the API call\n",
    "base_model = get_latest_base_model(base_url, headers, f\"locale eq '{CUSTOM_SPEECH_LOCALE}' and status eq 'Succeeded'\")\n",
    "\n",
    "# Filter the base models to find the ones that support 'Language' adaptations and have the latest lastActionDateTime\n",
    "filtered_models = [model for model in base_model['values'] if 'properties' in model and 'Language' in model['properties']['features'].get('supportsAdaptationsWith', [])]\n",
    "if filtered_models:\n",
    "\tlatest_model = max(filtered_models, key=lambda x: x['createdDateTime'])\n",
    "\tprint(\"Latest model supporting 'Language' adaptations:\")\n",
    "\tprint(latest_model)\n",
    "else:\n",
    "\tprint(\"No models found that support 'Language' adaptations.\")\n",
    "\n",
    "# Get the latest model ID from the self link for example 8066b5fb-0114-4837-90b6-0c245928a896 is the model id in 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/base/8066b5fb-0114-4837-90b6-0c245928a896' \n",
    "base_model_id = latest_model['self'].split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest base model id: 8066b5fb-0114-4837-90b6-0c245928a896\n",
      "custom_model_with_plain_id:  7897ebf8-059c-442c-8a33-86f4b5842123\n",
      "custom_model_with_acoustic_id:  b331efb4-915f-41cc-8bb9-f074f39a3fdb\n"
     ]
    }
   ],
   "source": [
    "# check the model id from the train a new model (UI) in the Azure Speech Studio. \n",
    "# The base model ids are vary from each language \n",
    "print(\"Latest base model id:\", base_model_id)\n",
    "print(\"custom_model_with_plain_id: \", custom_model_with_plain_id)\n",
    "print(\"custom_model_with_acoustic_id: \", custom_model_with_acoustic_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload zip files to a storage account and generate content urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files uploaded successfully.\n",
      "uploaded_files: ['eval_vi-VN_20241217132834', 'Call2-merge-err2', 'Call2-merge-err3', 'Call2-merge-err1']\n",
      "url: {'eval_vi-VN_20241217132834': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/eval_vi-VN_20241217132834.zip?se=2025-01-15T13%3A52%3A24Z&sp=r&sv=2025-01-05&sr=b&sig=ujIc/aGN5eRiOf094DmrK6EZw%2BZEtRm0Z2yQm0h3QHg%3D', 'Call2-merge-err2': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/Call2-merge-err2.zip?se=2025-01-15T13%3A52%3A24Z&sp=r&sv=2025-01-05&sr=b&sig=KeQoR8JYhiZzZlMECFwzctm2wwXmEb1qiFtcVLhThNQ%3D', 'Call2-merge-err3': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/Call2-merge-err3.zip?se=2025-01-15T13%3A52%3A24Z&sp=r&sv=2025-01-05&sr=b&sig=StZw6jXFiknc6OXO8koayVd4UP/YT0ITugVriG/5mzM%3D', 'Call2-merge-err1': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/Call2-merge-err1.zip?se=2025-01-15T13%3A52%3A24Z&sp=r&sv=2025-01-05&sr=b&sig=BxHzNpcPoopE7JIBx4vHneUOnOwcsBWEkWd6YsmJ1NU%3D'}\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"eval_dataset\"\n",
    "account_name = os.getenv(\"AZURE_STORAGE_ACCOUNT_NAME\")\n",
    "account_key = os.getenv(\"AZURE_STORAGE_ACCOUNT_KEY\")\n",
    "container_name = os.getenv(\"AZURE_STORAGE_CONTAINER_NAME\")\n",
    "\n",
    "uploaded_files, url = upload_dataset_to_storage(data_folder, container_name, account_name, account_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eval_vi-VN_20241217132834',\n",
       " 'Call2-merge-err2',\n",
       " 'Call2-merge-err3',\n",
       " 'Call2-merge-err1']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uploaded_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create datasets for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with ID: 867e28d4-2ae5-4d47-adce-fe325f829061\n",
      "Dataset created with ID: 41a0a991-e8ee-4f6e-bbad-f4cee3855fcf\n",
      "Dataset created with ID: c683d4d6-8021-413e-ba7b-79004e9587d8\n",
      "Dataset created with ID: 8a7eb804-25a1-486b-8255-d32f94069bc1\n"
     ]
    }
   ],
   "source": [
    "kind=\"Acoustic\"\n",
    "description = f\"[eval] Dataset for evaluation the {CUSTOM_SPEECH_LANG} base model\"\n",
    "dataset_ids = {}\n",
    "\n",
    "for display_name in uploaded_files:\n",
    "    dataset_ids[display_name] = create_dataset(base_url, headers, project_id, url[display_name], kind, display_name, description, CUSTOM_SPEECH_LOCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:   0%|          | 0/3 [00:00<?, ?step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:10<00:05,  5.04s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:20<00:00,  6.72s/step]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 83.71step/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 82.83step/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 92.86step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for display_name in uploaded_files:\n",
    "    monitor_status(base_url, headers, get_dataset_status, dataset_ids[display_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test accuracy of the trained Custom Speech model creating evaluations (tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/evaluations\n",
      "352518e0-0bb0-41fa-a57a-c1acb9b49a8a 867e28d4-2ae5-4d47-adce-fe325f829061 8066b5fb-0114-4837-90b6-0c245928a896 b331efb4-915f-41cc-8bb9-f074f39a3fdb\n",
      "{'model1': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/8066b5fb-0114-4837-90b6-0c245928a896'}, 'model2': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/b331efb4-915f-41cc-8bb9-f074f39a3fdb'}, 'dataset': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/867e28d4-2ae5-4d47-adce-fe325f829061'}, 'project': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/projects/352518e0-0bb0-41fa-a57a-c1acb9b49a8a'}, 'displayName': 'vi_eval_base_vs_custom_eval_vi-VN_20241217132834', 'description': '[vi-VN] Evaluation of the Vietnamese base and custom model', 'locale': 'vi-VN'}\n",
      "Evaluation job created with ID: 91e05bf6-f0d4-4243-8aa7-3e336a0f3483\n",
      "https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/evaluations\n",
      "352518e0-0bb0-41fa-a57a-c1acb9b49a8a 41a0a991-e8ee-4f6e-bbad-f4cee3855fcf 8066b5fb-0114-4837-90b6-0c245928a896 b331efb4-915f-41cc-8bb9-f074f39a3fdb\n",
      "{'model1': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/8066b5fb-0114-4837-90b6-0c245928a896'}, 'model2': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/b331efb4-915f-41cc-8bb9-f074f39a3fdb'}, 'dataset': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/41a0a991-e8ee-4f6e-bbad-f4cee3855fcf'}, 'project': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/projects/352518e0-0bb0-41fa-a57a-c1acb9b49a8a'}, 'displayName': 'vi_eval_base_vs_custom_Call2-merge-err2', 'description': '[vi-VN] Evaluation of the Vietnamese base and custom model', 'locale': 'vi-VN'}\n",
      "Evaluation job created with ID: 64a7ed05-2cd9-471f-9d9f-285a09936edd\n",
      "https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/evaluations\n",
      "352518e0-0bb0-41fa-a57a-c1acb9b49a8a c683d4d6-8021-413e-ba7b-79004e9587d8 8066b5fb-0114-4837-90b6-0c245928a896 b331efb4-915f-41cc-8bb9-f074f39a3fdb\n",
      "{'model1': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/8066b5fb-0114-4837-90b6-0c245928a896'}, 'model2': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/b331efb4-915f-41cc-8bb9-f074f39a3fdb'}, 'dataset': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/c683d4d6-8021-413e-ba7b-79004e9587d8'}, 'project': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/projects/352518e0-0bb0-41fa-a57a-c1acb9b49a8a'}, 'displayName': 'vi_eval_base_vs_custom_Call2-merge-err3', 'description': '[vi-VN] Evaluation of the Vietnamese base and custom model', 'locale': 'vi-VN'}\n",
      "Evaluation job created with ID: 4c06c9f8-6f23-4bfa-b48c-d2872aeae459\n",
      "https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/evaluations\n",
      "352518e0-0bb0-41fa-a57a-c1acb9b49a8a 8a7eb804-25a1-486b-8255-d32f94069bc1 8066b5fb-0114-4837-90b6-0c245928a896 b331efb4-915f-41cc-8bb9-f074f39a3fdb\n",
      "{'model1': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/8066b5fb-0114-4837-90b6-0c245928a896'}, 'model2': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/b331efb4-915f-41cc-8bb9-f074f39a3fdb'}, 'dataset': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/8a7eb804-25a1-486b-8255-d32f94069bc1'}, 'project': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/projects/352518e0-0bb0-41fa-a57a-c1acb9b49a8a'}, 'displayName': 'vi_eval_base_vs_custom_Call2-merge-err1', 'description': '[vi-VN] Evaluation of the Vietnamese base and custom model', 'locale': 'vi-VN'}\n",
      "Evaluation job created with ID: 82273a7d-4acd-4802-ab2b-12d4d082df90\n"
     ]
    }
   ],
   "source": [
    "description = f\"[{CUSTOM_SPEECH_LOCALE}] Evaluation of the {CUSTOM_SPEECH_LANG} base and custom model\"\n",
    "evaluation_ids={}\n",
    "for display_name in uploaded_files:\n",
    "    evaluation_ids[display_name] = create_evaluation(base_url, headers, project_id, dataset_ids[display_name], base_model_id, custom_model_with_acoustic_id, f'vi_eval_base_vs_custom_{display_name}', description, CUSTOM_SPEECH_LOCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:   0%|          | 0/3 [00:00<?, ?step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [01:00<00:30, 30.19s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [01:10<00:00, 23.49s/step]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 90.65step/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:   0%|          | 0/3 [00:00<?, ?step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:10<00:00,  3.36s/step]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 41.29step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for display_name in uploaded_files:\n",
    "    monitor_status(base_url, headers, get_evaluation_status, evaluation_ids[display_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Print evaluation result with WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/evaluations/91e05bf6-f0d4-4243-8aa7-3e336a0f3483', 'model1': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/base/8066b5fb-0114-4837-90b6-0c245928a896'}, 'model2': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/b331efb4-915f-41cc-8bb9-f074f39a3fdb'}, 'dataset': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/867e28d4-2ae5-4d47-adce-fe325f829061'}, 'transcription2': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/transcriptions/7e30f88c-92db-4e19-be8d-b1fab52bc3d8'}, 'transcription1': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/transcriptions/4a97025a-9f75-4cb7-9ce5-79de50add8a7'}, 'project': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/projects/352518e0-0bb0-41fa-a57a-c1acb9b49a8a'}, 'links': {'files': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/evaluations/91e05bf6-f0d4-4243-8aa7-3e336a0f3483/files'}, 'properties': {'wordErrorRate1': 0.004, 'sentenceErrorRate1': 0.1, 'tokenErrorRate1': -1.0, 'sentenceCount1': 10, 'wordCount1': 247, 'correctWordCount1': 246, 'wordSubstitutionCount1': 1, 'wordDeletionCount1': 0, 'wordInsertionCount1': 0, 'tokenCount1': -1, 'correctTokenCount1': -1, 'tokenSubstitutionCount1': -1, 'tokenDeletionCount1': -1, 'tokenInsertionCount1': -1, 'wordErrorRate2': 0.0, 'sentenceErrorRate2': 0.0, 'tokenErrorRate2': -1.0, 'sentenceCount2': 10, 'wordCount2': 247, 'correctWordCount2': 247, 'wordSubstitutionCount2': 0, 'wordDeletionCount2': 0, 'wordInsertionCount2': 0, 'tokenCount2': -1, 'correctTokenCount2': -1, 'tokenSubstitutionCount2': -1, 'tokenDeletionCount2': -1, 'tokenInsertionCount2': -1}, 'lastActionDateTime': '2025-01-15T05:53:57Z', 'status': 'Succeeded', 'createdDateTime': '2025-01-15T05:52:52Z', 'locale': 'vi-VN', 'displayName': 'vi_eval_base_vs_custom_eval_vi-VN_20241217132834', 'description': '[vi-VN] Evaluation of the Vietnamese base and custom model'}\n",
      "{'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/evaluations/64a7ed05-2cd9-471f-9d9f-285a09936edd', 'model1': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/base/8066b5fb-0114-4837-90b6-0c245928a896'}, 'model2': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/b331efb4-915f-41cc-8bb9-f074f39a3fdb'}, 'dataset': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/41a0a991-e8ee-4f6e-bbad-f4cee3855fcf'}, 'transcription2': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/transcriptions/0793e1ce-10cb-4afa-a937-4ef5e59e5a43'}, 'transcription1': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/transcriptions/5728e227-51df-4699-9eb4-0279c17a94eb'}, 'project': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/projects/352518e0-0bb0-41fa-a57a-c1acb9b49a8a'}, 'links': {'files': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/evaluations/64a7ed05-2cd9-471f-9d9f-285a09936edd/files'}, 'properties': {'wordErrorRate1': -1.0, 'sentenceErrorRate1': -1.0, 'sentenceCount1': -1, 'wordCount1': -1, 'correctWordCount1': -1, 'wordSubstitutionCount1': -1, 'wordDeletionCount1': -1, 'wordInsertionCount1': -1, 'wordErrorRate2': -1.0, 'sentenceErrorRate2': -1.0, 'sentenceCount2': -1, 'wordCount2': -1, 'correctWordCount2': -1, 'wordSubstitutionCount2': -1, 'wordDeletionCount2': -1, 'wordInsertionCount2': -1, 'error': {'code': 'InvalidData', 'message': 'Invalid or empty input data for evaluation.'}}, 'lastActionDateTime': '2025-01-15T05:53:55Z', 'status': 'Failed', 'createdDateTime': '2025-01-15T05:52:52Z', 'locale': 'vi-VN', 'displayName': 'vi_eval_base_vs_custom_Call2-merge-err2', 'description': '[vi-VN] Evaluation of the Vietnamese base and custom model'}\n",
      "{'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/evaluations/4c06c9f8-6f23-4bfa-b48c-d2872aeae459', 'model1': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/base/8066b5fb-0114-4837-90b6-0c245928a896'}, 'model2': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/b331efb4-915f-41cc-8bb9-f074f39a3fdb'}, 'dataset': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/c683d4d6-8021-413e-ba7b-79004e9587d8'}, 'transcription2': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/transcriptions/424b8e02-59fc-4cba-9a64-88b444b76051'}, 'transcription1': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/transcriptions/55f0ab1b-75d8-4094-988e-5fe572dbaa65'}, 'project': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/projects/352518e0-0bb0-41fa-a57a-c1acb9b49a8a'}, 'links': {'files': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/evaluations/4c06c9f8-6f23-4bfa-b48c-d2872aeae459/files'}, 'properties': {'wordErrorRate1': -1.0, 'sentenceErrorRate1': -1.0, 'sentenceCount1': -1, 'wordCount1': -1, 'correctWordCount1': -1, 'wordSubstitutionCount1': -1, 'wordDeletionCount1': -1, 'wordInsertionCount1': -1, 'wordErrorRate2': -1.0, 'sentenceErrorRate2': -1.0, 'sentenceCount2': -1, 'wordCount2': -1, 'correctWordCount2': -1, 'wordSubstitutionCount2': -1, 'wordDeletionCount2': -1, 'wordInsertionCount2': -1, 'error': {'code': 'InvalidData', 'message': 'Invalid or empty input data for evaluation.'}}, 'lastActionDateTime': '2025-01-15T05:54:03Z', 'status': 'Failed', 'createdDateTime': '2025-01-15T05:52:52Z', 'locale': 'vi-VN', 'displayName': 'vi_eval_base_vs_custom_Call2-merge-err3', 'description': '[vi-VN] Evaluation of the Vietnamese base and custom model'}\n",
      "{'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/evaluations/82273a7d-4acd-4802-ab2b-12d4d082df90', 'model1': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/base/8066b5fb-0114-4837-90b6-0c245928a896'}, 'model2': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/b331efb4-915f-41cc-8bb9-f074f39a3fdb'}, 'dataset': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/8a7eb804-25a1-486b-8255-d32f94069bc1'}, 'transcription2': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/transcriptions/d666d4b5-87c3-4237-8177-f79adae514b6'}, 'transcription1': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/transcriptions/29478d76-b77b-4851-ac7c-acbdf476a0c1'}, 'project': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/projects/352518e0-0bb0-41fa-a57a-c1acb9b49a8a'}, 'links': {'files': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/evaluations/82273a7d-4acd-4802-ab2b-12d4d082df90/files'}, 'properties': {'wordErrorRate1': -1.0, 'sentenceErrorRate1': -1.0, 'sentenceCount1': -1, 'wordCount1': -1, 'correctWordCount1': -1, 'wordSubstitutionCount1': -1, 'wordDeletionCount1': -1, 'wordInsertionCount1': -1, 'wordErrorRate2': -1.0, 'sentenceErrorRate2': -1.0, 'sentenceCount2': -1, 'wordCount2': -1, 'correctWordCount2': -1, 'wordSubstitutionCount2': -1, 'wordDeletionCount2': -1, 'wordInsertionCount2': -1, 'error': {'code': 'InvalidData', 'message': 'Invalid or empty input data for evaluation.'}}, 'lastActionDateTime': '2025-01-15T05:53:53Z', 'status': 'Failed', 'createdDateTime': '2025-01-15T05:52:53Z', 'locale': 'vi-VN', 'displayName': 'vi_eval_base_vs_custom_Call2-merge-err1', 'description': '[vi-VN] Evaluation of the Vietnamese base and custom model'}\n",
      "{'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/evaluations/82273a7d-4acd-4802-ab2b-12d4d082df90', 'model1': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/base/8066b5fb-0114-4837-90b6-0c245928a896'}, 'model2': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/b331efb4-915f-41cc-8bb9-f074f39a3fdb'}, 'dataset': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/8a7eb804-25a1-486b-8255-d32f94069bc1'}, 'transcription2': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/transcriptions/d666d4b5-87c3-4237-8177-f79adae514b6'}, 'transcription1': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/transcriptions/29478d76-b77b-4851-ac7c-acbdf476a0c1'}, 'project': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/projects/352518e0-0bb0-41fa-a57a-c1acb9b49a8a'}, 'links': {'files': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/evaluations/82273a7d-4acd-4802-ab2b-12d4d082df90/files'}, 'properties': {'wordErrorRate1': -1.0, 'sentenceErrorRate1': -1.0, 'sentenceCount1': -1, 'wordCount1': -1, 'correctWordCount1': -1, 'wordSubstitutionCount1': -1, 'wordDeletionCount1': -1, 'wordInsertionCount1': -1, 'wordErrorRate2': -1.0, 'sentenceErrorRate2': -1.0, 'sentenceCount2': -1, 'wordCount2': -1, 'correctWordCount2': -1, 'wordSubstitutionCount2': -1, 'wordDeletionCount2': -1, 'wordInsertionCount2': -1, 'error': {'code': 'InvalidData', 'message': 'Invalid or empty input data for evaluation.'}}, 'lastActionDateTime': '2025-01-15T05:53:53Z', 'status': 'Failed', 'createdDateTime': '2025-01-15T05:52:53Z', 'locale': 'vi-VN', 'displayName': 'vi_eval_base_vs_custom_Call2-merge-err1', 'description': '[vi-VN] Evaluation of the Vietnamese base and custom model'}\n",
      "Evaluation Results for base model and custom model: eval_vi-VN_20241217132834 Call2-merge-err2 Call2-merge-err3 Call2-merge-err1 \n",
      "                     Dataset  WER_base_model  WER_custom_model\n",
      "0  eval_vi-VN_20241217132834           0.004               0.0\n",
      "1           Call2-merge-err2          -1.000              -1.0\n",
      "2           Call2-merge-err3          -1.000              -1.0\n",
      "3           Call2-merge-err1          -1.000              -1.0\n"
     ]
    }
   ],
   "source": [
    "# Collect WER results for each dataset\n",
    "wer_results = []\n",
    "eval_title = \"Evaluation Results for base model and custom model: \"\n",
    "for display_name in uploaded_files:\n",
    "    eval_info = get_evaluation_results(base_url, headers, evaluation_ids[display_name])\n",
    "    print(eval_info)\n",
    "    eval_title = eval_title + display_name + \" \"\n",
    "    wer_results.append({\n",
    "            'Dataset': display_name,\n",
    "            'WER_base_model': eval_info['properties']['wordErrorRate1'],\n",
    "            'WER_custom_model': eval_info['properties']['wordErrorRate2'],\n",
    "            \n",
    "    })\n",
    "# Create a DataFrame to display the results\n",
    "print(eval_info)\n",
    "wer_df = pd.DataFrame(wer_results)\n",
    "print(eval_title)\n",
    "print(wer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation eval_vi-VN_20241217132834 Scoring results\n",
      "=====================================\n",
      "Evaluation Call2-merge-err2 Scoring results\n",
      "=====================================\n",
      "Evaluation Call2-merge-err3 Scoring results\n",
      "=====================================\n",
      "Evaluation Call2-merge-err1 Scoring results\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "# Create a markdown file for table scoring results\n",
    "md_table_scoring_result(base_url, headers, evaluation_ids, uploaded_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Calculate WER/CER from the evaluation result\n",
    "> ‚ùóÔ∏èTo calculate the Word Error Rate (WER) and Character Error Rate (CER) from the evaluation result, you need to download the result file from Azure AI Foundry or Speech Studio, and then use the Human labeled transcription (normalized) and Machine recognition result > txt_lexical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_name</th>\n",
       "      <th>original_transcript</th>\n",
       "      <th>stt_transcript</th>\n",
       "      <th>WER</th>\n",
       "      <th>CER</th>\n",
       "      <th>highlighted_original</th>\n",
       "      <th>highlighted_stt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vi_Call6_preds</td>\n",
       "      <td>Ôªøƒë·ªÉ g·∫∑p tr·ª±c ti·∫øp nh√¢n vi√™n h·ªó tr·ª£ m·ªùi qu√Ω kh√°...</td>\n",
       "      <td>Ôªøƒë·ªÉ g·∫∑p tr·ª±c ti·∫øp nh√¢n vi√™n h·ªó tr·ª£ m·ªùi qu√Ω kh√°...</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>&lt;span style='background-color:yellow'&gt;Ôªøƒë·ªÉ&lt;/spa...</td>\n",
       "      <td>&lt;span style='background-color:yellow'&gt;Ôªøƒë·ªÉ&lt;/spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vi_Call6_preds</td>\n",
       "      <td>d·∫° contoso s·ªë nƒÉm kh√¥ng m·ªôt ba xin nghe ·∫° r·ªìi em ∆°i...</td>\n",
       "      <td>d·∫° contoso s·ªë nƒÉm kh√¥ng m·ªôt ba xin nghe ·∫°¬†t·ª•i¬†em ∆°i...</td>\n",
       "      <td>0.361446</td>\n",
       "      <td>0.170149</td>\n",
       "      <td>&lt;span style='background-color:yellow'&gt;d·∫°&lt;/span...</td>\n",
       "      <td>&lt;span style='background-color:yellow'&gt;d·∫°&lt;/span...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         wav_name                                original_transcript  \\\n",
       "0  vi_Call6_preds  Ôªøƒë·ªÉ g·∫∑p tr·ª±c ti·∫øp nh√¢n vi√™n h·ªó tr·ª£ m·ªùi qu√Ω kh√°...   \n",
       "1  vi_Call6_preds  d·∫° contoso s·ªë nƒÉm kh√¥ng m·ªôt ba xin nghe ·∫° r·ªìi em ∆°i...   \n",
       "\n",
       "                                      stt_transcript       WER       CER  \\\n",
       "0  Ôªøƒë·ªÉ g·∫∑p tr·ª±c ti·∫øp nh√¢n vi√™n h·ªó tr·ª£ m·ªùi qu√Ω kh√°...  0.190476  0.055556   \n",
       "1  d·∫° contoso s·ªë nƒÉm kh√¥ng m·ªôt ba xin nghe ·∫°¬†t·ª•i¬†em ∆°i...  0.361446  0.170149   \n",
       "\n",
       "                                highlighted_original  \\\n",
       "0  <span style='background-color:yellow'>Ôªøƒë·ªÉ</spa...   \n",
       "1  <span style='background-color:yellow'>d·∫°</span...   \n",
       "\n",
       "                                     highlighted_stt  \n",
       "0  <span style='background-color:yellow'>Ôªøƒë·ªÉ</spa...  \n",
       "1  <span style='background-color:yellow'>d·∫°</span...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.wercer_tool import evaluate_stt\n",
    "from utils.wercer_tool import OriginFileType\n",
    "\n",
    "origin_path = \"wer_origin\"\n",
    "#wer_origin_path = \"wer_origin\"\n",
    "stt_folder = \"wer_result\"\n",
    "output_csv_path = \"stt_evaluation_results.csv\"\n",
    "output_html_path = \"stt_evaluation_results.html\"\n",
    "\n",
    "evaluation_df = evaluate_stt(\n",
    "    # When you have multi lines in the original/stt files, you should use OriginFileType.MULTI_LINE\n",
    "    OriginFileType.MULTI_LINE,\n",
    "    origin_path=origin_path,\n",
    "    stt_folder=stt_folder,\n",
    "    output_csv=output_csv_path,\n",
    "    output_html=output_html_path\n",
    ")\n",
    "evaluation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_name</th>\n",
       "      <th>original_transcript</th>\n",
       "      <th>stt_transcript</th>\n",
       "      <th>WER</th>\n",
       "      <th>CER</th>\n",
       "      <th>highlighted_original</th>\n",
       "      <th>highlighted_stt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_vi-VN_20241217132830.wav</td>\n",
       "      <td>Ch√†o b·ªô ph·∫≠n h·ªó tr·ª£ kh√°ch h√†ng c·ªßa Contoso Ele...</td>\n",
       "      <td>Ch√†o b·ªô ph·∫≠n h·ªó tr·ª£ kh√°ch h√†ng c·ªßa contoso ele...</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>&lt;span style='background-color:yellow'&gt;Ch√†o&lt;/sp...</td>\n",
       "      <td>&lt;span style='background-color:yellow'&gt;Ch√†o&lt;/sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_vi-VN_20241217132833.wav</td>\n",
       "      <td>T√¥i mu·ªën bi·∫øt c√°ch li√™n h·ªá v·ªõi b·ªô ph·∫≠n h·ªó tr·ª£ ...</td>\n",
       "      <td>T√¥i mu·ªën bi·∫øt c√°ch li√™n h·ªá v·ªõi b·ªô ph·∫≠n h·ªó tr·ª£ ...</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>&lt;span style='background-color:yellow'&gt;T√¥i&lt;/spa...</td>\n",
       "      <td>&lt;span style='background-color:yellow'&gt;T√¥i&lt;/spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_vi-VN_20241217132830.wav</td>\n",
       "      <td>T√¥i ƒëang g·∫∑p v·∫•n ƒë·ªÅ v·ªõi m√°y t√≠nh x√°ch tay c·ªßa ...</td>\n",
       "      <td>ƒëang g·∫∑p v·∫•n ƒë·ªÅ v·ªõi m√°y t√≠nh x√°ch tay c·ªßa m√¨nh...</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.058252</td>\n",
       "      <td>&lt;span style='background-color:red'&gt;T√¥i&lt;/span&gt; ...</td>\n",
       "      <td>&lt;span style='background-color:yellow'&gt;ƒëang&lt;/sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3_vi-VN_20241217132830.wav</td>\n",
       "      <td>T√¥i mu·ªën ƒë·ªïi s·∫£n ph·∫©m m·ªõi nh·∫•t c·ªßa Contoso Ele...</td>\n",
       "      <td>T√¥i mu·ªën ƒë·ªïi s·∫£n ph·∫©m m·ªõi nh·∫•t c·ªßa contoso ele...</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>&lt;span style='background-color:yellow'&gt;T√¥i&lt;/spa...</td>\n",
       "      <td>&lt;span style='background-color:yellow'&gt;T√¥i&lt;/spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4_vi-VN_20241217132831.wav</td>\n",
       "      <td>T√¥i mu·ªën h·ªßy ƒë∆°n h√†ng c·ªßa m√¨nh, c√≥ th·ªÉ b·∫°n h∆∞·ªõ...</td>\n",
       "      <td>T√¥i mu·ªën h·ªßy ƒë∆°n h√†ng c·ªßa m√¨nh. C√≥ th·ªÉ b·∫°n h∆∞·ªõ...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>&lt;span style='background-color:yellow'&gt;T√¥i&lt;/spa...</td>\n",
       "      <td>&lt;span style='background-color:yellow'&gt;T√¥i&lt;/spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5_vi-VN_20241217132831.wav</td>\n",
       "      <td>T√¥i mu·ªën mua th√™m ph·ª• ki·ªán cho m√°y t√≠nh x√°ch t...</td>\n",
       "      <td>T√¥i mu·ªën mua th√™m ph·ª• ki·ªán cho m√°y t√≠nh x√°ch t...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>&lt;span style='background-color:yellow'&gt;T√¥i&lt;/spa...</td>\n",
       "      <td>&lt;span style='background-color:yellow'&gt;T√¥i&lt;/spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6_vi-VN_20241217132831.wav</td>\n",
       "      <td>T√¥i mu·ªën bi·∫øt th·ªùi gian giao h√†ng c·ªßa s·∫£n ph·∫©m...</td>\n",
       "      <td>T√¥i mu·ªën bi·∫øt th·ªùi gian giao h√†ng c·ªßa s·∫£n ph·∫©m...</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.061644</td>\n",
       "      <td>&lt;span style='background-color:yellow'&gt;T√¥i&lt;/spa...</td>\n",
       "      <td>&lt;span style='background-color:yellow'&gt;T√¥i&lt;/spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7_vi-VN_20241217132831.wav</td>\n",
       "      <td>T√¥i mu·ªën bi·∫øt ch√≠nh s√°ch b·∫£o h√†nh c·ªßa s·∫£n ph·∫©m...</td>\n",
       "      <td>T√¥i mu·ªën bi·∫øt ch√≠nh s√°ch b·∫£o h√†nh c·ªßa s·∫£n ph·∫©m...</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.020548</td>\n",
       "      <td>&lt;span style='background-color:yellow'&gt;T√¥i&lt;/spa...</td>\n",
       "      <td>&lt;span style='background-color:yellow'&gt;T√¥i&lt;/spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8_vi-VN_20241217132832.wav</td>\n",
       "      <td>T√¥i mu·ªën bi·∫øt c√°ch s·ª≠ d·ª•ng s·∫£n ph·∫©m m·ªõi nh·∫•t c...</td>\n",
       "      <td>T√¥i mu·ªën bi·∫øt c√°ch s·ª≠ d·ª•ng s·∫£n ph·∫©m m·ªõi nh·∫•t c...</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>&lt;span style='background-color:yellow'&gt;T√¥i&lt;/spa...</td>\n",
       "      <td>&lt;span style='background-color:yellow'&gt;T√¥i&lt;/spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9_vi-VN_20241217132832.wav</td>\n",
       "      <td>T√¥i mu·ªën bi·∫øt c√°ch truy c·∫≠p v√†o t√†i kho·∫£n c·ªßa ...</td>\n",
       "      <td>T√¥i mu·ªën bi·∫øt c√°ch truy c·∫≠p v√†o t√†i kho·∫£n c·ªßa ...</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.027211</td>\n",
       "      <td>&lt;span style='background-color:yellow'&gt;T√¥i&lt;/spa...</td>\n",
       "      <td>&lt;span style='background-color:yellow'&gt;T√¥i&lt;/spa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      wav_name  \\\n",
       "0   1_vi-VN_20241217132830.wav   \n",
       "1  10_vi-VN_20241217132833.wav   \n",
       "2   2_vi-VN_20241217132830.wav   \n",
       "3   3_vi-VN_20241217132830.wav   \n",
       "4   4_vi-VN_20241217132831.wav   \n",
       "5   5_vi-VN_20241217132831.wav   \n",
       "6   6_vi-VN_20241217132831.wav   \n",
       "7   7_vi-VN_20241217132831.wav   \n",
       "8   8_vi-VN_20241217132832.wav   \n",
       "9   9_vi-VN_20241217132832.wav   \n",
       "\n",
       "                                 original_transcript  \\\n",
       "0  Ch√†o b·ªô ph·∫≠n h·ªó tr·ª£ kh√°ch h√†ng c·ªßa Contoso Ele...   \n",
       "1  T√¥i mu·ªën bi·∫øt c√°ch li√™n h·ªá v·ªõi b·ªô ph·∫≠n h·ªó tr·ª£ ...   \n",
       "2  T√¥i ƒëang g·∫∑p v·∫•n ƒë·ªÅ v·ªõi m√°y t√≠nh x√°ch tay c·ªßa ...   \n",
       "3  T√¥i mu·ªën ƒë·ªïi s·∫£n ph·∫©m m·ªõi nh·∫•t c·ªßa Contoso Ele...   \n",
       "4  T√¥i mu·ªën h·ªßy ƒë∆°n h√†ng c·ªßa m√¨nh, c√≥ th·ªÉ b·∫°n h∆∞·ªõ...   \n",
       "5  T√¥i mu·ªën mua th√™m ph·ª• ki·ªán cho m√°y t√≠nh x√°ch t...   \n",
       "6  T√¥i mu·ªën bi·∫øt th·ªùi gian giao h√†ng c·ªßa s·∫£n ph·∫©m...   \n",
       "7  T√¥i mu·ªën bi·∫øt ch√≠nh s√°ch b·∫£o h√†nh c·ªßa s·∫£n ph·∫©m...   \n",
       "8  T√¥i mu·ªën bi·∫øt c√°ch s·ª≠ d·ª•ng s·∫£n ph·∫©m m·ªõi nh·∫•t c...   \n",
       "9  T√¥i mu·ªën bi·∫øt c√°ch truy c·∫≠p v√†o t√†i kho·∫£n c·ªßa ...   \n",
       "\n",
       "                                      stt_transcript       WER       CER  \\\n",
       "0  Ch√†o b·ªô ph·∫≠n h·ªó tr·ª£ kh√°ch h√†ng c·ªßa contoso ele...  0.095238  0.019608   \n",
       "1  T√¥i mu·ªën bi·∫øt c√°ch li√™n h·ªá v·ªõi b·ªô ph·∫≠n h·ªó tr·ª£ ...  0.076923  0.023810   \n",
       "2  ƒëang g·∫∑p v·∫•n ƒë·ªÅ v·ªõi m√°y t√≠nh x√°ch tay c·ªßa m√¨nh...  0.125000  0.058252   \n",
       "3  T√¥i mu·ªën ƒë·ªïi s·∫£n ph·∫©m m·ªõi nh·∫•t c·ªßa contoso ele...  0.090909  0.027273   \n",
       "4  T√¥i mu·ªën h·ªßy ƒë∆°n h√†ng c·ªßa m√¨nh. C√≥ th·ªÉ b·∫°n h∆∞·ªõ...  0.111111  0.024691   \n",
       "5  T√¥i mu·ªën mua th√™m ph·ª• ki·ªán cho m√°y t√≠nh x√°ch t...  0.083333  0.018519   \n",
       "6  T√¥i mu·ªën bi·∫øt th·ªùi gian giao h√†ng c·ªßa s·∫£n ph·∫©m...  0.068966  0.061644   \n",
       "7  T√¥i mu·ªën bi·∫øt ch√≠nh s√°ch b·∫£o h√†nh c·ªßa s·∫£n ph·∫©m...  0.068966  0.020548   \n",
       "8  T√¥i mu·ªën bi·∫øt c√°ch s·ª≠ d·ª•ng s·∫£n ph·∫©m m·ªõi nh·∫•t c...  0.080000  0.024390   \n",
       "9  T√¥i mu·ªën bi·∫øt c√°ch truy c·∫≠p v√†o t√†i kho·∫£n c·ªßa ...  0.103448  0.027211   \n",
       "\n",
       "                                highlighted_original  \\\n",
       "0  <span style='background-color:yellow'>Ch√†o</sp...   \n",
       "1  <span style='background-color:yellow'>T√¥i</spa...   \n",
       "2  <span style='background-color:red'>T√¥i</span> ...   \n",
       "3  <span style='background-color:yellow'>T√¥i</spa...   \n",
       "4  <span style='background-color:yellow'>T√¥i</spa...   \n",
       "5  <span style='background-color:yellow'>T√¥i</spa...   \n",
       "6  <span style='background-color:yellow'>T√¥i</spa...   \n",
       "7  <span style='background-color:yellow'>T√¥i</spa...   \n",
       "8  <span style='background-color:yellow'>T√¥i</spa...   \n",
       "9  <span style='background-color:yellow'>T√¥i</spa...   \n",
       "\n",
       "                                     highlighted_stt  \n",
       "0  <span style='background-color:yellow'>Ch√†o</sp...  \n",
       "1  <span style='background-color:yellow'>T√¥i</spa...  \n",
       "2  <span style='background-color:yellow'>ƒëang</sp...  \n",
       "3  <span style='background-color:yellow'>T√¥i</spa...  \n",
       "4  <span style='background-color:yellow'>T√¥i</spa...  \n",
       "5  <span style='background-color:yellow'>T√¥i</spa...  \n",
       "6  <span style='background-color:yellow'>T√¥i</spa...  \n",
       "7  <span style='background-color:yellow'>T√¥i</spa...  \n",
       "8  <span style='background-color:yellow'>T√¥i</spa...  \n",
       "9  <span style='background-color:yellow'>T√¥i</spa...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.wercer_tool import evaluate_stt\n",
    "from utils.wercer_tool import OriginFileType\n",
    "\n",
    "origin_path = \"wer_origin_vi/trans_original.txt\"\n",
    "#wer_origin_path = \"wer_origin\"\n",
    "stt_folder = \"wer_result_vi\"\n",
    "output_csv_path = \"stt_evaluation_results.csv\"\n",
    "output_html_path = \"stt_evaluation_results.html\"\n",
    "\n",
    "evaluation_df = evaluate_stt(\n",
    "    # When you have a single line training file with the format:\n",
    "    # 1_vi-VN_20241217132830.wav\tCh√†o b·ªô ph·∫≠n h·ªó tr·ª£ kh√°ch h√†ng c·ªßa Contoso Electronics, t√¥i mu·ªën h·ªèi v·ªÅ s·∫£n ph·∫©m m·ªõi nh·∫•t c·ªßa c√¥ng ty.\n",
    "    # 10_vi-VN_20241217132833.wav\tT√¥i mu·ªën bi·∫øt c√°ch li√™n h·ªá v·ªõi b·ªô ph·∫≠n h·ªó tr·ª£ kh√°ch h√†ng c·ªßa Contoso Electronics, c√≥ th·ªÉ b·∫°n h∆∞·ªõng d·∫´n t√¥i c√°ch li√™n h·ªá kh√¥ng?\n",
    "    # 2_vi-VN_20241217132830.wav\tT√¥i ƒëang g·∫∑p v·∫•n ƒë·ªÅ v·ªõi m√°y t√≠nh x√°ch tay c·ªßa m√¨nh, c√≥ th·ªÉ b·∫°n c√≥ th·ªÉ gi√∫p t√¥i kh√¥i ph·ª•c d·ªØ li·ªáu kh√¥ng?\n",
    "    OriginFileType.SINGLE_LINE_TRAINING,\n",
    "    origin_path=origin_path,\n",
    "    stt_folder=stt_folder,\n",
    "    output_csv=output_csv_path,\n",
    "    output_html=output_html_path\n",
    ")\n",
    "evaluation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aoai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
