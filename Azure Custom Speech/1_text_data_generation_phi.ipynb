{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [text gen] Domain related Text Generation with Phi 3.5\n",
    "\n",
    "This sample demonstrates how to generate a plain text file to train custom speech model.\n",
    "\n",
    "> âœ¨ **_Note_** <br>\n",
    "> Please check the custom speech support for each language before you get started - https://learn.microsoft.com/en-us/azure/ai-services/speech-service/language-support?tabs=stt#:~:text=Custom%20speech%20support\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Git clone the repository to your local machine.\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/hyogrin/Azure_OpenAI_samples.git\n",
    "```\n",
    "\n",
    "-   A subscription key for the Speech service. See [Try the speech service for free](https://docs.microsoft.com/azure/cognitive-services/speech-service/get-started).\n",
    "-   Python 3.5 or later needs to be installed. Downloads are available [here](https://www.python.org/downloads/).\n",
    "-   The Python Speech SDK package is available for Windows (x64 or x86) and Linux (x64; Ubuntu 16.04 or Ubuntu 18.04).\n",
    "-   On Ubuntu 16.04 or 18.04, run the following commands for the installation of required packages:\n",
    "    ```sh\n",
    "    sudo apt-get update\n",
    "    sudo apt-get install libssl3 libasound2\n",
    "    ```\n",
    "-   On Debian 9, run the following commands for the installation of required packages:\n",
    "    ```sh\n",
    "    sudo apt-get update\n",
    "    sudo apt-get install libssl1.0.2 libasound2\n",
    "    ```\n",
    "-   On Windows you need the [Microsoft Visual C++ Redistributable for Visual Studio 2017](https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads) for your platform.\n",
    "\n",
    "Configure a Python virtual environment for 3.10 or later:\n",
    "\n",
    "1.  open the Command Palette (Ctrl+Shift+P).\n",
    "1.  Search for Python: Create Environment.\n",
    "1.  select Venv / Conda and choose where to create the new environment.\n",
    "1.  Select the Python interpreter version. Create with version 3.10 or later.\n",
    "\n",
    "```bash\n",
    "# Create a virtual environment\n",
    "python -m venv venv\n",
    "\n",
    "# Activate the virtual environment\n",
    "# On Windows\n",
    "venv\\Scripts\\activate\n",
    "\n",
    "# On macOS/Linux\n",
    "source venv/bin/activate\n",
    "\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Create an .env file based on the .env-sample file. Copy the new .env file to the folder containing your notebook and update the variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "## 1. Generate synthetic dataset with Phi 3.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the environment variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage\n",
    "from azure.ai.inference.models import UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "SPEECH_KEY = os.getenv(\"AZURE_AI_SPEECH_API_KEY\")\n",
    "SPEECH_REGION = os.getenv(\"AZURE_AI_SPEECH_REGION\")\n",
    "CUSTOM_SPEECH_LANG = os.getenv(\"CUSTOM_SPEECH_LANG\")\n",
    "CUSTOM_SPEECH_LOCALE = os.getenv(\"CUSTOM_SPEECH_LOCALE\")\n",
    "\n",
    "phi_api_endpoint = os.getenv(\"AZURE_PHI3.5_ENDPOINT\")\n",
    "phi_api_key = os.getenv(\"AZURE_PHI3.5_API_KEY\")\n",
    "phi_deployment_name = os.getenv(\"AZURE_PHI3.5_DEPLOYMENT_NAME\")\n",
    "\n",
    "if \"/models\" in phi_api_endpoint:\n",
    "    phi_api_endpoint = phi_api_endpoint.split(\"/models\")[0] + \"/models\"\n",
    "    \n",
    "print(\"=== Azure AI Speech Info ===\")\n",
    "print(f\"SPEECH_REGION={SPEECH_REGION}\")\n",
    "print(f\"CUSTOM_SPEECH_LANG={CUSTOM_SPEECH_LANG}\")\n",
    "print(f\"CUSTOM_SPEECH_LOCALE={CUSTOM_SPEECH_LOCALE}\\n\")    \n",
    "\n",
    "try:\n",
    "    client = ChatCompletionsClient(\n",
    "        #endpoint=\"https://aoai-services1.services.ai.azure.com/models/chat/completions?api-version=2024-05-01-preview\", # you will run into a 500 error if you use this endpoint\n",
    "        endpoint=phi_api_endpoint,\n",
    "        credential=AzureKeyCredential(phi_api_key)\n",
    "    )\n",
    "\n",
    "    print(\"=== Initialized AI Inference client ===\")\n",
    "    print(f\"AZURE_PHI3.5_ENDPOINT={phi_api_endpoint}\")\n",
    "    print(f\"AZURE_PHI3.5_API_KEY={phi_api_key}\")\n",
    "    print(f\"AZURE_PHI3.5_DEPLOYMENT_NAME={phi_deployment_name}\")       \n",
    "        \n",
    "except (ValueError, TypeError) as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare prompt to generate text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference.models import SystemMessage\n",
    "from azure.ai.inference.models import UserMessage\n",
    "\n",
    "NUM_SAMPLES = 5\n",
    "\n",
    "topic = f\"\"\"\n",
    "Contoso Electronics call center QnA related expected spoken utterances for {CUSTOM_SPEECH_LANG} and English languages.\n",
    "\"\"\"\n",
    "question = f\"\"\"\n",
    "create {NUM_SAMPLES} lines of jsonl of the topic in {CUSTOM_SPEECH_LANG} and english. jsonl format is required. use 'no' as number and '{CUSTOM_SPEECH_LOCALE}', 'en-US' keys for the languages.\n",
    "only include the lines as the result. Do not include ```jsonl, ``` and blank line in the result. \n",
    "\"\"\"\n",
    "\n",
    "system_message = \"\"\"\n",
    "Generate plain text sentences of #topic# related text to improve the recognition of domain-specific words and phrases.\n",
    "Domain-specific words can be uncommon or made-up words, but their pronunciation must be straightforward to be recognized. \n",
    "Use text data that's close to the expected spoken utterances. The nummber of utterances per line should be 1. \n",
    "Here is examples of the expected format:\n",
    "{\"no\": 1, \"string\": \"string\", \"string\": \"string\"}\n",
    "{\"no\": 2, \"string\": \"string\", \"string\": \"string\"}\n",
    "\"\"\"\n",
    "\n",
    "user_message = f\"\"\"\n",
    "#topic#: {topic}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        SystemMessage(content=system_message),\n",
    "        UserMessage(content=user_message),\n",
    "    ],\n",
    "    # Simply change the model name for the appropiate model \"Phi-3.5-mini-instruct\" or \"Phi-3.5-vision-instruct\"\n",
    "    model=phi_deployment_name, \n",
    "    temperature=0.8,\n",
    "    max_tokens=1024,\n",
    "    top_p=0.1\n",
    ")\n",
    "\n",
    "content = response.choices[0].message.content\n",
    "print(content)\n",
    "print(\"Usage Information:\")\n",
    "#print(f\"Cached Tokens: {response.usage.prompt_tokens_details.cached_tokens}\") #only o1 models support this\n",
    "print(f\"Completion Tokens: {response.usage.completion_tokens}\")\n",
    "print(f\"Prompt Tokens: {response.usage.prompt_tokens}\")\n",
    "print(f\"Total Tokens: {response.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_text_file = \"cc_support_expressions.jsonl\"\n",
    "with open(synthetic_text_file, 'w', encoding='utf-8') as f:\n",
    "    for line in content.split('\\n'):\n",
    "        if line.strip():  # Check if the line is not empty\n",
    "            f.write(line + '\\n')\n",
    "\n",
    "%store synthetic_text_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a plain text file to train custom speech models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Check https://learn.microsoft.com/en-us/azure/ai-services/speech-service/language-support?tabs=stt for supported locale\n",
    "languages = [CUSTOM_SPEECH_LOCALE] # List of languages to generate audio files\n",
    "DELETE_OLD_DATA = True\n",
    "\n",
    "output_dir = \"plain_text\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "if(DELETE_OLD_DATA):\n",
    "    for file in os.listdir(output_dir):\n",
    "        os.remove(os.path.join(output_dir, file))    \n",
    "\n",
    "\n",
    "with open(synthetic_text_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            expression = json.loads(line)\n",
    "            for lang in languages:\n",
    "                text = expression[lang]\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "                file_name = f\"{lang}_{timestamp}.txt\"\n",
    "                with open(os.path.join(output_dir,file_name), 'a', encoding='utf-8') as plain_text:\n",
    "                    plain_text.write(f\"{text}\\n\")\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON on line: {line}\")\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"plain_text\"  # Redefine output_dir if necessary\n",
    "\n",
    "with open(os.path.join(output_dir, file_name), 'r', encoding='utf-8') as file:\n",
    "    content = file.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the generated text file path in the variable `plain_text_path`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_text_path = os.path.join(output_dir, file_name)\n",
    "%store plain_text_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
