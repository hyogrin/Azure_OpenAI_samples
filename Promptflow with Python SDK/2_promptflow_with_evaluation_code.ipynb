{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute batch groundness evaluation flow using Promptflow Python SDK \n",
    "í”„ë¡¬í”„íŠ¸ í”Œë¡œìš°ëŠ” ì•„ì´ë””ì–´ ë°œìƒ, í”„ë¡œí† íƒ€ì´í•‘, í…ŒìŠ¤íŠ¸, í‰ê°€ë¶€í„° í”„ë¡œë•ì…˜ ë°°í¬ ë° ëª¨ë‹ˆí„°ë§ì— ì´ë¥´ê¸°ê¹Œì§€ LLM ê¸°ë°˜ AI ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì—”ë“œíˆ¬ì—”ë“œ ê°œë°œ ì£¼ê¸°ë¥¼ ê°„ì†Œí™”í•˜ë„ë¡ ì„¤ê³„ëœ ê°œë°œ ë„êµ¬ ëª¨ìŒì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì‹ ì†í•œ ì—”ì§€ë‹ˆì–´ë§ì´ í›¨ì”¬ ì‰¬ì›Œì§€ê³  í”„ë¡œë•ì…˜ ìˆ˜ì¤€ì˜ í’ˆì§ˆë¡œ LLM ì•±ì„ ë¹Œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "\n",
    "> âœ¨ ***Note*** <br>\n",
    "> PromptflowëŠ” ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ì´ë©°, Azure ML, Azure AI Studio, Local VS Codeí™˜ê²½ì„ ëª¨ë‘ ì§€ì›í•©ë‹ˆë‹¤.  \n",
    "\n",
    "## Prerequisites\n",
    "3.10 ë˜ëŠ” ì´í›„ ë²„ì „ì˜ Python ê°€ìƒ í™˜ê²½ì„ êµ¬ì„±í•©ë‹ˆë‹¤ : \n",
    " 1. ëª…ë ¹ Paletteë¥¼ ì—½ë‹ˆë‹¤ (Ctrl+Shift+P).\n",
    " 1. Pythonì„ ê²€ìƒ‰í•©ë‹ˆë‹¤: Create Environmentë¥¼ ì„ íƒí•©ë‹ˆë‹¤.\n",
    " 1. Venv / Condaë¥¼ ì„ íƒí•˜ê³  ìƒˆ í™˜ê²½ì„ ë§Œë“¤ ìœ„ì¹˜ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.\n",
    " 1. Python interpreter ë²„ì „ì„ ì„ íƒí•©ë‹ˆë‹¤. 3.10 ì´ìƒì˜ ë²„ì „ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë””íœë˜ì‹œ ì„¤ì¹˜ë¥¼ ìœ„í•´ ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ ì‹¤í–‰ì— í•„ìš”í•œ packageë“¤ì„ ì„¤ì¹˜í•˜ì„¸ìš”. \n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "## Set up your environment\n",
    "í˜„ì¬ì˜ repositoryë¥¼ Clone í•˜ì„¸ìš”. \n",
    "\n",
    "```bash\n",
    "git clone https://github.com/hyogrin/Azure_OpenAI_samples.git\n",
    "```\n",
    "\n",
    ".env-sample íŒŒì¼ì„ ê¸°ë°˜ìœ¼ë¡œ .env íŒŒì¼ì„ ë§Œë“­ë‹ˆë‹¤. ìƒˆ .env íŒŒì¼ì„ ë…¸íŠ¸ë¶ì´ ë“¤ì–´ ìˆëŠ” í´ë”ì— ë³µì‚¬í•˜ê³  ë³€ìˆ˜ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "## Steps\n",
    "#### 1. Create Promptflow client with Credential and configuration\n",
    "#### 2. AI Studio batch run to get the base run data \n",
    "#### 3. Run Groundedness Evaluation of the Promptflow \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Import required libraries\n",
    "from promptflow.azure import PFClient\n",
    "from promptflow.entities import Run\n",
    "# Import required libraries\n",
    "from azure.identity import DefaultAzureCredential, EnvironmentCredential, InteractiveBrowserCredential\n",
    "from dotenv import load_dotenv\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "with open('./config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "print(config[\"subscription_id\"])\n",
    "print(config[\"resource_group\"])\n",
    "print(config[\"workspace_name\"]) # Azure AI Studio project name which is not the same as the Azure ML workspace name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Monitor the status of the run_result\n",
    "def monitor_status(pf_azure_client:PFClient, run_result:Run):\n",
    "    with tqdm(total=3, desc=\"Running Status\", unit=\"step\") as pbar:\n",
    "        status = pf_azure_client.runs.get(run_result).status\n",
    "        if status == \"Preparing\":\n",
    "            pbar.update(1)\n",
    "        while status != \"Completed\" and status != \"Failed\":\n",
    "            if status == \"Running\" and pbar.n < 2:\n",
    "                pbar.update(1)\n",
    "            print(f\"Current Status: {status}\")\n",
    "            time.sleep(10)\n",
    "            status = pf_azure_client.runs.get(run_result).status\n",
    "        while(pbar.n < 3):\n",
    "            pbar.update(1)\n",
    "        print(\"Promptflow Running Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Promptflow client with Credential and configuration\n",
    "- Create a promptflow client with the credential and configuration. You need to set the `config.json` file with subscription_id, resource_group and workspace_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()\n",
    "# if you cannot use DefaultAzureCredential and InteractiveBrowserCredential you need to set up the Managed identity in your .env file\n",
    "\n",
    "pf_azure_client = PFClient.from_config(credential=credential, path=\"./config.json\")\n",
    "\n",
    "try:\n",
    "    workspace = pf_azure_client.ml_client.workspaces.get(name=config[\"workspace_name\"])\n",
    "    print(f\"Connected to Azure AI Studio Workspace: {workspace.name}\")\n",
    "    print(f\"Workspace Location: {workspace.location}\")\n",
    "    print(f\"Workspace ID: {workspace.id}\")\n",
    "except HttpResponseError as e:\n",
    "    print(f\"Failed to connect to Azure ML Workspace: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. AI Studio batch run to get the base run data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the exist connections\n",
    "- currently we only support create connection in Azure AI, ML Studio UI. Check the exiting connections in the workspace.\n",
    "> âœ¨ ***important*** <br>\n",
    "> Update flow.dag.yaml files in your flow_path with the connection name you have created in the Azure ML Studio UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_path = \"./chat-serverless\"\n",
    "data_path = \"./data/questions_outdoor.jsonl\"\n",
    "\n",
    "# get the context from context.json file as str and map it to the column_mapping\n",
    "with open('./data/context_simple.json', 'r') as file:\n",
    "    context = json.load(file)\n",
    "file.close()\n",
    "column_mapping = {\n",
    "    \"question\": \"${data.question}\",\n",
    "    \"context\": context.get(\"context\")    \n",
    "}\n",
    "\n",
    "base_run = pf_azure_client.run(\n",
    "    flow=flow_path,\n",
    "    type=\"chat\",\n",
    "    data=data_path, \n",
    "    column_mapping=column_mapping,\n",
    "    display_name=\"chat_serverless_context_data\",\n",
    "    tags={\"chat_serverless_context_jsonl\": \"\", \"1st_round\": \"\"},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_status(pf_azure_client, base_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail = pf_azure_client.get_details(base_run)\n",
    "\n",
    "detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Groundedness Evaluation of the Promptflow \n",
    "The eval-groundness flow is illustrating measures how grounded the model's predicted answers are against the context. Even if LLMâ€™s responses are true, if not verifiable against context, then such responses are considered ungrounded.\n",
    "\n",
    "> ğŸ§ª +For Your Information<br>\n",
    "> **Groundedness** is a measure of how well the model's responses are grounded in the context. A grounded response is one that is directly supported by the context. For example, if the context is about a dog, a grounded response would be \"Dogs are mammals.\" An ungrounded response would be \"Dogs can fly.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "eval_groundedness_flow_path = \"./evaluation/\"\n",
    "data_path = \"./data/qna_outdoor.jsonl\"\n",
    "\n",
    "with open('./data/context_simple.json', 'r') as file:\n",
    "    context = json.load(file)\n",
    "\n",
    "column_mapping={\n",
    "        \"question\": \"${data.question}\",\n",
    "        \"context\": context.get(\"context\")    ,\n",
    "        \"answer\": \"${run.outputs.gpt4o_answer}\",\n",
    "    }\n",
    "eval_name = \"eval_groundedness\"\n",
    "now = datetime.datetime.now()\n",
    "timestamp = now.strftime(\"%m_%d_%H%M\")\n",
    "eval_name = str(eval_name + \"_\" + timestamp)\n",
    "\n",
    "eval_groundedness_result = pf_azure_client.run(\n",
    "    flow=eval_groundedness_flow_path,\n",
    "    data=data_path,\n",
    "    run=base_run,  # use run as the variant\n",
    "    column_mapping=column_mapping,\n",
    "    display_name=eval_name,\n",
    "    name=eval_name,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# pf_azure_client.stream(eval_groundedness_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_status(pf_azure_client, eval_groundedness_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail = pf_azure_client.get_details(eval_groundedness_result)\n",
    "\n",
    "detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
